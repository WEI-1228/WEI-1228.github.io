[{"title":"【pytorch笔记】pytorch中tensor.scatter_函数理解","url":"/2021/12/17/%E3%80%90pytorch%E7%AC%94%E8%AE%B0%E3%80%91pytorch%E4%B8%ADtensor-scatter-%E5%87%BD%E6%95%B0%E7%90%86%E8%A7%A3/","content":"Pytorch中的函数后加上“_”表示在原始tensor的基础上操作，改变原始tensor，若是torch.的函数，则不会改变原始tensor，而是会生成一个新的tensor，因此torch.scatter()和tensor.scatter_()函数的区别就在于是否改变原tensor。下面我们就通过scatter_()函数来介绍该函数作用。\nTensor.scatter_(dim, index, src, reduce=None) → Tensor\n我们首先通过阅读官方文档来看看这个函数的作用是什么。翻译过来主要意思就是，将src中的元素，按照index的顺序放入dim维度中。下面还举了一个3-D的例子\nself[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n\n如果你能一眼看出这个是怎么做的，那就可以退出不用看了。这三行表示的是在三个不同维度上对将src写到self函数中的效果。其中最关键的位置是index[i][j][k]，因为它决定了src[i][j][k]放进self中的位置。因此，src每个维度都必须&gt;=index的每个维度，因为每个index[i][j][k]都对应着一个src[i][j][k]。\n我通过二维的例子来进行解释。\nx = torch.zeros((3, 5))# tensor([[0., 0., 0., 0., 0.],#         [0., 0., 0., 0., 0.],#\t\t  [0., 0., 0., 0., 0.]])index = torch.tensor([[1, 0, 2, 1, 1],[0, 1, 1, 0, 2]])# tensor([[1, 0, 2, 1, 1],#         [0, 1, 1, 0, 2]])src = torch.randn((2, 5))# tensor([[-0.4014, -0.7197,  1.1508,  1.1462, -1.0964],#         [ 1.0820, -2.2081,  0.6046,  0.3120, -0.1554]])x = x.scatter_(dim=0, index=index, src=src)# tensor([[ 1.0820, -0.7197,  0.0000,  0.3120,  0.0000],#         [-0.4014, -2.2081,  0.6046,  1.1462, -1.0964],#         [ 0.0000,  0.0000,  1.1508,  0.0000, -0.1554]])\n\n上面怎么得到的呢？你可以按照下面的方式想，就能很容易直观得到结果。\n我们先将index每个位置上的数与src中每个位置上的数对应起来，如下图\n\n这样，每个index的位置，都对应着相应位置一个src的数。我们先在脑子中建立这样一个对应关系的印象，下面会用到这个对应关系。\n通过给的示例self[index[i][j][k]][j][k] = src[i][j][k]可以发现src中的!dim维度的索引（在这个例子中dim=0，!dim列就是第1维度），与x中对应维度的索引一一对应的，也就是说src第j列的数字，一定是放到x的第j列，那么你将src想成一列一列的数\n\n每一列的数，都要放到x的对应列中去，我们来看结果是不是这样的\n\n可以看到，经过处理后，x的每一列数字，就是对应到src每一列数字上，只是在这一列上的顺序不同。那么这个顺序怎么确定呢？这就要用到我们上面画的对应关系了，src对应位置的index作为索引，放到x对应列上的位置去，就得到了最终结果。也就是说，**index的每一列都是作为src对应列的顺序存在的**。\n最后我们整合一遍，首先看参数dim=0，说明除了第0维度，在其他维度上，src与x的索引是一致的，具体到我们的例子里来说，就是src的每一列与x的每一列位置是对应的，要将src每一列元素，填充到x的每一列中去。但对应的列的填充顺序是什么呢？当然就是看index上，每一列的数字了。\n下面我们再来举一个dim=1的例子。\nx = torch.zeros((3, 5))# tensor([[0., 0., 0., 0., 0.],#         [0., 0., 0., 0., 0.],#\t\t  [0., 0., 0., 0., 0.]])index = torch.tensor([[0, 1, 3, 2, 4], [1, 3, 4, 0, 2]])# tensor([[0, 1, 3, 2, 4],#         [1, 3, 4, 0, 2]])src = torch.randn((2, 5))# tensor([[ 0.2267, -1.5383, -1.1069, -1.3450, -0.5601],#         [ 0.5058,  1.3454,  0.1888, -0.0366, -1.2225]])x = x.scatter_(dim=1, index=index, src=src)\n\n大家可以先思考一下这个结果是什么？\n按照刚才的方法，首先由于dim=1，因此对于!dim=1的维度，src与x的索引是一致的，在本例中也就是行，src中每行元素应该填充到x的每一行去，因此，x的第三行肯定是空的，因为src只有两行数。而这两行数应该怎么填充呢？当然就是将index中对应行的数当作索引，把src中的数按照索引放到x中去啦。第一行是[ 0.2267, -1.5383, -1.1069, -1.3450, -0.5601]，索引为[0, 1, 3, 2, 4]，按照索引对第一行排序，0.2267放第0个位置，-1.5383放第1个位置，-1.1069放第3个位置…得到 [ 0.2267, -1.5383, -1.3450, -1.1069, -0.5601]，第二行自己算算吧，最后结果就是\ntensor([[ 0.2267, -1.5383, -1.3450, -1.1069, -0.5601],        [-0.0366,  0.5058, -1.2225,  1.3454,  0.1888],        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n\n","categories":["Pytorch笔记"],"tags":["Pytorch"]},{"title":"十一月计划及完成情况","url":"/2021/11/30/%E5%8D%81%E4%B8%80%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/","content":"11月1日\n\n  打毛线\n打了四圈\n\n  西瓜书——半监督学习\n计算学习理论没看懂跳过了，半监督学习中的图半监督学习没看懂，其他都大概看懂了\n\n  信号与系统继续学习\n\n\n\n11月2日\n\n  GBDT和XGBoost\nGBDT看懂了，XGBoost看懂了一点，还有很多细节没搞懂，明天也可以继续深挖细节\n\n  信号与系统继续学习\n有一点没太学明白，明天要看书复习一遍\n\n  跑步\n一公里5分06。。。好垃圾\n\n  打毛线\n\n\n\n11月3日\n\n  XGBoost\n完全疏通，很爽\n\n  体测\n跳远2.24m、引体向上3、一千米4：40\n\n  信号与系统复习\n下午体测，晚上继续看了会XGBOOST，就没看，明天开始复习\n\n\n最近还要开始深度学习课程了，先把李宏毅的深度学习看完，代码也要开始练习了，有能力还能看斯坦福的CS224N\n\n11月4日\n\n  信号与系统复习\n\n  西瓜书——概率图模型\n开了个头，明天继续\n\n  打毛线\n\n\n\n11月5日\n\n 隐马尔可夫模型吃透\n 打毛线\n\n\n11月6日\n\n 条件随机场的定义及表示形式\n\n\n11月7日\n\n CRF——最大熵模型\n\n​    还是很模糊明天看博客\n\n11月8日\n\n  最大熵模型与CRF\n最大熵模型基本完成，只是最后的IIS推导还没看明白，CRF最后带入求解也没看懂，下次再看吧\n\n\n\n11月9日\n\n 信号与系统学习+复习\n\n\n11月10日\n\n  深度学习——李宏毅\n把HW1重新做了一遍理解了一遍，课程学了一个章节\n\n\n明天要开始复习现代企业管理了，有时间还要再继续改进一下HW1，把误差再降低一些\n\n11月11日\n\n 现代企业管理复习（0~1章）\n\n\n11月12日\n\n 现代企业管理复习（2章）\n\n\n11月13日\n\n  现代企业管理复习（3~4章）\n\n  信号与系统学习\n学了三节视频，尽早把第四章学完，还有把ML第一个作业继续调一下，不然总感觉心里有块石头吊着，每天都很不舒服\n\n\n\n11月14日\n\n  现代企业管理复习（5章）\n\n  信号与系统学习\n\n  HW1调试\n\n\n\n11月15日\n\n HW1调试\n 现代企业管理复习\n\n\n11月16日\n\n 现代企业管理复习\n 信号与系统学习\n HW2调试\n\n\n11月17日\n\n 现代企业管理复习\n\n\n11月18日\n\n 现代企业管理复习\n 一拳超人漫画看完\n\n\n11月19日\n\n 现代企业管理复习\n 政审表\n 宝贝作业修改\n 毕业设计询问\n 打围巾结束\n\n​    预测失误，1m2根本不够长，还需要继续努力\n\n  宝贝小作文\n写了一半\n\n\n\n11月20日\n\n 形式与政策\n 小作文写信\n\n明天开始继续深度学习，还有毕业论文相关的论文开始看\n\n11月21日\n\n transformer学习\n\n\n11月22日\n\n BERT学习\n 论文阅读\n\n\n11月23日\n\n 论文阅读\n\n\n11月24日\n\n 论文阅读\n\n\n11月25日\n\n 论文阅读\n\n\n11月26日\n\n 组会\n\n\n11月27日\n11月28日\n\n  进击的巨人\n\n  休息\n\n\n\n11月29日\n\n HW4，attention看完\n\n看了一天的这个作业代码，训练一次要两个小时，根本没办法写。一晚上看pad_sequences没看明白，到宿舍看明白了一些，明天要写一篇博客记录一下，确实有点难理解。还有collate_fn没理解，明天再看几篇博客理解理解。下一步还要看attention源码，pytorch也要多熟悉了。\n\n11月30日\n问题：现在基本上都是在看别人的项目代码，自己还没有试着写过代码，看着别人的代码就觉得很有逻辑，但是如果自己写起来估计就不太写得好，怎么办？\n\n attention is all you need论文阅读\n collate_fn作用\n pytorch的attention源码阅读\n\n​    看了但没完全看懂，明天再试着继续看一下，还有论文conformer也看看\n\n\n            这个月计划完成的还行，中间有几天看动漫看的着迷了，从早看到玩，需要改进。还有要去锻炼了，体检都说我超重了/(ㄒoㄒ)/~~。下个月要继续pytorch的学习使用，还有李宏毅深度学习看完来。待学习的任务还有CS224N、线性代数基础书、西瓜书很多公式的推导、统计学习方法学习、深度学习代码编写。\n          \n","categories":["计划"],"tags":["计划"]},{"title":"十月计划及完成情况","url":"/2021/11/01/%E5%8D%81%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/","content":"10月12日：\n\n  西瓜书——决策树\n多变量决策树还未理解\n  信号与系统学习\n\n  跑步三公里\n\n\n\n10月13日：\n\n  西瓜书——神经网络\n还剩最后的神经网络分类没看完\n\n  西瓜书——LDA\n拉格朗日乘子法还没掌握\n  信号与系统学习与复习\nLDA看的久了一些，就没时间来看了\n  宝贝的信写完\n\n\n\n10月14日：\n\n  西瓜书——神经网络\n神经网络结束，朴素贝叶斯看完\n\n  信号与系统学复习与学习\n第一章复习完成，第二章学习遇到问题，明天继续啃\n\n\n\n10月15日：\n\n  西瓜书——SVM\nSMO算法还没理解透，下次继续理解\n\n  拉格朗日乘子法\n\n  信号与系统学习\n\n\n\n10月16日：\n\n  西瓜书——贝叶斯分类器\n朴素贝叶斯看完了\n\n  信号与系统学习\n\n\n\n10月17日：\n\n  西瓜书——贝叶斯分类器\n贝叶斯分类器结束，EM算法学习也结束\n\n  跑步三公里\n\n\n\n10月18日：\n\n 西瓜书——集成学习开头\n EM算法复习理解一下\n 信号与系统学习\n\n\n10月19日：\n\n 西瓜书——集成学习\n 信号与系统复习\n\n\n10月20日：\n\n 西瓜书——聚类\n 信号与系统学习\n 机器人汇报PPT\n\n\n10月21日：\n\n  机器人改进\n机器人优化结束，还剩实验报告没写\n\n  信号与系统第二章学习结束\n学习与复习结束，明天开始第三章\n\n  西瓜书——聚类\n看了一部分，明天结束\n\n\n\n10月22日：\n\n  西瓜书聚类结束\n高斯混合模型和EM算法结束，花了很多时间，导致没时间看信号与系统\n\n  信号与系统第三章开始学习\n\n  跑步四公里\n\n\n\n10月23日：\n\n  机器人博客撰写\n花了半个上午+一个下午+半个晚上，超出预期\n\n  信号与系统第三章开始学习\n刚开了个头，明天继续\n\n  西瓜书——降维\n没空看啦，明天再看吧\n\n\n\n10月24日：\n\n  信号与系统继续学习\n学了一点\n\n  西瓜书——降维\n心血来潮更新了我和宝贝的博客，还搭了一个私有云盘花了一天时间，就没搞其他的\n\n\n\n10月25日：\n\n  搭邮件服务器\n一上午没成功。。。\n\n\n其他啥都没干，就当放假\n\n10月26日：\n\n  信号与系统第三章学习结束\n\n  西瓜书——降维\n又没完成。。一晚上又去弄WSL去了，明天不能这么下去了，该学什么就学什么，打毛线都还没学，时间要利用起来，不能这么浪费了\n\n\n\n10月27日：\n\n  西瓜书——降维，一定要开始了\nKPCA还没看明白，其他的其他的看了一下午，感觉最近的效率有点低了，得调整啊\n\n  机器人课设报告要完成了\n一上午写报告\n\n  复习信号与系统第三章\n\n  学打毛线\n\n\n\n10月28日：\n​    7点33下床\n​    8点23打开电脑学习\n\n  西瓜书——降维\n\n  机器人汇报PPT\n\n  宝贝的报告写完\n\n  复习信号与系统第三章\n\n  跑步\n一公里五分零四。。。好拉跨\n\n  学打毛线\n\n\n\n10月29日：\n​    8点09下床\n​    十点半开始看机器学习（之前机器人汇报）\n\n  西瓜书——特征选择与数据压缩\n特征选择看完了，最后的LASSO回归求解没看懂，数据压缩也基本没看懂\n\n  学打毛线\n\n  信号与系统继续\n\n  机器人课设汇报\n\n  线性代数视频学习\n\n\n\n10月30日\n​    7点44下床\n​    8点40开始学习\n\n  线性代数视频学习完成\n\n  信号与系统第四章开始学习\n\n  打毛线\n打到凌晨两点半，什么都没打出来，打错了\n\n\n\n10月31日\n\n  打毛线\n十一点起床打毛线，打到晚上八点半，打错两次什么都没打出来\n\n  西瓜书——计算学习理论\n\n\n\n\n            这个月每天的计划完成情况不是很理想，很多时间都被浪费了，下个月要努力了。\n          \n","categories":["计划"],"tags":["计划"]},{"title":"2021年保研经验贴","url":"/2021/09/21/2021%E5%B9%B4%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E8%B4%B4/","content":"\n2021年保研大战就快要结束了，感觉形势还是一如既往的严峻，大佬们是一如既往的海。每次面试前，感觉自己复习的挺好，应该没什么问题，可每次面试出来之后，就感觉我怎么什么都不会。在此记录一下我的保研经历，不算非常累，运气起了很大的作用，希望对以后保研的学弟学妹或九推的同学能起到帮助，也欢迎大家在评论区交流！\n\n\n\n基本情况本科就读于合肥工业大学（不出名的211），所在班级是人数非常少的创新班，夏令营排名为5 / 28，后期综合排名为2 / 28。\n四级：579，六级：596\n论文：无\n竞赛：比较多，但是都挺水的\n项目：一个大创项目，一个实验室项目\n夏令营入营：北京邮电大学计算机学院，华东师范大学计算机学院，山东大学软件学院\n夏令营offer：华师计算机、山大软院（全员优营😅）\n预推免：东南大学计算机、国科大人工智能学院\n最终去向：国科大人工智能学院\n夏令营北京邮电大学计算机（7.9）概况介绍北邮好像是第一次开夏令营，填报的时候系统可以填三个志愿，最后能进一个学院。我至今都没搞清楚是什么情况，系统上显示我是第一个志愿被录取了，但是后来给我面试的好像是第二个志愿，2组软工的，一共入了二十个，好像只要5，6个。刚好那几天没有课，我就去请了一星期的假到外面开宾馆去面试。北邮面试挺简单的，老师们感觉也都很温柔。\n学院面试一上来老师就说面试分为三个部分。\n第一个部分是政治问题，如何看待校园贷、学术不端、当代大学生如何为国家做贡献。说完之后一个老师问我那你说说你如何为国家做贡献，我说我不犯法就是为国家做贡献哈哈哈，然后说了什么可能承担国家的课题之类的，攻克一些技术方面的话。\n第二部分是英语回答问题，那老师中文问问题，要我用英文回答。问了我们学校智能科学与技术专业（我所在的创新班）和计算机科学与技术专业的区别，还有为什么我选择他们的计算机学院不选择人工智能学院。我用的我的中式英语给他们回答了一遍，说我们智科都注重于软件，他们计算机软硬兼顾，我们学了机器学习，计算机视觉还有自然语言处理等，他们注重数据库、操作系统等。然后回答后面一个问题的时候，我最后一句说的是your institute is more … more fit me. 回答完之后我自己都笑了哈哈哈哈。\n第三部分就正式中文面试了。首先中文自我介绍一下，但由于我之前都只背了英文自我介绍，背了好几个晚上的英文版本，背的贼溜，上来居然要我中文自我介绍。我就当场把英文的转成中文的，顺口介绍了一下大创项目。讲完之后发现很多地方没讲到，竞赛还有成绩都没讲到┭┮﹏┭┮然后开始问我的项目，项目的数据是哪来的，项目推荐系统的准确性是如何衡量的（我项目中有个推荐系统），我大创项目的具体流程，然后问我有没有考虑过用步态识别来完成这个项目（前一天听老师的研究生汇报课题，好像他们就研究的步态识别）。然后把我专利问了问，还问了我的比赛情况，我的在比赛中的职责之类的。然后一个老师插了一句，你是智能科学与技术的是吧，那我问你随机森林算法原理是什么。幸好前几天复习机器学习把随机森林给看了一遍，感觉回答的挺好的。最后问我如何看待实习、读研计划、如果研究生遇到困难怎么办。\n总结北邮面试的总体感觉还是不错的，除了英文自我介绍，其他问题回答的都挺好。过了一个星期北邮老师打电话来问我的意向，问我有没有其他的offer，最后去不去北邮。然后我当时非常纠结学硕专硕的区别，我就跟他说如果学硕我就去，专硕不一定。电话打完之后我就后悔了，因为当时回家了一趟还刚进高铁站回校，下午就给老师发了封邮件说：专硕我也愿意！，那老师说：好的！之后就没有消息了。在那个夏令营的群里问出没出结果，大家也都不理我。那个时候拿到华师的offer了，过了几天一气之下就把群给退了🤣\n山东大学软件学院（7.10 ~ 7.11）概况介绍山大软件感觉实力也不错，总共128人面试，好像有些人没参加，最后优营好像96个，几乎全员优营，而且优营之后还没说是否能直接录取，说的是当前保研名额还没确定，等九月份才能确定是否录取。然后九月份的时候居然还开了预推免，真不知道山大要搞什么。\n10号宣讲会宣讲会就是各个实验室老师汇报他们做的东西，做的情况，非常无聊，而且还会记录时长，不能退出，进去和结束都要签到，好烦人。我就把腾讯会议在那挂着，一下都没听，去车站接女朋友去了。从上午讲到下午，上午八点半开始，下午六点多结束，中间一小时休息，其他时间一直在讲。。\n11号面试感觉山大面试面不出个什么东西来，又不要我英文自我介绍，让我中文自我介绍。然后英文问了我项目几个问题，我都回答上了。然后那些老师就一直问我项目，这个怎么做的，有没有考虑什么什么什么。我就说没考虑，没时间做那么多。然后就结束了。\n总结山大夏令营之后要联系导师，不联系导师不给优营，而且还发了个问卷挺唬人，有一项就是拿到优营之后去不去山大，填不去那肯定不要你，填去，那心里又不舒服，最后还是填了去哈哈哈哈。九月份的时候又收集了一个问卷，我就直接填了不去。感觉山大面试问不出什么水平来，完全就问项目，专业课专业知识什么的一下都没问。\n华东师范大学计算机（7.13 ~ 7.15）概况介绍入了华师计算机是我意想不到的，里面也有很多运气成分。华师夏令营的系统可以填2个志愿，我五月份在华师夏令营网站看到计算机学院要求专业排名前15%，而我是17%，所以我当时就没去报计算机夏令营。因为软件工程要求前20%就行，所以我第一志愿就填了软件工程，推荐信用的是我大创指导老师的推荐信。然后到了六月多，系统快关了，我再去官网看了看，发现计算机的排名要求也变成了20%，我就又赶紧报了个计算机学院，然后我想两个推荐信用同一个老师不太好，我就换了个之前我大数据比赛的指导老师的推荐信。最后没想到第一志愿没入，第二志愿给入了。计算机夏令营总共入了114人，实际进群100个左右，后来有的人又退群，说不去了，还剩九十多个人在群里。到机试的时候看到只有83个人提交过，最后优营了60个，比例还是非常高的，入了营基本上就稳了。\n12号宣讲会第一天就是一大堆的宣讲，各个团队的情况介绍啦，还有各个老师的课题汇报之类的。我基本没怎么听，在吃东西跟女朋友一起看觉醒年代哈哈哈。就听了两个比较感兴趣的团队，一个机器学习团队，一个语言认知与知识计算团队。\n13号上午机考 + 下午交流第二天就是机考以及与各个团队的交流。之前就听说华师夏令营的机考是他们学校的ACM出题，所以非常慌，一直也在练算法。用的当然就是华师自己的OJ，感兴趣的可以注册一个去看看，刷刷题ECNU Online Judge。账号是当天早上考前发的，中途不能掉线，因为账号绑定IP地址，如果掉线IP变了这个号就登不上了。一共四题，每题100分，感觉挺难的，没有人AC但有人拿了360，真的是太牛了。我最后拿了230分，感觉有个十几二十名吧。\n\nA. 索引查询\nB. 框体排序\nC. 放水\n\n\nD. 正则表达式匹配\n14号团队面试14号下午需要提交一个志愿表，要填写打算去的团队，以及一二三志愿导师，学院会尽量根据志愿情况，让志愿上的团队来面试你。我当时提交的团队是机器学习团队，因此第二天面试我的就是机器学习团队的老师。\n首先英文自我介绍（终于能用到自我介绍了），我就把背了无数遍的自我介绍又熟练的背了一遍。然后是给了一段英文文章，让我读一遍，然后翻译出来。我感觉我读的还行，翻译的时候就有点磕磕绊绊，自己知道是什么意思，估计面试的老师没听明白我在说什么。翻译完之后还有一个老师问我六级过了没(─.─|||\n自我介绍之后给了一张图片，让我回答图片上的问题，第一个问题是容器和虚拟机的概念，当时一下没反应过来容器是什么，就说我没听说过容器。面试结束后想了想，容器不就是docker嘛，之前学Java的时候我还用过，居然没回答上。第二个问题是SVM是什么，让我讲讲SVM的原理之类的。由于我当时就不是很了解SVM，只知道这个SVM是最大分类间隔分类器，前几天又正好看了李宏毅老师的SVM讲解，就说了一大堆没说到重点，把那个老师都说懵了。我说了什么就是最大分类间隔，然后用的损失函数是hinge-loss之类的，那老师说不是问你损失函数，问你原理。我又说了一大堆屁话哈哈哈，然后这个问题就结束了。\n之后就是各个老师问问题，一个老师问看你做这个项目，对于训练模型方面你有什么经验可以给我们分享吗，有没有遇到什么坑。由于我的项目都是随便做了做，根本没去训练，当时想要老师给台服务器训练模型，老师都不给我，直接让学长给了我一个训练好的模型，然后我就在那胡乱跟老师扯哈哈哈，说到什么学习率方面。然后他又问那学习率方面你怎么做的，我说我用的学习率衰减。他继续问学习率衰减还有什么其他方法吗，我回答说按照当前损失函数梯度设置学习率，梯度越小学习率设置越小，需要计算当前梯度之类的。然后那老师说叫我去看看Pytorch的学习率衰减方法，里面有很多，我这时候才反应过来他问的是Pytorch里的学习率衰减策略，我之前也是有看过的啊喂，只是不知道他问的是这个。\n总的来说，面试感觉很凉，很凉很凉，面完之后就一直躺床上，一直在想该怎么回答。\n总结面试完第二天，那个填了志愿的老师就打电话给我了，问了问我的情况，说我面试的分数怎么这么低，问了我什么问题，我说问了我SVM，然后他说，哦，我记得你。当时刚好就是这个老师一直在问我SVM，把他给说蒙了。。。然后他说他打电话问了我老师（给我写推荐信的）我的情况，由于我比赛给我们学校那个老师挂了好几个名，然后都拿到了奖，所以这个老师给我说了一通好话，把我推荐给这老师了，而且好巧不巧，这个老师跟华师我填志愿的老师之前就有合作，很早就认识了，他才有机会跟我说好话。然后华师的老师最后说可以要我，把我简历发他一份。刚跟那老师打完电话，我们学校的老师就给我打电话了，说华师老师打电话问他我的情况，说我面试成绩不好，然后他帮我解释说我不太会面试，但是实践能力很强，比赛拿了很多奖，对我印象很深刻之类的话。我当时真是太感谢他了！这老师真的太好了呜呜呜。\n过了两个星期出结果，我也顺利的拿到了优营。在这还是要感谢一下我的老师呜呜呜。\n预推免东南大学计算机学院概况介绍东南计算机总共入营了四五百人，计算机学院和软件学院好像是一起面试的，分了好多组并行面试。东南是夏令营和预推免一起开的，所以入了很多人，而且东南入营了没有任何短信或邮件通知，只有加了群或者经常关注官网或系统才能知道自己入营了，感觉很多同学就因为这个错过了入营的机会，没去系统里点确认参加。由于当时已经拿到华师offer了，也不想去东南，就没复习天天在家玩了。所以最后面试情况也不好，没拿到优营。\n分组面试（8.7）我面试是第40号，总共46人，到下午才轮到我。首先是讲PPT，学院发了个PPT模版，要自己做个PPT然后屏幕共享讲解。讲完之后英文问我项目，我做了那些工作，以及这个项目怎么做的之类的。很久没有面试，没有练口语了，所以回答的超级烂，磕磕绊绊，没有一句话完整说完。英文问完之后老师开始问问题，第一个老师说我项目太简单了。第二个老师看我PPT最后一页写了大数据之类的什么什么，就问我大数据方面的问题：1、如果数据量太大，比方1T或更大，单机无法全部加载，你怎么训练模型，2、数据量如果太少，你有什么办法解决。我当时一个都没答好，第一个问题我就没回答，老师说不用都会打，我就回答了第二个，我说数据加强，自己手动做数据什么的。然后那个老师说这类方法的名字叫什么你知不知道，我又说不知道。然后就结束了。\n总结面试完之后我就好迷茫，怎么问我一个都不会，心里有点难受呜呜呜。然后去网上查了一下，看到感觉那些方法都不是老师想要问的方法。总的来说自己还是非常菜，还是要继续提升自己，多看看书。\n国科大人工智能学院概况介绍我在七月份还是八月份的时候就在国科大系统上报名了预推免，然后一直没有消息，我还以为我早就凉了，前两个星期晚上跑步的时候，北京来了一个电话，我一看北京，我还以为北邮被鸽穿了来找我了哈哈哈哈，没想到是国科大的老师来问我情况，问我有没有别的offer，我说有个上海的offer，但如果国科大能要我我还是想冲一下，去面试。了解了一下我的情况后就说过几天面试，等消息。过了两天官网就发通知了，总共19人入了，加群的有16人，最终就16个人面试，不知道招多少人，按往年情况来看，估计招十个左右。进群看到一个清华，一个上交，压力就大起来了。\n学院面试国科大学院面试感觉也很舒服，老师看起来也都很友好，首先是英文自我介绍，我还是用的之前背的模版，但这次综合排名出来之后，我又多加了两句话说我已经取得了保研资格，并且综合排名是第二名。之后老师问我创新班是什么情况，让我介绍一下。又问了一下我项目的情况，以及一些课程情况。因为我简历上写能熟练运用C++，Python，Java进行编程，老师就问有多熟练，到哪种程度。最后问我如何在不知道python列表情况下获得最后一个元素。。。总的来说非常简单，就跟聊天一样。\n导师面试第二天上午我就打电话给填了志愿的老师问我能不能去，她说她在开会，下午再联系我。下午她就发封邮件给我，让我看一篇论文，第二天一起讨论讨论。那篇论文是关于transformer变形的论文，我就先把transformer看了一遍，然后去看这篇论文，当天晚上就看的差不多了。第二天起来又看了一会。下午五点的时候来给我面试，一共三个人，两个老师，还有一个人应该是她的研一学生。讲完之后她说我讲的不错，一天时间能理解到这个程度很不错。第二天早上我刚醒没一会，她就打电话来说要我了，把我报到学院去了。然后我的面试就这么结束了。\n总结国科大从通知我面试到最后拟录取我，正好一个星期，12号老师打电话了解情况，19号就给我发了拟录取通知，都没太反应过来。去网上搜了一下国科大人工智能学院的信息，都不太多，因为是2017年才新成立的学院。然后经过多方打听，并在拟录取我的那个中午，我也跟导师聊了三四十分钟，把我想知道的信息都问清楚了，感觉这个学院还是不错的，而且导师感觉也很不错，比华师找的那个好多了至少不会很差吧，而且听我在北京读书的朋友说国科大在北京名气挺大的，刚好我女朋友毕业以后也去北京，我就选择了国科大人工智能学院，把华师给拒了。\n\n写在最后2021年保研就快要结束了，我的去向也基本上定了下来，虽然还不知道国科大究竟怎么样，但终究只是走的路不一样，关键还是要看研究生阶段自己的造化了。去哪里其实都一样，但求个无悔二字，只要自己满意就行。等我去那边读书了再来更新那边的情况吧。\n保研大战刚开始的时候，我去博客上看了很多经验贴，南大，中科大厦大之类的，我就感觉如果我去我也行，可实际上到自己报名的时候，连入营的机会都没有。连续被拒十多次，心态都要爆炸了。后来心态慢慢也放平了，看到保研群里的大佬那么多，要不就是都有论文，要不就是排名特别高，我这种没论文没排名的人，那些学校确实看不上我，我也不做那种春秋大梦了。\n\n今年保研的情况不会比上一届严峻，海王依旧很多，往往十个人就能占了一百个夏令营名额，所以按道理来说预推免会有很多的机会。但实际上今年很多学校都特别海，候补的人特别多，基本上入营后，除了优营的选手就是候补。这也就导致我后来的第二名的排名没什么用了，想去投，但学校不多了。本来非常想去中科大，但中科大今年收我们学校的人不多，往年入营的人都有很多，今年却卡了rank，只收了我们班前两名，和计算机的前三名，后面的人压根就没机会，而且由于WL很长，我现在有rank了但没机会给我投了。\n最后也希望没有offer的同学在九推中拿到满意的offer，学弟学妹保研的时候也能拿到心仪的offer！\n\n11月15日补充\n在开系统最后的那几天，我身边有很多同学给中科大的老师发邮件，中科大很多老师都没招满，都需要自己去联系，很多同学就通过自己联系去了中科大，联系其他学校的也有，所以到最后快开系统的几天机会还是有很多的，海王放了offer就有机会了。所以不要轻易放弃，不要因为夏令营失利就否定自己！\n","categories":["保研"],"tags":["保研","计算机","夏令营","面试"]},{"title":"PX4无人机+Gazebo仿真实现移动物体的跟踪","url":"/2021/10/23/PX4%E6%97%A0%E4%BA%BA%E6%9C%BA-Gazebo%E4%BB%BF%E7%9C%9F%E5%AE%9E%E7%8E%B0%E7%A7%BB%E5%8A%A8%E7%89%A9%E4%BD%93%E7%9A%84%E8%B7%9F%E8%B8%AA/","content":"\n            这个学期我们有一个智能机器人系统的课设，我们组分配到的题目是《仿真环境下使用无人机及相机跟踪移动物体》，本文主要记录完成该课设的步骤以及内容。我们采用的最终方案是PX4飞控+gazebo仿真+mavros通讯控制，实现了在gazebo环境下无人机跟踪一个移动的小车。本文所使用的是Ubuntu18.04 + melodic。\n          \n\n\n\n试验环境介绍\n            首先要搞懂各个部分的关系[7]，以及各自的作用，才能对控制无人机有个完整的认识，我在一开始做的时候就花了很多时间都没搞懂PX4到底是个无人机还是个什么东西，mavros又是干什么的。下面我简要介绍一下各个部分的关系，让大家有个大致的了解。\n          \n\nPX4飞控PX4是一个飞控固件，所谓的飞控固件，就是能够向无人机发出控制命令，控制无人机的位姿、飞行速度以及螺旋桨的转速等等。无人机的运动就需要通过飞控固件发出命令来控制。官网的用户手册在这，推荐看英文版本，中文版本有的地方翻译的实在是太烂了，我看的时候感觉像是机翻的，而且与原文的位置都不太一样。\nGazebo仿真gazebo仿真就不用多说了吧，在学ros基本的操作的时候就应该接触过gazebo。这就是一个能够模拟现实世界的仿真软件，PX4的源代码里就提供了PX4无人机的gazebo模型，通过launch文件直接运行就能得到一个gazebo下的无人机。\nMAVROS通讯mavros里面有个ros，一看就是和ros相关的。我们看官网的介绍“MAVROS – MAVLink extendable communication node for ROS with proxy for Ground Control Station.”，这句话的意思是，MAVROS是MAVLink为了让ROS代理控制站的扩展交流节点。首先MAVLink是一个无人机通讯协议，也就是说与无人机交流所发出的信号或数据格式都要符合该协议，与HTTP等协议是一个道理。然后控制站其实是PX4为了控制无人机所开发的一个图形化控制站，可以通过GUI的形式来操作无人机，给一般用户很好的体验。而这里是用来代理控制站，也就是说充当控制站来控制无人机。到这里就很明显了，MAVROS就相当于代码版的控制站，若想要通过ros节点开控制无人机的飞行，那就必须通过mavros这个包，在这个包内包含了控制无人机的消息格式等。\n\n            综上所述，整个无人机的控制逻辑就是，通过mavros向PX4飞控发送控制命令，PX4再将命令发送到无人机的各个组件，以控制无人机按照用户的逻辑进行运动。而该无人机就在gazebo中，在gazebo中可以看到无人机的运动情况。\n          \n\n实验过程PX4无人机的安装1、安装环境依赖sudo apt install -y ninja-build exiftool python-argparse python-empy python-toml python-numpy python-yaml python-dev python-pip ninja-build protobuf-compiler libeigen3-dev genromfs xmlstarlet libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev\n\n2、安装python依赖（melodic默认的是python2）pip install pandas jinja2 pyserial cerberus pyulog numpy toml pyquaternion  -i https://pypi.tuna.tsinghua.edu.cn/simple\n\n我安装的时候pyulog没装上，其他的都装上了，如果你们也有这个问题，就把其他的装上，pyulog后面还有个步骤会自动安装\n3、安装ros与gazebo这两个的安装就不多说了，如果没安装的话可以在网上先安装好这两个再继续操作。\n4、安装mavrossudo apt install ros-melodic-mavros ros-melodic-mavros-extraswget https://gitee.com/robin_shaun/XTDrone/raw/master/sitl_config/mavros/install_geographiclib_datasets.shsudo chmod a+x ./install_geographiclib_datasets.shsudo ./install_geographiclib_datasets.sh #这步需要装一段时间,请耐心等待PX4配置\n\n\n            我在安装的时候出现两个问题。第一个问题是sudo apt install包的时候一直出现404，未找到这个包，解决方案时sudo apt update，将软件源更新一下，很可能是原始的位置已经过期了，需要更新才能找到最新的位置。第二个问题是最后一步的.sh文件执行太慢了，我挂那两三个小时都没结束，大概是因为被墙了吧。解决办法如下[8]：在 /usr/share 下目录新建 GeographicLib 目录。将  geoids gravity magnetic 三个文件夹拷贝到 /usr/share/GeographicLib 文件夹下面。上述三个文件夹的链接在这，提取码：dje9\n          \n\n5、PX4安装这里推荐使用gitee安装，非常感谢XTDrone团队[2]将代码放在了gitee上，我也使用过github安装，但总是断开连接，无数次重试才完整安装完成。\ncd ~git clone https://gitee.com/robin_shaun/PX4_Firmwarecd PX4_Firmwaregit checkout -b xtdrone/dev v1.11.0-beta1bash ./Tools/setup/ubuntu.sh --no-nuttx --no-sim-tools\n\n将.gitmodules替换为如下内容（在PX4_Firmware文件夹中ctrl+h查看隐藏文件）[1]\n[submodule &quot;mavlink/include/mavlink/v2.0&quot;]\tpath = mavlink/include/mavlink/v2.0\turl = https://gitee.com/robin_shaun/c_library_v2.git\tbranch = master[submodule &quot;src/drivers/uavcan/libuavcan&quot;]\tpath = src/drivers/uavcan/libuavcan\turl = https://gitee.com/robin_shaun/uavcan.git\tbranch = px4[submodule &quot;Tools/jMAVSim&quot;]\tpath = Tools/jMAVSim\turl = https://gitee.com/robin_shaun/jMAVSim.git\tbranch = master[submodule &quot;Tools/sitl_gazebo&quot;]\tpath = Tools/sitl_gazebo\turl = https://gitee.com/robin_shaun/sitl_gazebo.git\tbranch = master[submodule &quot;src/lib/matrix&quot;]\tpath = src/lib/matrix\turl = https://gitee.com/robin_shaun/Matrix.git\tbranch = master[submodule &quot;src/lib/ecl&quot;]\tpath = src/lib/ecl\turl = https://gitee.com/robin_shaun/ecl.git\tbranch = master[submodule &quot;boards/atlflight/cmake_hexagon&quot;]\tpath = boards/atlflight/cmake_hexagon\turl = https://gitee.com/robin_shaun/cmake_hexagon.git\tbranch = px4[submodule &quot;src/drivers/gps/devices&quot;]\tpath = src/drivers/gps/devices\turl = https://gitee.com/robin_shaun/GpsDrivers.git\tbranch = master[submodule &quot;src/modules/micrortps_bridge/micro-CDR&quot;]\tpath = src/modules/micrortps_bridge/micro-CDR\turl = https://gitee.com/robin_shaun/micro-CDR.git\tbranch = px4[submodule &quot;platforms/nuttx/NuttX/nuttx&quot;]\tpath = platforms/nuttx/NuttX/nuttx\turl = https://gitee.com/robin_shaun/NuttX.git\tbranch = px4_firmware_nuttx-9.1.0+[submodule &quot;platforms/nuttx/NuttX/apps&quot;]\tpath = platforms/nuttx/NuttX/apps\turl = https://gitee.com/robin_shaun/NuttX-apps.git\tbranch = px4_firmware_nuttx-9.1.0+[submodule &quot;platforms/qurt/dspal&quot;]\tpath = platforms/qurt/dspal\turl = https://gitee.com/robin_shaun/dspal.git[submodule &quot;Tools/flightgear_bridge&quot;]\tpath = Tools/flightgear_bridge\turl = https://gitee.com/robin_shaun/PX4-FlightGear-Bridge.git\tbranch = master [submodule &quot;Tools/jsbsim_bridge&quot;]\tpath = Tools/jsbsim_bridge\turl = https://gitee.com/robin_shaun/px4-jsbsim-bridge.git[submodule &quot;src/examples/gyro_fft/CMSIS_5&quot;]\tpath = src/examples/gyro_fft/CMSIS_5\turl = https://gitee.com/mirrors/CMSIS_5\n\n再次执行子模块更新指令\ngit submodule update --init --recursive\n\n编译\nmake px4_sitl_default gazebo\n\n配置环境变量，注意路径的匹配，你若修改了文件夹名要进行对应的修改，第一个catkin_ws是自己的工作目录。\nsource ~/catkin_ws/devel/setup.bashsource ~/PX4_Firmware/Tools/setup_gazebo.bash ~/PX4_Firmware/ ~/PX4_Firmware/build/px4_sitl_defaultexport ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmwareexport ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmware/Tools/sitl_gazebo\n\n下面我们就可以测试PX4无人机了，执行下面的命令\ncd ~/PX4_Firmwareroslaunch px4 mavros_posix_sitl.launch\n\n此时会打开gazebo环境，里面地面上有一个无人机。\n\n最后一步，测试无人机通讯\nrostopic echo /mavros/state\n\n若显示的消息中出现connected: True,则说明MAVROS与SITL通信成功。到此，无人机的配置就结束了。\n移动小车的安装\n            由于实验要求的是实现移动物体的跟踪，因此我使用了一个可控制的小车来代替移动物体[10]，通过键盘控制节点可以控制小车在gazebo环境中移动。\n          \n\n本试验使用的是TurtleBot3小车，安装和控制移动都非常方便。\n安装小车命令[5]\nsudo apt-get install ros-melodic-turtlebot3-*\n\n通过上述命令就安装好了TurtleBot小车，是不是很方便。\n由于该小车有三种形态，所以还需要通过环境变量指定一种形态，否则无法运行，我实验中使用的是 burger形态，其他两种形态你们可以自己去修改，我下面都以burger形态小车来讲解。通过环境变量指定小车有一下两种方式，推荐第二种一劳永逸，但若要修改就需要进入.bashrc文件中修改\nexport TURTLEBOT3_MODEL=burger\t\t\t\t\t\t\t# 每次打开新的终端都要执行echo &quot;export TURTLEBOT3_MODEL=burger&quot; &gt;&gt; ~/.bashrc\t\t#直接写入环境变量，打开终端每次都会自动执行\n\n下面我们运行小车，测试一下小车控制\nroslaunch turtlebot3_gazebo turtlebot3_world.launch\n\n然后运行键盘控制节点\nrosrun teleop_twist_keyboard teleop_twist_keyboard.py\n\n若没安装该节点需要先安装，执行下面的命令\nsudo apt-get install ros-melodic-teleop-twist-keyboard\n\n\n通过I L J K ,四个键可以控制小车的运动，详细的运动控制自己看控制台的输出。到此，移动小车的安装就已经完成。\nPX4无人机添加摄像头以及配置的修改\n            通过上面的工作，我们完成了无人机和移动物体的配置，若要完成无人机通过相机追踪小车，那相机怎么能少得了呢？默认的PX4无人机是不带摄像头的，我们需要修改配置文件使其带上一个摄像头。\n          \n\n给PX4添加一个深度摄像机[3]\ncd ~/PX4_Firmware/launchcp mavros_posix_sitl.launch mavros_posix_sitl_cp.launch\t\t# 不修改原始无人机文件，复制一个副本进行修改gedit mavros_posix_sitl_cp.launch\n\n\n            我后面的修改操作都是基于副本，先复制一份然后操作副本，以保持源代码的结构\n          \n\n做如下改动\n添加\n&lt;arg name=&quot;my_model&quot; default=&quot;iris_downward_depth_camera&quot;/&gt;\n\n修改\n&lt;arg name=&quot;sdf&quot; default=&quot;$(find mavlink_sitl_gazebo)/models/$(arg vehicle)/$(arg vehicle).sdf&quot;/&gt; \n\n为\n&lt;arg name=&quot;sdf&quot; default=&quot;$(find mavlink_sitl_gazebo)/models/$(arg vehicle)/$(arg my_model).sdf&quot;/&gt; \n\n\n            注意添加的代码需要在修改的上方\n          \n\n添加摄像头就完成了，但是该摄像头默认的分辨率是48 * 64，非常低，飞高一些就看不清地面的小车了，我们还需要修改一下摄像头的分辨率。\ncd ~/PX4_Firmware/Tools/sitl_gazebo/models/depth_cameragedit depth_camera.sdf\n\n将对应部分修改为\n&lt;update_rate&gt;10&lt;/update_rate&gt;...&lt;image&gt;&lt;format&gt;R8G8B8&lt;/format&gt;&lt;width&gt;400&lt;/width&gt;&lt;height&gt;400&lt;/height&gt;&lt;/image&gt;\n\nwidth与height对应的就是摄像头的分辨率，update_rate是图像的发布频率，由于把像素改高了，怕系统处理速度慢，因此把频率降低一倍。\n下面我们来测试一下摄像头是否配置成功。\ncd ~/PX4_Firmwareroslaunch px4 mavros_posix_sitl_cp.launch\t\t# 注意我修改的都是副本，不要运行错了\n\n放大无人机可以看见前面装上了一个长条形摄像机，这就是一个向下的深度相机。\n然后打开rviz，新开一个终端输入\nrviz\n\n先添加一个接收图像的窗口\n\n将图像的话题选择为/camera/rgb/image_raw，另一个对应的是深度图像，可以自己切换看看效果。\n\n这个时候image窗口就会显示无人机摄像机拍摄下来的图像，然后在运行无人机的那个终端输入命令commander takeoff，观察该图像窗口，会随着无人机起飞变化。\n\n由于这个地面平坦，将小车放到这个环境中的话，小车会动不了，所以要将仿真环境改一下，改成原始的空仿真环境。\nPX4仿真环境的配置文件是/home/ljw/PX4_Firmware/launch/posix_sitl.launch，与之前一样，我们不对原始文件进行修改，我们修改副本。\ncd ~/PX4_Firmware/launchcp posix_sitl.launch posix_sitl_cp.launchgedit posix_sitl_cp.launch\n\n将\n&lt;!-- Gazebo sim --&gt;&lt;include file=&quot;$(find gazebo_ros)/launch/empty_world.launch&quot;&gt;\t&lt;arg name=&quot;gui&quot; value=&quot;$(arg gui)&quot;/&gt;\t&lt;arg name=&quot;world_name&quot; value=&quot;$(arg world)&quot;/&gt;\t&lt;arg name=&quot;debug&quot; value=&quot;$(arg debug)&quot;/&gt;\t&lt;arg name=&quot;verbose&quot; value=&quot;$(arg verbose)&quot;/&gt;\t&lt;arg name=&quot;paused&quot; value=&quot;$(arg paused)&quot;/&gt;\t&lt;arg name=&quot;respawn_gazebo&quot; value=&quot;$(arg respawn_gazebo)&quot;/&gt;&lt;/include&gt;\n\n修改为\n&lt;!-- Gazebo sim --&gt;&lt;include file=&quot;$(find gazebo_ros)/launch/empty_world.launch&quot;&gt;    &lt;arg name=&quot;gui&quot; value=&quot;$(arg gui)&quot;/&gt;    &lt;arg name=&quot;world_name&quot; value=&quot;$(find turtlebot3_gazebo)/worlds/empty.world&quot;/&gt;    &lt;arg name=&quot;debug&quot; value=&quot;$(arg debug)&quot;/&gt;    &lt;arg name=&quot;verbose&quot; value=&quot;$(arg verbose)&quot;/&gt;    &lt;arg name=&quot;paused&quot; value=&quot;$(arg paused)&quot;/&gt;    &lt;arg name=&quot;respawn_gazebo&quot; value=&quot;$(arg respawn_gazebo)&quot;/&gt;&lt;/include&gt;\n\n也就是将原本的gazebo的.world文件换成turtlebot3小车的empty.world文件，这个world里什么都没有。光这样修改还没有生效，因为我们修改的是副本，原始调用这个文件的文件也需要修改，调用这个文件的文件就是之前的mavros_posix_sitl_cp.launch\ngedit mavros_posix_sitl_cp.launch\n\n将\n&lt;include file=&quot;$(find px4)/launch/posix_sitl.launch&quot;&gt;\n\n修改为\n&lt;include file=&quot;$(find px4)/launch/posix_sitl_cp.launch&quot;&gt;\n\n到此，无人机的配置就已经完成，可以再次运行一次无人机，看看环境是否发生变化。\n合并无人机和移动小车\n            在前面的步骤中，我们将无人机和移动小车都准备好了，下面我们就只要将无人机和小车放在同一环境中，就能开始我们的跟踪实验了。\n          \n\n通过阅读turtlebot3的启动文件/opt/ros/melodic/share/turtlebot3_gazebo/turtlebot3_empty_world.launch，可以看到启动小车的代码，我们将该代码添加到启动无人机的文件中，就能同时启动小车和无人机。\ncd ~/PX4_Firmware/launchgedit posix_sitl_cp.launch\n\n添加如下代码\n&lt;!-- car model and parameter --&gt;    &lt;arg name=&quot;model&quot; default=&quot;$(env TURTLEBOT3_MODEL)&quot; doc=&quot;model type [burger, waffle, waffle_pi]&quot;/&gt;    &lt;arg name=&quot;x_pos&quot; default=&quot;1.0&quot;/&gt;    &lt;arg name=&quot;y_pos&quot; default=&quot;1.0&quot;/&gt;    &lt;arg name=&quot;z_pos&quot; default=&quot;0.0&quot;/&gt;    &lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro --inorder $(find turtlebot3_description)/urdf/turtlebot3_burger.urdf.xacro&quot; /&gt;&lt;!-- gazebo car model --&gt;&lt;node pkg=&quot;gazebo_ros&quot; type=&quot;spawn_model&quot; name=&quot;spawn_urdf&quot; args=&quot;-urdf -model turtlebot3_$(arg model) -x $(arg x_pos) -y $(arg y_pos) -z $(arg z_pos) -param robot_description&quot; /&gt;\n\n我们让小车出生在1 1位置，无人机默认出生在0 0 位置。为了让小车更容易被无人机识别，我们将小车全身改成黑色。\nroscd turtlebot3_descriptioncd urdfsudo gedit turtlebot3_burger.gazebo.xacro\n\n\n            注意选择自己的小车文件进行修改，我这里修改的是burger小车的。\n          \n\n将文件中所有&lt;material&gt;Gazebo/xxx&lt;/material&gt;中的xxx全部改成Black。\n到此，无人机与移动小车全部配置完毕执行，我们测试一下。\ncd ~/PX4_Firmwareroslaunch px4 mavros_posix_sitl_cp.launch\n\n\n我们可以看到中间一个无人机和一个黑乎乎的小车，周围的环境已经变成了空的了。然后启动键盘控制节点可以控制小车的运动\nrosrun teleop_twist_keyboard teleop_twist_keyboard.py\n\n控制无人机运动通过阅读PX4官网的一个控制实例[9]，我们可以大致了解无人机运动的控制流程。我将实例代码复制过来并且添加注释，让大家对无人机控制代码有个理解。\n/*头文件，包括常见的geometry_msgs和mavros通信需要的mavros_msgs，添加上就行*/#include &lt;ros/ros.h&gt;#include &lt;geometry_msgs/PoseStamped.h&gt;#include &lt;mavros_msgs/CommandBool.h&gt;#include &lt;mavros_msgs/SetMode.h&gt;#include &lt;mavros_msgs/State.h&gt;/*current_state表示的是无人机的状态，在主函数中订阅了对应的话题，这个状态就会不断更新，表示无人机当前的状态。state_cb就是对应的回调函数，会不断的执行，更新状态。现在先不用管为什么需要这个状态，后面的代码会解释。*/mavros_msgs::State current_state;void state_cb(const mavros_msgs::State::ConstPtr&amp; msg)&#123;    current_state = *msg;&#125;int main(int argc, char **argv)&#123;    ros::init(argc, argv, &quot;offb_node&quot;);    ros::NodeHandle nh;    \t// 订阅无人机的状态    ros::Subscriber state_sub = nh.subscribe&lt;mavros_msgs::State&gt;            (&quot;mavros/state&quot;, 10, state_cb);        /*     发布一个geometry_msgs::PoseStamped的消息，需要知道的是，这个消息是控制无人机的一种方式，将指定坐标包裹进这个消息，然后发布出去，无人机就能自动飞行到指定的坐标地点    */     ros::Publisher local_pos_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;            (&quot;mavros/setpoint_position/local&quot;, 10);        /*    无人机有一个锁，如果不解锁，无人机虽然接受了命令但是不会动被锁住了，只有解锁了才能对无人机进行控制，下面这个服务调用就是用来请求解锁无人机。上面的current_state就包含了无人机是否解锁的信息，若没解锁就需要解锁，否则就不用，其用途在这就体现出来    */    ros::ServiceClient arming_client = nh.serviceClient&lt;mavros_msgs::CommandBool&gt;            (&quot;mavros/cmd/arming&quot;);        /*    无人机飞行有很多种模式，如果需要用代码操控无人机，我们就需要切换到OFFBOARD模式。上面的current_state也包含了无人机当前的飞行模式，若不是OFFBOARD就需要切换到该模式。下面的这个服务调用就是用来请求切换无人机飞行模式。    */    ros::ServiceClient set_mode_client = nh.serviceClient&lt;mavros_msgs::SetMode&gt;            (&quot;mavros/set_mode&quot;);    //the setpoint publishing rate MUST be faster than 2Hz    /*    在OFFBOARD模式下，需要以&gt;=2HZ的频率向无人机发送消息，否则无人机会回退到OFFBOARD模式之前所在的模式，因此这里的rate需要设置的比2大就行    */    ros::Rate rate(20.0);\t    // wait for FCU connection    /*    等待无人机与控制站连接（代码的方式就是代理），只有连接了才能发送消息    */    while(ros::ok() &amp;&amp; !current_state.connected)&#123;        ros::spinOnce();        rate.sleep();    &#125;    /*    pose就是坐标，本实例是让无人机在2m处悬空，因此z设置为2，z表示的就是高度    */    geometry_msgs::PoseStamped pose;    pose.pose.position.x = 0;    pose.pose.position.y = 0;    pose.pose.position.z = 2;    // 下面这个感觉有没有都无所谓    //send a few setpoints before starting    for(int i = 100; ros::ok() &amp;&amp; i &gt; 0; --i)&#123;        local_pos_pub.publish(pose);        ros::spinOnce();        rate.sleep();    &#125;    // 请求的切换模式的消息，设置为OFFBOARD    mavros_msgs::SetMode offb_set_mode;    offb_set_mode.request.custom_mode = &quot;OFFBOARD&quot;;    // 请求解锁的消息，arm表示解锁，设置为true，disarm是上锁    mavros_msgs::CommandBool arm_cmd;    arm_cmd.request.value = true;    // 记录上次请求的时间    ros::Time last_request = ros::Time::now();    while(ros::ok())&#123;        // 如果无人机模式不是OFFBOARD并且离上次操作时间大于5秒就发送请求切换，这里的5s是为了演示清楚设置的延时        if( current_state.mode != &quot;OFFBOARD&quot; &amp;&amp;            (ros::Time::now() - last_request &gt; ros::Duration(5.0)))&#123;            if( set_mode_client.call(offb_set_mode) &amp;&amp;                offb_set_mode.response.mode_sent)&#123;                ROS_INFO(&quot;Offboard enabled&quot;);            &#125;            // 更新本次请求的时间            last_request = ros::Time::now();        &#125; else &#123;            // 如果当前未解锁且与请求时间大于5s，就发送请求解锁            if( !current_state.armed &amp;&amp;                (ros::Time::now() - last_request &gt; ros::Duration(5.0)))&#123;                if( arming_client.call(arm_cmd) &amp;&amp;                    arm_cmd.response.success)&#123;                    ROS_INFO(&quot;Vehicle armed&quot;);                &#125;                last_request = ros::Time::now();            &#125;        &#125;\t\t        // 不断发送位置消息，但是只有解锁后才能真正开始运动，如果不发送就会退出OFFBOARD模式，因为请求发送速度要&gt;=2HZ        local_pos_pub.publish(pose);        ros::spinOnce();        rate.sleep();    &#125;    return 0;&#125;\n\n通过官网的代码就能知道控制无人机飞行的一般流程，只要将核心代码逻辑修改一下，就能实现无人机对小车的跟踪了。可以先将上面的代码运行一次，观察一下无人机的运动。\n\n            总体流程为：1、通过launch文件启动无人机的gazebo环境2、新建一个工作空间，包含的依赖有roscpp、std_msgs、geometry_msgs、mavros、cv_bridge、image_transport、sensor_msgs其中后面几个是为了后续图像处理用的，这里一并导入3、创建一个cpp文件，将上述代码复制进去4、修改CMakeLists5、rosrun该节点在无人机解锁后就能看到无人机飞到了空中2m处\n          \n\n控制无人机跟踪运动小车\n            通过上述无人机悬空的代码我们已经了解了控制无人机飞行的代码流程：首先定义好需要发送与接收的话题消息，并且定义好各个请求，然后将无人机切换到OFFBOARD模式，接着解锁无人机，同时需要一直给无人机发送运动控制的消息，包括位置控制或速度控制，并且频率要大于2HZ。通过以上流程框架，我们就能设计一个自动跟踪移动小车的代码。\n          \n\n通过网上查阅资料看到，控制无人机运动不仅可以通过发送位置消息[4]，还可以像控制小乌龟一样，发送速度消息[6]，这就为跟踪小车的提供了方案。我设计的跟踪思路：\n之前案例订阅和发布的话题就不用多说了，全部都要订阅，然后需要额外订阅的是无人机发送的图像，之前设置了10HZ，也就是一秒钟无人机会发送十帧图像过来，在该订阅的回调函数内，对图像进行处理，检查图像内是否有小车，如果有的话，就通过比较小车像素点的位置和图像中心像素点的位置，来判断方位，并相应的设置速度。图像处理回调函数如下：\n#include &lt;ros/ros.h&gt;#include &lt;geometry_msgs/PoseStamped.h&gt;#include &lt;geometry_msgs/Twist.h&gt;#include &lt;mavros_msgs/CommandBool.h&gt;#include &lt;mavros_msgs/SetMode.h&gt;#include &lt;mavros_msgs/State.h&gt;#include &lt;mavros_msgs/Altitude.h&gt;#include &quot;sensor_msgs/Image.h&quot;#include &quot;cv_bridge/cv_bridge.h&quot;#include&lt;opencv2/core/core.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;// 一些全局变量// 悬空高度（追踪小车的高度）const double h = 4;// 调整高度的速度（上升或下降）const double hv = 0.1;// 控制无人机的速度geometry_msgs::Twist velocity;// 无人机当前的高度double curH;// 无人机是否已经稳定在空中的标志bool start = false;void doImg(const sensor_msgs::Image::ConstPtr &amp;msg) &#123;        if(!start) return;        // 将无人机发布的图像先转化为灰度图，再进行二值化，就能得到黑白图像，若小车出现，那么在图像内有黑色的像素，否则图像全是白色像素，这也是我将小车改成黑色的原因，若改成其它颜色就不好进行分离    cv_bridge::CvImagePtr cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);\tcv::Mat img = cv_ptr -&gt; image;    cv::Mat gray, bin;    cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);    cv::threshold(gray, bin, 127, 255, cv::THRESH_BINARY);        // 获得图像的宽和高    static int row = bin.rows, col = bin.cols;    // 图像中心点的位置，我们假设图像中心点的位置就是无人机的位置，这样就能很方便的发布速度来控制无人机    static double centX = row / 2, centY = col / 2;        // x y用来记录小车在该帧图像出现的位置    int x, y;    // 是否找到小车的标记    bool findCar = false;        // 遍历图像，若图像内有黑色像素则代表发现了小车，记录下此时的x y位置    for(int i = 0; i &lt; row; i++) &#123;        for(int j = 0; j &lt; col; j++) &#123;            uchar point = bin.at&lt;uchar&gt;(i, j);            if(point == 0) &#123;                findCar = true;                x = i, y = j;                break;            &#125;        &#125;        if(findCar) break;    &#125;        // 记录最后一次找到小车的时间    static ros::Time last_find_time = ros::Time::now();    if(findCar) &#123;        ROS_INFO(&quot;找到目标位置, x = %d, y = %d&quot;, x, y);        // 将小车（所在像素点）相对无人机（图像中心像素点）的位置归一化到0 ~ 1之间，并以此作为控制无人机的速度，小车离无人机越远，则无人机的速度越大，否则无人机的速度越小        double vx = abs(centX - x) / centX;        double vy = abs(centY - y) / centY;                // 经测试，无人机发送的图像的垂直方向是无人机的x方向，图像的水平方向是无人机的y方向        // 因此，若小车（像素位置）在无人机（像素位置）上方，需要发送一个正的x方向速度，否则要发送一个负方向的速度        if(x &lt; centX) velocity.linear.x = vx;        else velocity.linear.x = -vx;        \t\t// y方向同理        if(y &lt; centY) velocity.linear.y = vy;        else velocity.linear.y = -vy;        // 若不给无人机发送z方向的速度，无人机会时上时下，因此通过下面这个代码控制无人机高度，若低于一定高度，就发布z方向的速度，若高于某个高度，就发送一个-z方向的速度，让无人机下降        if(curH &lt; h - 0.5) velocity.linear.z = hv;        else if(curH &lt; h + 0.5) velocity.linear.z = 0;        else velocity.linear.z = (curH - h) * -hv;        ROS_INFO(&quot;发布速度 x : %f, y : %f, z : %f&quot;, velocity.linear.x, velocity.linear.y, velocity.linear.z);        // 记录无人机最后一次发现小车的时间，后面有用        last_find_time = ros::Time::now();    &#125; else &#123;        ros::Time now = ros::Time::now();        velocity.linear.x = 0;        velocity.linear.y = 0;        // 无人机丢失目标五秒内，什么都不操作        if(now - last_find_time &lt; ros::Duration(5)) &#123;            ROS_INFO(&quot;没有找到目标...&quot;);        &#125; else &#123;            // 无人机丢失目标五秒后，开始向上飞行（扩大视野）来搜寻小车，搜寻的最高高度是无人机跟踪小车高度的两倍，这也是前面代码中控制无人机下降的原因，若无人机在升空过程中发现目标小车，会立刻下降跟踪小车            if(curH &lt; 2 * h - 1) &#123;                ROS_INFO(&quot;上升高度寻找，当前高度为：%.2f&quot;, curH);                velocity.linear.z = hv;            &#125; else &#123;                if(curH &gt; 2 * h + 1) velocity.linear.z = -hv;                else velocity.linear.z = 0;                ROS_INFO(&quot;目标丢失。。。&quot;);            &#125;        &#125;    &#125;&#125;\n\n上面的回调函数完成了对无人机追踪小车速度的控制，其运行逻辑是：若无人机发现了小车，就通过小车相对无人机的方位，发送x y方向的速度，否则如果丢失的话，在五秒内不进行任何操作，超过五秒后，开始提升无人机的高度扩大视野来寻找小车，最大高度是跟踪小车高度的两倍，一旦发现小车立刻下降并跟踪小车。\n上面只是一个回调函数，还要主函数来控制无人机。\nvoid do_H(const mavros_msgs::Altitude::ConstPtr&amp; msg) &#123;    curH = msg-&gt;local;&#125;mavros_msgs::State current_state;void state_cb(const mavros_msgs::State::ConstPtr&amp; msg)&#123;    current_state = *msg;&#125;int main(int argc, char **argv)&#123;    ros::init(argc, argv, &quot;offb_node&quot;);    ros::NodeHandle nh;    setlocale(LC_ALL, &quot;&quot;);    ros::Subscriber state_sub = nh.subscribe&lt;mavros_msgs::State&gt;            (&quot;mavros/state&quot;, 10, state_cb);    ros::Publisher local_pos_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;            (&quot;mavros/setpoint_position/local&quot;, 10);    ros::Publisher local_vec_pub = nh.advertise&lt;geometry_msgs::Twist&gt;            (&quot;/mavros/setpoint_velocity/cmd_vel_unstamped&quot;, 10);    ros::ServiceClient arming_client = nh.serviceClient&lt;mavros_msgs::CommandBool&gt;            (&quot;mavros/cmd/arming&quot;);    ros::ServiceClient set_mode_client = nh.serviceClient&lt;mavros_msgs::SetMode&gt;            (&quot;mavros/set_mode&quot;);    ros::Subscriber img_sub = nh.subscribe&lt;sensor_msgs::Image&gt;(&quot;/camera/rgb/image_raw&quot;, 10, doImg);    ros::Subscriber height_sub = nh.subscribe&lt;mavros_msgs::Altitude&gt;            (&quot;/mavros/altitude&quot;, 10, do_H);    //the setpoint publishing rate MUST be faster than 2Hz    ros::Rate rate(20.0);    // wait for FCU connection    while(ros::ok() &amp;&amp; !current_state.connected)&#123;        ros::spinOnce();        rate.sleep();    &#125;    geometry_msgs::PoseStamped pose;    pose.pose.position.x = 0;    pose.pose.position.y = 0;    pose.pose.position.z = h;    velocity.linear.x = 0;    velocity.linear.y = 0;    velocity.linear.z = 0;    mavros_msgs::SetMode offb_set_mode;    offb_set_mode.request.custom_mode = &quot;OFFBOARD&quot;;    mavros_msgs::CommandBool arm_cmd;    arm_cmd.request.value = true;    ros::Time last_request = ros::Time::now();    bool takeoff = false;    while(ros::ok())&#123;        if(!takeoff) &#123;            if( current_state.mode != &quot;OFFBOARD&quot; &amp;&amp;                (ros::Time::now() - last_request &gt; ros::Duration(2.0)))&#123;                if( set_mode_client.call(offb_set_mode) &amp;&amp;                    offb_set_mode.response.mode_sent)&#123;                    ROS_INFO(&quot;Offboard enabled&quot;);                &#125;                last_request = ros::Time::now();            &#125;            if( !current_state.armed &amp;&amp;                (ros::Time::now() - last_request &gt; ros::Duration(2.0)))&#123;                if( arming_client.call(arm_cmd) &amp;&amp;                    arm_cmd.response.success)&#123;                    ROS_INFO(&quot;Vehicle armed&quot;);                &#125;                last_request = ros::Time::now();            &#125;            if( current_state.armed &amp;&amp;                 (ros::Time::now() - last_request &gt; ros::Duration(5.0))) &#123;                    takeoff = true;                    ROS_INFO(&quot;Vehicle stabled&quot;);                    start = true;                    ROS_INFO(&quot;开始追踪...&quot;);                    last_request = ros::Time::now();                &#125;            local_pos_pub.publish(pose);        &#125; else &#123;            local_vec_pub.publish(velocity);        &#125;        ros::spinOnce();        rate.sleep();    &#125;    return 0;&#125;\n\n上述代码的逻辑比较好理解，我就不加注释，流程是：先通过位置控制无人机，让无人机在高度h处稳定悬空，当无人机稳定悬停在空中时，将控制无人机的方式改为速度控制，也就是通过发送速度来控制无人机。\n\n            为了方便讲解，将代码分成了两部分贴，将两部分合起来放在一个cpp里，就能正常执行。代码中无人机是否稳定悬空是通过一个时间延迟实现的，假定无人机能在五秒内悬停在指定点，五秒前都是通过位置控制无人机，五秒后就一直通过速度控制无人机。\n          \n\n到此，无人机跟踪运动小车的整个实验就完成了。\n参考Ubuntu18.04下基于ROS和PX4的无人机仿真平台的基础配置搭建\n ↩XTDrone仿真平台基础配置\n ↩PX4+gazebo仿真给无人机添加摄像头\n ↩使用ROS节点控制PX4——位置控制\n ↩ROS-melodic学习turtlebot3笔记＜一功能包导入与测试＞\n ↩PX4学习笔记3: 速度控制\n ↩APM,PX4,GAZEBO,MAVLINK,MAVROS,ROS之间的关系以及科研设备选型\n ↩执行 install_geographiclib_datasets.sh 错误！\n ↩MAVROS Offboard control example\n ↩在gazebo中导入移动小车+二维码\n ↩autolabor ROSTutorials\n ↩","categories":["ROS"],"tags":["ROS","PX4","目标跟踪"]}]