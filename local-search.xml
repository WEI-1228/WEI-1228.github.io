<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Luong-Attention与Bahdanau-Attention</title>
    <link href="/2022/04/24/Luong-Attention%E4%B8%8EBahdanau-Attention/"/>
    <url>/2022/04/24/Luong-Attention%E4%B8%8EBahdanau-Attention/</url>
    
    <content type="html"><![CDATA[<p>最近正在看RNN相关内容，看Pytorch教程看到一个seq2seq对话机器人教程，里面用到了Attention，这种attention方法是Luong等人提出来的，因此我称为Luong-Attention。在看论文，网上搜索相关文章的时候，还看到了一个Bahdanau提出的Attention方法，称其为Bahdanau-Attention，我就也把这篇文章阅读了一下，下面分别介绍一下这两种Attention机制。</p><h2 id="bahdanau-attention">Bahdanau-Attention</h2><h3 id="rnn-encoder-decoder">RNN Encoder-Decoder</h3><p>先简要介绍一下基于RNNEncoder-Decoder的翻译任务框架，该Attention机制就是基于这个框架之上，能让模型同时学习对齐和翻译。</p><p>在Encoder-Decoder框架中，encoder先读入输入句子<span class="math inline">\(x=(x_1,\cdots,x_{T_x})\)</span>，将其转成上下文向量<span class="math inline">\(c\)</span>。最常见的方法就是用RNN <span class="math display">\[\begin{aligned}h_t=f(x_t, h_{t-1})\\c=q(\{ h_1,\cdots,h_{T_x} \})\end{aligned}\tag{1}\label{a}\]</span> 其中，<span class="math inline">\(h_{t}\in\mathcal{R^n}\)</span>是<span class="math inline">\(t\)</span>时刻输出的隐状态，<span class="math inline">\(c\)</span>是从句子每个词的隐状态生成的上下文向量。<span class="math inline">\(f、q\)</span>一般都是非线性函数。Sutskever et al.(2014)中，<span class="math inline">\(f=LSTM\)</span>，<span class="math inline">\(q({h_1,\cdots,h_{T_x}})=h_T\)</span>，也就是直接将输入的最后一个位置的隐状态当作上下文向量。</p><p>decoder一般都是用来给定上下文向量<span class="math inline">\(c\)</span>，与之前所有预测出的单词<span class="math inline">\(y_1,\cdots,y_{t^{&#39;}-1}\)</span>，来预测下一个单词<span class="math inline">\(y_{t^{&#39;}}\)</span>。换句话说，decoder定义了输出翻译的y的概率，将其分解为顺序的联合概率的积：<span class="math display">\[p(y) = \mathop{\Pi}_{t=1}^Tp(y_t|\{y_1,\cdots,y_{t-1}\},c)\tag{2}\label{b}\]</span> 其中<span class="math inline">\(y=(y_1,\cdots,y_{T_y})\)</span>。有了RNN，每个条件概率都能通过模型计算为<span class="math display">\[p(y_t|\{ {y_1,\cdots,y_{t-1}\} },c)=g(y_{t-1},s_t,c)\tag{3}\label{c}\]</span> 其中，<span class="math inline">\(g\)</span>是非线性函数，潜在的多层的函数，能输出概率<span class="math inline">\(y_t\)</span>，<span class="math inline">\(s_t\)</span>是RNN的隐状态向量。需要注意的是，这个函数<span class="math inline">\(g\)</span>不光可以是RNN，还可以是RNN和de-convolutional网络的混合。</p><h3 id="方法">方法</h3><h4 id="encoder">Encoder</h4><p>本文使用的Encoder是Bi-RNN双向循环神经网络，因为这样能让模型在输出某个单词的时候考虑到前后文的信息，不只考虑前面的信息。通过双向神经网络，我们能获得每个单词的前向隐状态向量<span class="math inline">\(\overrightarrow{h_1},\cdots,\overrightarrow{h_j}\)</span>和后向隐状态向量<span class="math inline">\(\overleftarrow{h_j}\,\cdots,\overleftarrow{h_j}\)</span>。然后我们将前后向每个位置的隐状态向量拼接起来，得到<span class="math inline">\(h_j=[\overrightarrow{h_j^T};\overleftarrow{h_j^T}]^T\)</span>。这样，每个向量表示<span class="math inline">\(h_j\)</span>都包含了前后向的信息，然后由于RNN更擅长表示附近的输入，因此向量表示<span class="math inline">\(h_j\)</span>更能表示<span class="math inline">\(x_j\)</span>的相关信息。</p><h4 id="decoder">Decoder</h4><p>通过上一节介绍的的RNNEncoder-Decoder框架，就能开始介绍Decoder中的Bahdanau-Attention机制了。在这个attention机制中，我们定义上面的条件概率公式<span class="math inline">\(\eqref{b}\)</span>为： <span class="math display">\[p(y_i|y_1,\cdots,y_{i-1},\bold{x})=g(y_{i-1},s_i,c_i)\tag{4}\]</span>通过该公式，我们就能计算出下一个时刻应该输出哪个单词，即概率<span class="math inline">\(y_i\)</span>最大的那个单词。其中<span class="math inline">\(s_i\)</span>是RNN在时刻<span class="math inline">\(i\)</span>的隐状态，计算公式是： <span class="math display">\[s_i=f(s_{i-1},y_{i-1},c_i)\tag{5}\]</span> 也就是说，<span class="math inline">\(s_i\)</span>的计算需要上一个时刻的隐状态<span class="math inline">\(s_{i-1}\)</span>和上一个时刻的输出<span class="math inline">\(y_{i-1}\)</span>，以及当前时刻的上下文向量<span class="math inline">\(c_i\)</span>的参与，这就说明<span class="math inline">\(c_i\)</span>的计算是先于<span class="math inline">\(s_i\)</span>的，计算<span class="math inline">\(c_i\)</span>不需要<span class="math inline">\(s_i\)</span>的参与。</p><p>需要注意的是，不像当时已有的encoder-decoder模型方法，只考虑隐状态或之前输出的结果，这里还把上下文向量<span class="math inline">\(c_i\)</span>作为参数输入，这个<span class="math inline">\(c_i\)</span>是每个输出位置<span class="math inline">\(y_i\)</span>独有的参数，每个位置都需要动态计算出这个<span class="math inline">\(c_i\)</span>。</p><p>上下文向量<span class="math inline">\(c\)</span>的计算依赖于encoder编码每个单词的隐状态向量<span class="math inline">\((h_1,\cdots,h_{T_x})\)</span>。每个向量<span class="math inline">\(h_i\)</span>都包含了输入序列的所有信息（因为encoder是Bi-RNN），但更注重在单词<span class="math inline">\(i\)</span>附近的信息。</p><p>我们先来看看<span class="math inline">\(c_i\)</span>怎么计算，因为<span class="math inline">\(c_i\)</span>的计算不依赖于<span class="math inline">\(s_i\)</span>和<span class="math inline">\(y_i\)</span>，相反，这两个参数的计算都依赖于<span class="math inline">\(c_i\)</span>。<span class="math inline">\(c_i\)</span>是输入序列每个位置向量表示的加权求和：<span class="math display">\[c_i=\sum_{j=1}^{T_x}\alpha_{ij}h_j\tag{6}\]</span> <span class="math inline">\(\alpha_{ij}\)</span>就是当前输出位置<span class="math inline">\(i\)</span>对其他某个位置<span class="math inline">\(j\)</span>的权重，也就是说对于当前输出的单词<span class="math inline">\(i\)</span>，要考虑其与所有位置的权重，因此这样得到的每个位置的<span class="math inline">\(c_i\)</span>都是独立的，动态计算出来的： <span class="math display">\[\begin{aligned}\alpha_{ij}=\frac{\exp e_{ij}}{\sum_{k=1}^{T_x}\exp (e_{ik})}\\\text{where}\ e_{ik}=a(s_{i-1},h_k)\end{aligned}\tag{7}\]</span> <span class="math inline">\(\alpha_{ij}\)</span>的计算就是，计算当前输出位置<span class="math inline">\(i\)</span>的前一个位置的隐状态<span class="math inline">\(s_{i-1}\)</span>与所有单词的向量表示<span class="math inline">\(h_k\)</span>的相似度<span class="math inline">\(e_{ik}\)</span>（我这么称呼），然后将这个相似度通过一个softmax层，就得到了输出位置<span class="math inline">\(i\)</span>对每个输入位置<span class="math inline">\(j\)</span>的权重<span class="math inline">\(\alpha_{ij}\)</span>。那这个相似度<span class="math inline">\(e_{ik}\)</span>怎么计算，在这个方法中，就是简单的通过一个前馈神经网络来计算，参数随着整个网络一起优化。</p><p>权重<span class="math inline">\(\alpha_{ij}\)</span>代表前一个位置<span class="math inline">\(i-1\)</span>隐状态<span class="math inline">\(s_{i-1}\)</span>与所有位置的向量表示的相关性，越相关则<span class="math inline">\(\alpha\)</span>越大，否则越小。这就在decoder上实现了attention机制，让模型自己选择哪一部分相关性最大，最关注哪一部分。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220424144620347.png" alt="模型流程"><figcaption aria-hidden="true">模型流程</figcaption></figure><p>上图就是整个模型的流程，再来梳理一遍。首先输入每个单词的词向量<span class="math inline">\(\{X_1,X_2,\cdots,X_T\}\)</span>，通过双向RNN转化为前向隐状态向量<span class="math inline">\(\{\overrightarrow{h_1},\cdots,\overrightarrow{h_j}\}\)</span>和后向隐状态向量<span class="math inline">\(\{\overleftarrow{h_j}\,\cdots,\overleftarrow{h_j}\}\)</span>，拼接成完整的隐状态向量<span class="math inline">\(\{h_j,\cdots,h_j\}\)</span>，这些是encoder的工作。然后开始进入decoder部分，对于每个输出位置<span class="math inline">\(i\)</span>，计算该位置前一个位置的输出隐向量<span class="math inline">\(s_i\)</span>与所有位置的单词隐向量<span class="math inline">\(h_j\)</span>，计算attention的权重<span class="math inline">\(\alpha_{ij}\)</span>，进而计算上下文向量<span class="math inline">\(c_i\)</span>，再通过<span class="math inline">\(c_i\)</span>计算当前位置的隐状态向量<span class="math inline">\(s_i\)</span>,最后计算当前时刻<span class="math inline">\(i\)</span>的输出概率，得到当前时刻输出的单词<span class="math inline">\(y_i\)</span>。</p><hr><h2 id="luong-attention">Luong-Attention</h2><p>Luong-Attention提出了多种方法，但这些不同的方法的不同在于，求每个位置的上下文表示向量<span class="math inline">\(c_i\)</span>的方法不同。之后的流程都是一样的。我就先介绍一下所有的流程，再介绍不同的求<span class="math inline">\(c_i\)</span>的方法。</p><h3 id="整体流程">整体流程</h3><p>在Luong-Attention中，使用了多层单向LSTM作为编码器，先将输入文本向量转化为隐向量，每个单词t都对应有一个输出的隐向量<span class="math inline">\(\overlineh_s\)</span>。然后利用输入位置的隐向量<span class="math inline">\(\overlineh_s\)</span>，通过上面说的不同方法，得到每个输出位置对应的上下文向量<span class="math inline">\(c_t\)</span>。对于某个输出时刻<span class="math inline">\(t\)</span>，通过RNN能得到输出的隐向量<span class="math inline">\(h_t\)</span>,通过拼接结合<span class="math inline">\(h_t\)</span>和<span class="math inline">\(c_t\)</span>，得到注意力化的隐向量 <span class="math display">\[\tilde h_t=\tanh (W_c[c_t;h_t])\tag{8}\]</span> 注意力化的向量<span class="math inline">\(\tildeh_t\)</span>然后送到softmax层，得到输出单词的概率分布，就能用损失函数进行参数更新了：<span class="math display">\[p(y_t|y_{&lt;t},x)=\text{softmax}(W_s\tilde h_s)\tag{9}\]</span> 下面我们具体介绍一下怎么计算上下文向量<span class="math inline">\(c_t\)</span>。</p><h3 id="全局attention">全局Attention</h3><p>全局attention就是计算<span class="math inline">\(c_t\)</span>的时候，要考虑所有输入单词的隐向量，与Bahdanau-Attention中计算上下文向量的方法一样，给每个输入单词的隐状态一个权重，将所有隐状态加权求和，就能得到<span class="math inline">\(c_t\)</span>。时刻<span class="math inline">\(t\)</span>，第<span class="math inline">\(s\)</span>个隐状态向量的权重计算公式如下： <span class="math display">\[\begin{aligned}a_t(s)&amp;=\text{align}(h_t,\overline h_s)\\&amp;=\frac{\exp ({\text{score}(h_t,\overlineh_s)})}{\sum_{s^{&#39;}}\exp ({\text{score}(h_t,\overlineh_{s^{&#39;}})})}\\\end{aligned}\tag{10}\label{eq:10}\]</span> 其中的score函数是一个基于内容的函数，有三种不同的可选形式：<span class="math display">\[\begin{equation}\text{score}(h_t,\overline h_s)=\left\{\begin{array}{ll}h_t^T \overline h_s &amp; dot\\h_t^T W_a\overline h_s &amp; general\\v_a^T\tanh (W_a[h_t;\overline h_s]) &amp; concat\end{array}\right.\end{equation}\tag{11}\]</span> 与Bahdanau-Attention的比较：</p><ul><li>本方法中encoder和decoder使用的都是单向LSTM最顶层的输出，而Bah的encoder使用双向RNN前向后向输出的结合</li><li>本方法中的计算流程是<span class="math inline">\(h_t \rightarrow a_t\rightarrow c_t \rightarrow \tildeh_t\)</span>，先计算当前时刻输出的权重，再通过RNN输出的所有输入位置隐状态计算attention权重，然后通过权重加权得到上下文向量，最后得到最终的注意力化的隐状态；而Bahattention的流程是<span class="math inline">\(s_{t-1} \rightarrow a_t\rightarrow c_t \rightarrow s_t\)</span></li><li>最后，Bahattention只尝试了concat形式的打分函数，而本方法尝试了三种，并且证明了有其他方法比concat方法更好。</li></ul><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220424163732940.png" alt="全局attention示意图"><figcaption aria-hidden="true">全局attention示意图</figcaption></figure><h3 id="局部attention">局部Attention</h3><p>与全局对应的就是局部了，就是不把所有的输入单词的隐状态都用上，而只用部分，来计算上下文向量<span class="math inline">\(c_t\)</span>。具体用哪一部分呢？当然是由模型自己来选择。具体来说，首先模型在输出时刻<span class="math inline">\(t\)</span>生成一个位置<span class="math inline">\(p_t\)</span>，用于计算<span class="math inline">\(c_t\)</span>的隐向量都从窗口<span class="math inline">\([p_t-D,p_t+D]\)</span>中获得，<span class="math inline">\(D\)</span>是个超参数。怎么生成位置<span class="math inline">\(p_t\)</span>呢，又有两种方法。</p><ul><li><p>第一种是固定<span class="math inline">\(p_t=t\)</span>，假设窗口随着时间单调递增的。每个向量的权重<span class="math inline">\(a_t(s)\)</span>就通过公式<span class="math inline">\(\eqref{eq:10}\)</span>来计算</p></li><li><p>第二种是让模型预测<span class="math inline">\(p_t\)</span>的位置，通过下面的公式</p></li></ul><p><span class="math display">\[p_t=S\dotproduct \text{sigmoid}(v_p^T\tanh (W_ph_t))\tag{12}\]</span></p><p>​ 其中<span class="math inline">\(v_p\)</span>和<span class="math inline">\(W_p\)</span>都作为模型的参数来学习。<span class="math inline">\(S\)</span>是输入句子的长度，因此<span class="math inline">\(p_t\in[0, S]\)</span>。计算每个位置的权重<span class="math inline">\(a_t(s)\)</span>的时候，还添加了高斯分布，计算公式变成如下形式： <span class="math display">\[a_t(s)=\text{align}(h_t,\overline h_s)\exp({-\frac{(s-p_t)^2}{2\sigma^2}})\tag{13}\]</span> ​ 设置<span class="math inline">\(\sigma=\frac{D}{2}\)</span>。注意<span class="math inline">\(s\)</span>是相对于<span class="math inline">\(p_t\)</span>的位置。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220424165630355.png" alt="局部attention示意图"><figcaption aria-hidden="true">局部attention示意图</figcaption></figure><h3 id="前向输入法">前向输入法</h3><p>在机器翻译任务中，通常会维持一个输入集合，如果已经翻译过了就不应该继续翻译，而本方法在翻译的时候是独立的。因此，提出了前向输入的方法，将当前的输出<span class="math inline">\(h_t\)</span>当作下一个时刻输入的一部分。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220424171327770.png" alt="image-20220424171327770"><figcaption aria-hidden="true">image-20220424171327770</figcaption></figure><p>如图中虚线所示，将原本的输入与上一个时刻的输出拼接起来，当作这个时刻的输入。这样有两个好处：</p><ul><li>能让模型知道之前的信息，以便做出判断</li><li>让这个模型同时获取深度和广度的信息</li></ul><h2 id="总结">总结</h2><p>两种Attention模型都是很早提出的attention，实现attention的方法都使用了softmax函数，都有上下文向量<span class="math inline">\(c_t\)</span>，但是两个上下文向量的用法不一样。在Bahdanau-Attention中，<span class="math inline">\(c_t\)</span>是用来计算时刻<span class="math inline">\(t\)</span>的隐向量<span class="math inline">\(s_t\)</span>，并且还用来计算最后的概率<span class="math inline">\(p(y)\)</span>；而在Luong-Attention中，<span class="math inline">\(c_t\)</span>直接与时刻<span class="math inline">\(t\)</span>的隐向量拼接，用来预测概率<span class="math inline">\(p(y)\)</span>。总的来说，Bahdanau-Attention的计算方法更复杂一些，需要计算一个中间量<span class="math inline">\(s_i\)</span>,Luong-Attention相对较简单一些，也更符合直觉。</p>]]></content>
    
    
    <categories>
      
      <category>Attention</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>Attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为什么RNN中的batch_size都在第二维度</title>
    <link href="/2022/04/16/%E4%B8%BA%E4%BB%80%E4%B9%88RNN%E4%B8%AD%E7%9A%84batch-size%E9%83%BD%E5%9C%A8%E7%AC%AC%E4%BA%8C%E7%BB%B4%E5%BA%A6/"/>
    <url>/2022/04/16/%E4%B8%BA%E4%BB%80%E4%B9%88RNN%E4%B8%AD%E7%9A%84batch-size%E9%83%BD%E5%9C%A8%E7%AC%AC%E4%BA%8C%E7%BB%B4%E5%BA%A6/</url>
    
    <content type="html"><![CDATA[<p>今天在学习RNN的时候发现Pytorch中关于RNN模型的输入形状都是<code>[seq_length, batch, *]</code>，跟Linear层或Conv层都不一样，网上搜了一圈找到答案。</p><p>由于batch的存在是为了让计算机并行计算，而RNN模型的计算流程有些特殊，需要接收到上一个<code>x</code>的输出才能继续计算下一个输出，因此如果我们让<code>batch</code>成为<code>first_dim</code>，内存中的数据就是这样存储的</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220416170543845.png" alt="第一种存储方式"><figcaption aria-hidden="true">第一种存储方式</figcaption></figure><p>由于计算机是按顺序读取数据的，如果这样存储，计算机就不能同时读入多组数据进行批处理，只能先计算完序列a，再计算序列b。</p><p>但是如果我们让<code>seq_length</code>成为<code>first_dim</code>，内存中的数据是这样存储的</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220416171131065.png" alt="第二种存储方式"><figcaption aria-hidden="true">第二种存储方式</figcaption></figure><p>这样的话，计算机就能一次性读入a1和b1，输出y1和y2，然后读入a2和b2，并行计算下去，有多少batch就能同时计算多少条数据。</p>]]></content>
    
    
    <categories>
      
      <category>pytorch笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>RNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EM算法的导出</title>
    <link href="/2022/04/06/EM%E7%AE%97%E6%B3%95%E7%9A%84%E5%AF%BC%E5%87%BA/"/>
    <url>/2022/04/06/EM%E7%AE%97%E6%B3%95%E7%9A%84%E5%AF%BC%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<p>本文主要对EM算法进行推导导出，不细讲EM算法的背景与原理，如果想从头开始学EM算法可以看李航老师的统计学习方法，或B站徐亦达老师的EM算法推导，我认为举得例子非常清楚，能很清楚的了解EM算法能干什么，在干什么。</p><h2 id="em算法流程">EM算法流程</h2><p><strong>输入</strong>：观测变量数据<span class="math inline">\(Y\)</span>，隐变量数据<span class="math inline">\(Z\)</span>，联合概率分布<span class="math inline">\(P(Y,Z|\theta)\)</span>，条件分布<span class="math inline">\(P(Z|Y,\theta)\)</span>；</p><p><strong>输出</strong>：模型参数<span class="math inline">\(\theta\)</span></p><p>（1）选择参数的初值<span class="math inline">\(\theta^{(0)}\)</span>，开始迭代；</p><p>（2）<span class="math inline">\(E\)</span>步：记<span class="math inline">\(\theta^{(i)}\)</span>为第<span class="math inline">\(i\)</span>次迭代参数<span class="math inline">\(\theta\)</span>的估计值，在第<span class="math inline">\(i+1\)</span>次迭代的<span class="math inline">\(E\)</span>步，计算 <span class="math display">\[\begin{equation}\begin{aligned}Q(\theta,\theta^{(i)})&amp;=E_Z[\text{log}P(Y,Z|\theta)]\\&amp;=\sum_Z \log P(Y,Z|\theta)P(Z|Y,\theta^{(i)})\end{aligned}\end{equation}\tag{1}\label{aaa}\]</span> 这里，<span class="math inline">\(P(Z|Y,\theta^{(i)})\)</span>是在给定观测数据<span class="math inline">\(Y\)</span>和当前的参数估计<span class="math inline">\(\theta^{(i)}\)</span>下隐变量数据<span class="math inline">\(Z\)</span>的条件概率分布；</p><p>（3）<span class="math inline">\(M\)</span>步：求使<span class="math inline">\(Q(\theta,\theta^{(i)})\)</span>极大化的<span class="math inline">\(\theta\)</span>，确定第<span class="math inline">\(i+1\)</span>次迭代的参数估计值<span class="math inline">\(\theta^{(i+1)}\)</span> <span class="math display">\[\begin{equation}\theta^{(i+1)}=\text{arg}\max_\theta Q(\theta,\theta^{(i)})\end{equation}\tag{2}\]</span> （4）重复（2），（3）步直到收敛。</p><p>上式中的<span class="math inline">\(Q(\theta,\theta^{(i+1)})\)</span>是算法的核心，该函数成为<span class="math inline">\(Q\)</span>函数。以上算法便是<span class="math inline">\(EM\)</span>算法的核心步骤。我看了很多书上还有视频课讲解都是先直接放个公式给你，然后再讲一大堆解释这个公式。我就是经理这样的痛苦过来的，看到别人列了这个公式我就听不下去了，完全不知道这个公式在干什么。下面我就简单推导一下这个公式怎么来的。</p><h2 id="em算法导出">EM算法导出</h2><p>学过很多机器学习算法的人都知道，大部分算法的优化方法都是通过极大化对数似然函数<span class="math inline">\((MLE)\)</span>推导出来的，也就是对观测到的数据的概率的对数似然函数极大化，然后求得参数<span class="math inline">\(\theta\)</span>，也就是<span class="math inline">\(\text{arg}\max_\theta \logP(Y|\theta)\)</span>，<span class="math inline">\(Y\)</span>就是观测数据<span class="math inline">\({y_1,y_2,\dots,y_n}\)</span>。在EM算法中也不例外，也要通过极大化对数似然函数开始推导，即极大化<span class="math inline">\(L(\theta)=\logP(Y|\theta)\)</span>。由于EM算法是含有隐变量<span class="math inline">\(Z\)</span>的算法，意思就是每个数据<span class="math inline">\(y_i\)</span>是由某个隐变量<span class="math inline">\(z_j\)</span>得到的。举个例子，两枚不同的硬币进行投掷，第一枚硬币(A)正面概率为<span class="math inline">\(p\)</span>，第二枚硬币(B)正面概率为<span class="math inline">\(q\)</span>，我们得到一个观测序列<span class="math inline">\(\{1,1,0,1,0,0,1,0,1,1\}\)</span>，但是我们不知道每一个结果是由A还是由B投掷得到的，这时候隐变量<span class="math inline">\(Z\)</span>就相当于某一枚硬币，我们无法观测到，但实际存在这样的变量，因此称为隐变量。懂了隐变量的概念后，就能对公式进行变形<span class="math display">\[\begin{aligned}L(\theta)=\log P(Y|\theta)=\log \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\\=\log P(Y,Z|\theta) - \log P(Z|Y,\theta)\end{aligned}\tag{3}\]</span> 这一步是通过<span class="math inline">\(P(Y,Z|\theta) =P(Y|\theta)P(Z|Y,\theta)\)</span>变形然后取<span class="math inline">\(\log\)</span>得到的。现在我们得到公式 <span class="math display">\[\log P(Y|\theta)=\log P(Y,Z|\theta) - \log P(Z|Y,\theta)\tag{4}\]</span> 然后我们对两边式子取对<span class="math inline">\(Z\)</span>的期望，得到 <span class="math display">\[E_Z[\log P(Y|\theta)]=E_Z[\log P(Y,Z|\theta) - \logP(Z|Y,\theta)]\tag{5}\]</span> 由于左边的<span class="math inline">\(P\)</span>内不包含变量<span class="math inline">\(Z\)</span>，因此相当于对常数取期望，结果就是<span class="math inline">\(\log P(Y|\theta)\)</span>， <span class="math display">\[\begin{aligned}\log P(Y|\theta)&amp;=E_Z[\log P(Y,Z|\theta) - \log P(Z|Y,\theta)]\\&amp;=\sum_ZP(Z|Y,\theta^{(i)})\logP(Y,Z|\theta)-\sum_ZP(Z|Y,\theta^{(i)})\log P(Z|Y,\theta)\end{aligned}\tag{6}\]</span> 上面所说的对<span class="math inline">\(Z\)</span>取期望，取的<span class="math inline">\(Z\)</span>的概率就是<span class="math inline">\(P(Z|Y,\theta^{(i)})\)</span>。</p><blockquote><p>注意，由于<span class="math inline">\(Y\)</span>表示的是所有数据，对于上面的硬币模型来说，如果投掷了3次，那么其结果可能为<span class="math inline">\(Y=\{0,1,1\}\)</span>，而这时候的<span class="math inline">\(Z\)</span>就有<span class="math inline">\(2^3\)</span>种可能了，因为每个位置的观测都可能由硬币A或硬币B得到，因此<span class="math inline">\(\sum_Z\)</span>有8项。</p></blockquote><p>有没有觉得上式有点眼熟？没错，上式中的第一项就是EM算法中的<span class="math inline">\(Q\)</span>函数<span class="math inline">\(\eqref{aaa}\)</span>。我们说要将概率的似然函数<span class="math inline">\(P(Y|\theta)\)</span>极大化，按照上面的公式，左右两边都对<span class="math inline">\(\theta\)</span>极大化，我们会发现右边多了一项<span class="math display">\[H(\theta,\theta^{(i)})=\sum_ZP(Z|Y,\theta^{(i)})\logP(Z|Y,\theta)\tag{7}\]</span> 如果没有这一项，那么<span class="math inline">\(Q\)</span>函数就是我们的优化目标了，我们也就将优化目标从头推出来了，但事实上就是有这一项，那是EM算法有问题，把这一项省了吗？并不是，下面我们继续推导。</p><p>我们将上式记为<span class="math inline">\(H(\theta,\theta^{(i)})\)</span>函数，那么 <span class="math display">\[\log P(Y|\theta) = Q(\theta,\theta^{(i)})-H(\theta,\theta^{(i)})\tag{8}\]</span> 由于我们在EM算法中就是要对<span class="math inline">\(Q\)</span>函数极大化，因此迭代后的一定有<span class="math inline">\(Q(\theta,\theta^{(i+1)})\geqQ(\theta,\theta^{(i)})\)</span>，我们来看第二项 <span class="math display">\[H(\theta^{(i+1)},\theta^{(i)})-H(\theta^{(i)},\theta^{(i)})=\sum_Z \log(\frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})})P(Z|Y,\theta^{(i)})\tag{9}\]</span> 如果我们将其看成期望形式，<span class="math inline">\(P(Z|Y,\theta^{(i)})\)</span>是概率<span class="math inline">\(P(X)\)</span>，<span class="math inline">\(\log(\cdot)\)</span>是待求的期望函数<span class="math inline">\(\log(Y)\)</span>，而且<span class="math inline">\(\log\)</span>函数是凸函数，那么根据<span class="math inline">\(Jensen\)</span>不等式，我们能得到<span class="math inline">\(E[f(x)]\leq f(E[x])\)</span>，上面的式子就是<span class="math inline">\(E[f(x)]\)</span>，而 <span class="math display">\[\begin{aligned}f(E[x])&amp;=\log (\sum_Z\frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})}{P(Z|Y,\theta^{(i)})})\\&amp;=\log {\sum_Z P(Z|Y,\theta^{(i+1)})}\\&amp;=\log 1=0\end{aligned}\tag{10}\]</span> 也就是说，每一轮迭代不管<span class="math inline">\(\theta^{(i+1)}\)</span>是多少，<span class="math inline">\(H(\theta,\theta^{(i)})\)</span>都是在减小的，综合起来看，<span class="math inline">\(Q\)</span>每轮增加，<span class="math inline">\(H\)</span>每轮减小，那么<span class="math inline">\(Q-H\)</span>每轮肯定是在增加的，我们也就证明了在每轮迭代之后，<span class="math inline">\(\log P(Y|\theta)\)</span>每轮都是在增大的。</p><p>到此我们就推导出了要使变量的似然函数变大，只需要对函数<span class="math inline">\(Q\)</span>优化，求每轮使函数<span class="math inline">\(Q\)</span>最大的<span class="math inline">\(\theta\)</span>即可，也就是 <span class="math display">\[\theta^{(i+1)}=\text{arg}\max_\theta Q(\theta,\theta^{(i)})\]</span></p><h2 id="参考">参考</h2><p>李航《统计学习方法》</p><p>徐亦达机器学习：Expectation Maximization EM算法</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>EM算法</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Linear Transformer</title>
    <link href="/2022/04/04/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Linear-Transformer/"/>
    <url>/2022/04/04/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Linear-Transformer/</url>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/2006.16236">原文🔗</a></p><h1 id="fast-autoregressive-transformers-with-linear-attention">FastAutoregressive Transformers with Linear Attention</h1><h2 id="摘要">摘要</h2><p>Transformer已经在多个任务上取得了非常好的成绩，但是由于其复杂度与输入序列长度的二次方成正比，如果输入的是非常长的文本，它的速度会变得非常慢。为了解决这个问题，本文将self-attention表示成核函数特征的线性点积形式，并且充分利用矩阵乘积的相关性质，来将复杂度从<span class="math inline">\(O(n^2)\)</span>降到<span class="math inline">\(O(n)\)</span>，<span class="math inline">\(n\)</span>为序列的长度。我们证实了该公式能通过一直大大加速自回归transformer的速度迭代方法实现，并且揭露了它们与循环神经网络之间的关系。本文介绍的<em>lineartransformer</em>能获得原始transformer的性能，并且在超长文本的自回归预测的速度上要比原始的快4000倍。</p><h1 id="介绍">介绍</h1><p>Transformer模型最初是在一篇机器翻译的文章中被提出，并且已经证明了在许多任务上都能取得非常好的成绩。它除了在有大量监督学习样本的任务中非常有效，在没有样本或有限样本的迁移学习任务中也非常有效。</p><p>然而，获得这些好处的同时，也伴随着计算量的问题。主要的瓶颈就在于self-attention计算全局感受野，这个操作的复杂度是<span class="math inline">\(O(N)\)</span>。于是在实践中，Transformer的训练非常慢，并且表示文本的长度也是有限的。并且这会打破时间连贯性，让模型很难获得长文本的前后依赖关系。</p><p>最近，学者们都在研究如何增加上下文的长度但不牺牲效率。为此，Child等人提出了attention矩阵的稀疏分解，讲attention的复杂度降低到<span class="math inline">\(O(N\sqrt{N})\)</span>。Kitaev等人进一步用局部敏感哈希（Reformer）将attention的时间复杂度降到了<span class="math inline">\(O(NlogN)\)</span>。这些方法都让模型学习长文本成为可能。前面提到的这些方法虽然能让模型在长文本条件下顺利学习，都没有加速自回归的推理。</p><p>在本文中。我们提出了<em>lineartransformer</em>模型，能大大节省内存占用，并且复杂度是与文本长度呈线性的。我们通过self-attention的核函数的公式，并且利用矩阵乘积的相关属性来计算self-attention的权重。通过该线性公式，我们还将causalmasking表示成了线性时间复杂度，常数空间复杂度。这还揭露了transformers与RNN之间的关系，这能让模型的自回归加速几个数量级。</p><p>我们的评测在图像生成与ASR(automatic speechrecognition)上进行，评测证明了lineartransformer的性能能达到transformer的水平，并且还让速度提升了三个数量级。</p><h2 id="linear-transformers">Linear Transformers</h2><p>在本节，我们将我们提出的<em>lineartransformer</em>公式化。我们提出将传统attention的softmax形式改成基于特征的点积attention，这样能让模型具有更好的时空复杂度，并且能在线性时间内生成文本序列，类似于循环神经网络。</p><h3 id="transformers">Transformers</h3><p>我们再来回顾一下Transformer公式。</p><p>假设输入文本长度为<span class="math inline">\(N\)</span>，每个单词embedding到<span class="math inline">\(F\)</span>维的特征向量，那么输入文本的向量表示为<span class="math inline">\(x\in \mathbb{R}^{N\timesF}\)</span>，Transformer是由多层变换<span class="math inline">\(T:\mathbb{R}^{N\times F}\rightarrow\mathbb{R}^{N\times F}\)</span>，<span class="math inline">\(T_1(\cdot),\dots,T_L(\cdot)\)</span>表示的， <span class="math display">\[T_l(x)=f_l(A_l(x)+x)\tag{1}\]</span> <span class="math inline">\(f_l(x)\)</span>表示的就是全连接层，<span class="math inline">\(A_l(x)\)</span>表示的是attention层，<span class="math inline">\(A_l(x)+x\)</span>表示的是残差层。<span class="math inline">\(A_l(x)\)</span>的计算公式如下： <span class="math display">\[Q=xW_Q,\\ K=xW_k,\\ V=xW_V,\\A_l(x)=V^{&#39;}=\text{softmax}(\frac{QK^T}{\sqrt{D}})V\tag{2}\]</span></p><p><span class="math inline">\(V\)</span>的计算公式如下 <span class="math display">\[V_i^{&#39;}=\frac{\sum^N_{j=1}sim(Q_i,K_j)V_j}{\sum^N_{j=1}sim(Q_i,K_j)}\tag{3}\]</span></p><h2 id="线性attention">线性attention</h2><p>公式(2)是attention的一般定义，并且能用来定义其他种类的attention比如多项式attention或者RBFkernel attention。需要注意的是唯一需要加到<span class="math inline">\(sim\)</span>函数的约束是非负。这样就包括了所有kernel<span class="math inline">\(k(x,y):\mathbb{R}_+\)</span>。</p><p>给定一个用特征表示的核函数<span class="math inline">\(\phi(x)\)</span>，我们能将公式2重写为， <span class="math display">\[V_i^{&#39;}=\frac{\sum^N_{j=1}\phi (Q_i)^T\phi(K_j)V_j}{\sum^N_{j=1}\phi (Q_i)^T\phi (K_j)}\tag{4}\]</span> 我们再将其中的常数提出，利用矩阵的性质进一步化简 <span class="math display">\[V_i^{&#39;}=\frac{\phi (Q_i)^T\sum^N_{j=1}\phi (K_j)V_j^T}{\phi(Q_i)^T\sum^N_{j=1}\phi (K_j)}\tag{5}\]</span> 注意，特征映射<span class="math inline">\(\phi(\cdot)\)</span>作用在矩阵<span class="math inline">\(Q,K\)</span>的行方向上。</p><p>从公式(2)我们能看出softmax attention的时空复杂度是<span class="math inline">\(O(N^2)\)</span>。然而我们提出的<em>lineartransformer</em>的时空复杂度是<span class="math inline">\(O(N)\)</span>，因为我们能提前一次性计算出<span class="math inline">\(\sum_{j=1}^N\phi (K_j)V_j^T\)</span>，<span class="math inline">\(\sum_{j=1}^N\phi(K_j)\)</span>，之后每次用的时候直接取值就可以了。</p><h4 id="特征映射与计算代价">特征映射与计算代价</h4><p>对于softmax attention，乘法和加法的总复杂度是<span class="math inline">\(O(N^2\text{max}(D,M))\)</span>，其中<span class="math inline">\(D\)</span>是query、key的维度，<span class="math inline">\(M\)</span>是value的维度。但是，对于线性attention，我们先计算维度为<span class="math inline">\(C\)</span>的特征映射，然后计算新的values，这样只需要<span class="math inline">\(O(NCM)\)</span>的加法和乘法。</p><p>之前的分析都没有考虑核函数和特征函数的选择。注意，对应于指数核的特征函数是无限维的，这使得精确的softmax注意力的线性化是不可行的。另一方面，例如，多项式核具有精确的有限维特征映射，并且已被证明与指数核或RBF 核函数同样适用。2 次线性化多项式变换器的计算成本为<span class="math inline">\(O(ND^2M)\)</span>。这使得计算复杂度在<span class="math inline">\(N&gt;D^2\)</span>时有利。请注意，这在实践中是正确的，因为我们希望能够处理具有数万个元素的序列。对于我们处理较小序列的实验，我们使用了一个特征变换，该特征变换产生如下定义的正相似度函数<span class="math display">\[\phi(x) =\text{elu}(x)+1\\\text{where}\ \text{elu}(x)=\left\{\begin{aligned}x,if\ x\ge 0 \\\alpha(e^x-1),if\ x\lt0 \\\end{aligned}\right.\]</span></p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Reformer：The Efficient Transformer</title>
    <link href="/2022/01/23/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Reformer%EF%BC%9AThe-Efficient-Transformer/"/>
    <url>/2022/01/23/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Reformer%EF%BC%9AThe-Efficient-Transformer/</url>
    
    <content type="html"><![CDATA[<p><strong><a href="https://openreview.net/forum?id=rkgNKkHtvB">原文🔗</a></strong></p><h2 id="摘要">摘要</h2><p>Transformer模型在许多任务上都取得了SOTA的结果，然而训练这些模型通常都需要非常大的开销，特别是对于长文本模型。本文介绍了两种让Transformer模型更加高效的方法。第一，将点积的attention机制用局部敏感哈希来替代（LSH），这让时间复杂度从<span class="math inline">\(O(L^2)\)</span>降到了<span class="math inline">\(O(LlogL)\)</span>，其中<span class="math inline">\(L\)</span>是文本的长度。第二，使用可逆的残差网络代替标准的残差层，这样能只保存一次激活单元，而非一般的N次，其中N为网络的层数。最终得到了模型Reformer，与普通的Transformer模型效果不相上下，但内存开销更小，并且更快。</p><h2 id="简介">简介</h2><p>为了解决普通的Transformer内存开销大，时间复杂度高的问题，本文运用了下列技术：</p><ul><li>可逆层（上一篇论文笔记介绍），能够只存储一层的激活单元</li><li>将前馈层的激活单元拆分开来，并且分块处理它们，能降低空间复杂度</li><li>基于LSH的近似attention计算将attention部分的时间复杂度从<span class="math inline">\(O(L^2)\)</span>降低到了<span class="math inline">\(O(L\text{log}L)\)</span></li></ul><p>本文主要研究上面的三种方法，并且发现它们对模型训练时的影响几乎可以忽略不计。将激活单元拆分只影响代码实现，每一层的数据在数值上与Transformer是一样的。应用可逆残差层确实改变了模型的结构，但是在实验中发现对模型的影响也是可以忽略不计的。最后，LSH是对attention的改进，也是对模型效果影响最大的地方，桶的数目对模型效果影响很大。经过实验作者发现一组参数既能提高模型的效率，又能得到与原始Transformer模型相似的实验结果。</p><h2 id="局部敏感哈希注意力机制">局部敏感哈希注意力机制</h2><p>再让我们先回顾一下标准的attention计算过程。</p><h3 id="点积注意力">点积注意力</h3><p>Transformer中的标准attention是归一化的点积attention。输入包括<span class="math inline">\(d_k\)</span>维的queries和keys以及<span class="math inline">\(d_v\)</span>维的values。然后计算每个query与所有keys的点积，除以<span class="math inline">\(\sqrt{d_k}\)</span>，然后通过一个<span class="math inline">\(softmax\)</span>层，得到values的权重。在计算的时候，对于所有query的attention计算过程是同时进行的，因为可以将计算过程转化为矩阵乘法。将query打包成矩阵<span class="math inline">\(Q\)</span>，keys和values矩阵打包成矩阵<span class="math inline">\(K\)</span>和<span class="math inline">\(V\)</span>，计算过程就是： <span class="math display">\[\text{Attention}(Q, K, V) =\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V\tag{1}\]</span></p><h3 id="多头注意力机制">多头注意力机制</h3><p>Transformer并不是使用一个attention，而是使用多个attention，通过投影出<span class="math inline">\(h\)</span>组不同的queries，keys，values，得到<span class="math inline">\(h\)</span>个结果，然后拼接起来再进行一次投影，得到最后的结果。</p><h3 id="节约内存的注意力机制">节约内存的注意力机制</h3><p>为了计算attention消耗的内存，我们将重点放在attention计算公式(1)上。假设Q，K，V有相同的大小[<span class="math inline">\(batch\_size,length,d\_model\)</span>]</p><p>。其中主要的问题在于<span class="math inline">\(QK^T\)</span>，它的维度是[<span class="math inline">\(batch\_size,length,length\)</span>]。在实验中，作者训练了64K长度的模型，就算把batch-size设为1，在32位浮点精度的情况下<span class="math inline">\(64K\times64K\)</span>的矩阵会消耗16G内存。这就会让模型变得非常不实用，难以处理长文本。但重要的是，这个<span class="math inline">\(QK^T\)</span>矩阵没必要完全存储在内存中，因为可以分开计算每个query的attention值，在内存中每次只计算<span class="math inline">\(\text{softmax}(\frac{q_iK^T}{\sqrt{d_k}})V\)</span>，然后反向传播需要用它来计算梯度的时候再重新算一遍就可以了。然而这样的方法并不是非常高效，但空间复杂度与文本长度成正比。</p><h3 id="哈希注意力机制">哈希注意力机制</h3><p>在LSH中，我们初始化两个tensor，Q=K和V，维度为<span class="math inline">\([batch\_size,length,d\_model]\)</span>。我们也保持了多头注意力机制并且将重点关注在公式(1)。如前文所述，最大的问题在于<span class="math inline">\(QK^V\)</span>这一项的复杂度是平方的。但我们感兴趣的是softmax(<span class="math inline">\(QK^T\)</span>)。由于softmax的结果取决于输入元素中最大的一项，因此对于query<span class="math inline">\(q_i\)</span>我们只需要将重点关注在K中与queries最近的keys上。例如，如果K的长度是64K，对于每个<span class="math inline">\(q_i\)</span>我们只需要考虑一小部分，比如32个或64个最接近的keys，其他的keys与query点积经过softmax得到的结果几乎为0，可以不用考虑。这样就变得高效多了，然而怎么快速的在keys中找到与query最近的那几个呢？</p><h3 id="局部敏感哈希">局部敏感哈希</h3><p>我们先看一个LSH简单的示意图：</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220124145006703.png" alt="LSH示意图"><figcaption aria-hidden="true">LSH示意图</figcaption></figure><p>想象一个平面上有一个圆，上面有两个点x、y，将这个平面划分为四个部分（桶）（上图中的四个颜色），然后我们随机将这个圆圈旋转一个角度<span class="math inline">\(\theta_0\)</span>，x、y两个点会分别落到各自的部分。第一行三幅图中，x分别落在了0,1,2三个位置，y分别落在了3,2,0三个位置，那么在第一次和第三次旋转后，x和y是落在同一个组里，第二次旋转落在不同组里。这就是局部敏感哈希的原理，下面我们将这个原理应用在向量上。</p><p>快速在高维空间找到最近的向量的问题也能通过局部敏感哈希(LSH)解决。我们定义一个哈希函数，能将向量x映射到一个哈希值h(x)，它能让相近的向量映射到相同的哈希值，而距离比较远的向量不能，这样的哈希函数就是一种局部敏感哈希。在上述问题中，我们确实就需要将相近的向量映射到相同的哈希值（桶），并且要尽量让每个桶尽量一样大。如果有了这样的一个哈希函数，我们的问题就解决了。</p><p>我们通过随机投影来得到上述局部敏感哈希函数。如果我们要得到b个桶（将上图平面分为b份），那么就固定一个大小为<span class="math inline">\([d_k,b/2]\)</span>的随机矩阵<span class="math inline">\(R\)</span>，这个矩阵就相当于随机转动那个圆盘的力量，但转动的是一个向量。定义公式<span class="math inline">\(h(x)=argmax([xR;-xR])\)</span>，这个公式就是转动的方法，其中<span class="math inline">\([u;v]\)</span>表示两个向量连接。这个方法就是LSH，这也非常容易通过代码实现。</p><h3 id="lsh注意力机制">LSH注意力机制</h3><p>了解了LSH的原理，下面就介绍LSHattention。首先将普通的attention机制重写，对于每个query位置<span class="math inline">\(i\)</span>： <span class="math display">\[o_i=\sum\limits_{j\in\mathcal{P_i}}{\text{exp}(q_i\cdotk_j-z(i,\mathcal{P_i}))}v_j\\where\ \mathcal{P_i}={j:i\geq j}\tag{2}\]</span> 引入了标记<span class="math inline">\(\mathcal{P_i}\)</span>表示位置<span class="math inline">\(i\)</span>需要attend的位置，<span class="math inline">\(z\)</span>表示被除数的函数（比如softmax中的归一化项）。为了更加清晰，忽略了<span class="math inline">\(\sqrt{d_k}\)</span>的缩放。</p><p>这个公式实际上就是公式(1)的变形，公式(1)中的softmax拆开就是 <span class="math display">\[o_i=\sum\limits_{j\in\mathcal{P_i}}\frac{e^{q_i\cdot k_j}}{e^{q_1\cdotk_j}+e^{q_2\cdot k_j}+\cdots+e^{q_n\cdot k_j}}v_j\]</span> 然后让<span class="math inline">\(\text{exp}(z(i,\mathcal{P_i}))={e^{q_i\cdotk_j}}{e^{q_1\cdot k_j}+e^{q_2\cdot k_j}+\cdots+e^{q_n\cdotk_j}}\)</span>就得到了变形公式(2)。</p><p>为了使代码支持batch操作，我们通常在一个大的集合<span class="math inline">\(\widetilde{\mathcal{P}}={0,1,\dots,l}\supseteq{\mathcal{P_i}}\)</span>里进行attention操作，但要把不属于<span class="math inline">\(\mathcal{P_i}\)</span>的元素mask掉： <span class="math display">\[o_i=\sum\limits_{j\in\widetilde{\mathcal{P}}_i}\text{exp}(q_i\cdotk_j-m(j,\mathcal{P_i})-z(i,\mathcal{P_i}))v_j\\\text{where}\ m(j,\mathcal{P_i})=\left\{\begin{array}{lc}\infty&amp;\text{if}\ j\notin\mathcal{P_i}\\0&amp;\text{otherwise}\end{array}\right.\tag{3}\]</span> 如果mask了，就相当于在分母上除了一个无穷大，就等于0。</p><p>下面我们就能看LSH attention了，我们定义<span class="math inline">\(\mathcal{P_i}\)</span>为 <span class="math display">\[\mathcal{P_i}={j:h(q_i)=h(k_j)}\tag{4}\]</span> 也就是<span class="math inline">\(\mathcal{P_i}\)</span>包括所有与<span class="math inline">\(i\)</span>在同一个桶里的元素。</p><p>以上就是哈希attention的原理。然而如果仅仅这样操作还是会有问题的。</p><p>经过上述操作后，会得到<span class="math inline">\(b\)</span>个桶，一段文本的每个字的向量都会落到一个桶里，但潜在的问题是，每个桶里装的词向量数目是不均匀的，有的桶里多一些有的桶里少一些，甚至有可能某个桶里一个词向量都没有，这就让算法进行batch操作变得困难。为了解决这个问题，作者首先保证<span class="math inline">\(h(k_j)=h(q_j)\)</span>，也就是让每个词向量的query和key一定落在同一个桶中，通过设置<span class="math inline">\(k_j=\frac{q_j}{\Vertq_j\Vert}\)</span>（之前好像说了将query和key设成一样，不知道这里为什么又这样设，实际上后面的query和key是一样的）。然后将query按桶的序号进行排序，同一个桶内的query向量按照该词在句子中的位置进行排序。这样就定义了一种序号映射，<span class="math inline">\(i\mapsto s_i\)</span>，<span class="math inline">\(i\)</span>表示词在序列中的位置序号，<span class="math inline">\(s_i\)</span>表示排序后词所在的位置序号。将attention矩阵也经过这样排序后，在同一个桶内的词都会聚集在attention矩阵的对角线上，并且是连续的。然后我们就能进行batch操作了，定义一个长度<span class="math inline">\(m\)</span>，我们将排序后的query序列进行分块，每一块的长度就是<span class="math inline">\(m\)</span>。然后根据之前的定义，定义每个<span class="math inline">\(q_i\)</span>对应的 <span class="math display">\[\widetilde{\mathcal{P}}_i=\{ j:\lfloor \frac{s_i}{m}\rfloor - 1\ \le\lfloor\frac{s_j}{m}\rfloor \le \lfloor \frac{s_i}{m} \rfloor \}\tag{5}\]</span> 这个<span class="math inline">\(\widetilde{\mathcal{P}}_i\)</span>表示的是位置i的词能attentionto的所有词的集合，其中可能包含了不能attendto的词，需要用mask给去掉。这样一来对于所有的输入向量，我们都能用相同的代码计算attention矩阵了，每个输入向量不同的地方就是mask不同。在实验中，作者设置<span class="math inline">\(m=\frac{2l}{n_{buckets}}\)</span>，每个桶的平均大小为<span class="math inline">\(l/n_{buckets}\)</span>，设置m为其两倍，也就相当于左右各分一半，这里作者假设每个桶大小达到平均大小两倍的概率非常小。下图就是LSHattention的全过程。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220124174413183.png" alt="LSH attention过程与attention矩阵"><figcaption aria-hidden="true">LSHattention过程与attention矩阵</figcaption></figure><p>首先看左图，第一行是未排序的query=key，然后将每个位置的key分配到一个桶中，每个桶用不同颜色表示。分配完之后先通过桶序号进行排序，得到第三行的结果。然后将这段序列进行分块，每块大小为<span class="math inline">\(m\)</span>。最后进行在<span class="math inline">\(\widetilde{\mathcal{P}}_i\)</span>内进行attention操作。</p><p>接着是右图，我们看到a图是标准的attention矩阵，非常稀疏但是没有好好利用这些稀疏。b图是经过桶操作并且排序后的结果。c图让Q=K。d图进行分块操作。</p><h3 id="多轮lsh注意力">多轮LSH注意力</h3><p>由于hash操作是随机的，难免会出现错误情况，但出错的概率能通过多次hash操作减小。假设我们进行<span class="math inline">\(n_{rounds}\)</span>轮不同的hash操作<span class="math inline">\(\{h^{1},h^{2},h^{3},\dots,h^{n_{rounds}}\}\)</span>，那么最能得到： <span class="math display">\[\widetilde{\mathcal{P}}_i=\mathop{\cup}\limits_{r=1}^{n_{rounds}}\mathcal{P}_i^{(r)}\\\text{where} \ \mathcal{P}^{(r)}=\{ j:h^{(r)}(q_i)=h^{(r)}(q_j)\}\tag{6}\]</span></p><h2 id="可逆transformer">可逆Transformer</h2><p>上面的内容解决了Transformer模型的注意力机制复杂度高问题，这里的方法会进一步节省模型的内存消耗。可逆残差网络在上一篇笔记中已经介绍过了。实际上我是为了读懂这里的方法才去看那篇论文的，于是先写了那篇论文笔记作为铺垫。如果没看的话可以先看上一篇论文方法再来继续看这。我就不再解释一遍revnet的方法了，这里实际就直接将revnet的思想运用到了Transformer模型的残差结构中。我将公式再贴一遍，前向传播：<span class="math display">\[y_1=x_1+\mathcal{F}(x_2)\\y_2=x_2+\mathcal{G}(y_1)\tag{7}\]</span> 反向传播： <span class="math display">\[x_2=y_2-\mathcal{G}(y_1)\\x_1=y_1-\mathcal{F}(x_2)\tag{8}\]</span> 将<span class="math inline">\(\mathcal{F}\)</span>换成<span class="math inline">\(\text{Attention}\)</span>，<span class="math inline">\(\mathcal{G}\)</span>换成<span class="math inline">\(\text{FeedForward}\)</span>就得到了可逆的Transformer，作者将归一化层放到了残差结构中去，也就是<span class="math inline">\(\mathcal{F,G}\)</span>中。</p><h2 id="分块">分块</h2><p>由于前馈网络的每个激活单元是互不影响的，因此将输入的序列分块计算，计算完成后再合起来。假设我们将序列分成了<span class="math inline">\(c\)</span>块，那么输出为： <span class="math display">\[Y_2=[Y_2^{(1)};\dots;Y_2^{(c)}]=[X_2^{(1)}+\text{FeedForward}(Y_1^{(1)});\dots;X_2^{(c)}+\text{FeedForward}(Y_1^{(c)})]\tag{9}\]</span>事实上我感觉这对模型还是有修改的，因为这样就相当于每块共用了前馈层的参数，原始的Transformer每一块的参数是不同的，能表示更多信息，这样做就有信息损失了。</p><h2 id="总结">总结</h2><p>这篇论文结合了Transformer的信息表示优点与RevNet的节省内存的优点以及LSH方法的速度优点，诞生了Reformer。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021年度总结</title>
    <link href="/2022/01/02/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    <url>/2022/01/02/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>2021年算是人生中比较重要的一年吧，因为经历了保研等事情，自身成长了许多，并且自己的认识也提升了不少。</p><p>从年初开始的各项比赛，到年中的各种夏令营，到年末的迷茫。每个阶段都有着不同的心情与感受。</p><p>总的来说，自己还有很多缺点没有改掉</p><ul><li>不能计划好当日要做的事情</li><li>看手机总是停不下来</li><li>晚上总是喜欢熬夜</li><li>看书看着看着就会想去看一下手机。</li><li>总是因为某些事而开始暴躁</li><li>总是说脏话</li></ul><p>新的一年当然是希望把上面的缺点全部改掉，做一个全新的自己。</p><p>当然啦，新的一年也应该有新的一年的目标。</p><ul><li>和宝贝更好</li><li>减肥</li><li>看100篇论文，并做笔记</li><li>争取发一篇论文</li><li>机器学习基础打牢，做到手推公式</li></ul>]]></content>
    
    
    <categories>
      
      <category>年度总结</category>
      
    </categories>
    
    
    <tags>
      
      <tag>年度总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】The Reversible Residual Network</title>
    <link href="/2021/12/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91The-Reversible-Residual-Network/"/>
    <url>/2021/12/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91The-Reversible-Residual-Network/</url>
    
    <content type="html"><![CDATA[<p><strong><a href="https://proceedings.neurips.cc/paper/2017/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf">原文🔗</a></strong></p><h2 id="摘要">摘要</h2><p>深度残差神经网络推动了图像分类任务的SOTA，并且让又深又宽的网络性能变得更好了。然而内存消耗变成了网络的瓶颈，因为模型需要保存所有的激活单元，以便反向传播时计算梯度。本文提出了<strong>ReversibleResidualNetwork（RevNet）</strong>,ResNets的一种变体，能将每一层的激活单元通过后面的层构造出来。因此，每一层的绝大多数激活单元都不用存储在内存中，在反向传播的时候可以直接构造出来。本文在多个数据集（CIFAR-10,CIFAR0100,ImageNet）上证明了该方法的分类准确率与同等大小的ResNets是一样的，尽管该方法所需要的用来存储激活单元的内存大小与网络的深度是无关的。</p><h2 id="介绍">介绍</h2><p>在过去的几年中，深度卷积网络在多种视觉任务中都取得了快速的进展。对于大部分任务而言，SOTA的网络变得越来越深。比如，深度残差网络的结构在多个视觉领域都取得了SOTA的结果。其结构的关键是残差块（residualblock），它使得网络能直接传递信息，并且让反向传播不会出现梯度消失或梯度爆炸。这也使得我们能够训练上百层的网络，而这增加的深度取得了非常好的效果。</p><p>几乎现代的所有神经网络都是用反向传播法训练的。由于反向传播需要存储网络的激活单元，因此它占用的内存是与网络层数成正比的。<strong>然而，这就意味着随着网络变得越来越深，越来越宽，存储其中的激活单元将会占用非常多的内存</strong>，这也就导致了内存成为许多应用的瓶颈。<strong>减少激活单元占用的内存将会大大提高我们训练更深更宽的网络的能力</strong>。</p><p>本文提出了一种<strong>可逆的残差网络（Reversible ResidualNetworks，RevNets）</strong>，ResNets的一种<strong>可逆</strong>的变体，可逆的含义是，每一层的激活单元能通过之后的可逆层计算出来，这就使得我们不用存储每一层的激活单元在内存中，在方向传播的时候直接计算该位置的激活单元就行。当然，除了少量的不可逆的层需要保存在内存中，不能计算出来。这样设计的结果就是网络需要存储的激活单元的内存大小，是与网络的深度无关的，这通常也直接导致与传统的ResNets相比，网络的大小减少几个数量级。更令人惊讶的是，在作者的实验当中，这样做并没有导致明显的性能下降，几乎与原始的ResNets的效果是一模一样的。</p><h2 id="背景">背景</h2><h3 id="反向传播">1.反向传播</h3><p>反向传播是计算网络中参数对于损失函数的梯度的经典方法。它几乎被应用于所有的神经网络算法，并且对于具有自动微分功能的神经网络框架来说，它是一个理所应当的存在。由于为了实现节约内存，我们需要手动实现一部分的反向传播，因此先简要介绍回顾一下反向传播。</p><p>我们认为反向传播是一种反向自动求微分的方法。令<span class="math inline">\(v_1,v_2,...v_K\)</span>代表网络计算图<span class="math inline">\(\mathcal{G}\)</span>中的拓扑顺序的节点，其中<span class="math inline">\(v_k\)</span>代表最后的损失函数<span class="math inline">\(\mathcal{C}\)</span>。每一个节点代表的是计算图中的一个函数<span class="math inline">\(f_i\)</span>。反向传播会计算每个节点的<strong>总梯度</strong><span class="math inline">\(d\mathcal{C}/dv_i\)</span>，总梯度表示的是某个节点<span class="math inline">\(v_i\)</span>微小的变化对于<span class="math inline">\(\mathcal{C}\)</span>的影响，可以想象成导数的定义<span class="math inline">\(\lim\limits_{\Delta x\to\infty}\frac{f(x+\Delta x)- f(x)}{\Delta x}\)</span>，“总”的意思就是要考虑对<span class="math inline">\(v_i\)</span>的所有非直接影响，通过它之后的一系列节点<span class="math inline">\(v_k\)</span>，通俗一点就是说，对于节点<span class="math inline">\(v_i\)</span>的梯度，需要将后续节点对其产生的梯度全部加起来。为了避免表示混乱，后续使用<span class="math inline">\(\overline{v_i}=d\mathcal{C}/dv_i\)</span>来表示对<span class="math inline">\(v_i\)</span>的总梯度。</p><p>反向传播在计算图上以逆拓扑的顺序进行迭代计算。对于每个节点<span class="math inline">\(v_i\)</span>，运用如下的求导法则： <span class="math display">\[\overline{v_i}=\sum\limits_{j\in \text{Child(i)}}(\frac{\partialf_j}{\partial v_i})^T \overline{v_j}, \tag{1}\]</span> 其中<span class="math inline">\(\text{Child}(i)\)</span>表示<span class="math inline">\(v_i\)</span>的子节点，<span class="math inline">\(\partial f_j/\partialv_i\)</span>代表了表达式<span class="math inline">\(f_j\)</span>对节点<span class="math inline">\(v_i\)</span>的雅可比矩阵。上式其实就是简单的链式求导法则，求和代表的就是总梯度，也就是某个节点所有子节点对该节点的偏导数和，我来详细解释一下求和符号内的，对于该节点的导数为何是这样的形式。</p><p>高等数学中我们学的求导都是对一个标量进行求导，也就是自变量是一个数，而不是一个向量。而在深度学习中，我们知道输入模型的<span class="math inline">\(x\)</span>通常都是一个向量，非常高维度的向量，经过一个函数之后，输出的<span class="math inline">\(y\)</span>也是一个向量，与<span class="math inline">\(x\)</span>的维度一致，比如一个简单的线性函数<span class="math inline">\(y=wx+b\)</span>，参数为<span class="math inline">\(w,b\)</span>，输出输出都是一个向量，这时如果求<span class="math inline">\(y\)</span>对<span class="math inline">\(x\)</span>的导数，我们得到的就不是一个简单的<span class="math inline">\(dy/dx\)</span>了，我们得到的是一个雅可比矩阵：<span class="math display">\[\frac{\partial y}{\partial x}^T=\begin{pmatrix}\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partialx_2} &amp; \cdots &amp; \frac{\partial y_1}{\partial x_n}\\\frac{\partial y_2}{\partial x_1} &amp; \frac{\partial y_2}{\partialx_2} &amp; \cdots &amp; \frac{\partial y_2}{\partial x_n}\\\vdots &amp; \vdots &amp; \ddots &amp; \frac{\partial y_1}{\partialx_1}\\\frac{\partial y_n}{\partial x_1} &amp; \frac{\partial y_n}{\partialx_2} &amp; \cdots &amp; \frac{\partial y_n}{\partial x_n}\\\end{pmatrix}^T\]</span> 其中的<span class="math inline">\(n\)</span>就是向量的维度。我们将<span class="math inline">\(x\)</span>当作求导函数中的<span class="math inline">\(v_i\)</span>，将<span class="math inline">\(y\)</span>当作它的其中一个子节点<span class="math inline">\(v_j\)</span>，整个表达式<span class="math inline">\(y=wx+b\)</span>为两个节点之间的函数<span class="math inline">\(f_j\)</span>，那么根据链式求导法则，<span class="math inline">\(\overline{x} =\overline{y}\frac{dy}{dx}\)</span>，相当于上面求和符号中的某一项，这样看来是不是就非常清晰了，<span class="math inline">\(\overline{y}\)</span>相当于<span class="math inline">\(\overline{v_j}\)</span>。<span class="math inline">\(\overline{y}\)</span>的形式就是： <span class="math display">\[\overline{y}=\begin{pmatrix}dy_1\\dy_2\\\vdots\\dy_n\end{pmatrix}\]</span> 将上述两个矩阵相乘就能得到<span class="math inline">\(\overline{x}\)</span>了。</p><h3 id="深度残差网络">2.深度残差网络</h3><p>ResNets是由残差块组成的，具有下面的形式： <span class="math display">\[y=x+\mathcal{F}(x)，\tag{2}\]</span> 其中<span class="math inline">\(\mathcal{F}\)</span>，残差函数，通常是一个很浅的神经网络。ResNets能很好的解决梯度消失和梯度爆炸问题。由下图所示，分类问题的残差函数是由归一化层（BN），修正线性激活函数层（ReLU）与卷积层堆叠成的（C1代表<span class="math inline">\(1\times 1\)</span>的卷积核，C3代表<span class="math inline">\(3\times 3\)</span>的卷积核）。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220103003447551.png" alt="残差网络结构示意图"><figcaption aria-hidden="true">残差网络结构示意图</figcaption></figure><p>根据ResNets原文说明，我们有两种残差块的结构：基本的残差函数如上图右上部分，具有瓶颈的残差函数如上图的右下部分。何为具有瓶颈结构的卷积层呢？我们知道，一个普通的<span class="math inline">\(3\times3\)</span>卷积层会先将图像进行padding，然后进行卷积，以保证卷积前后图像的大小是不变的。而具有瓶颈结构的残差层，先使用<span class="math inline">\(1\times1\)</span>的卷积核，将图像缩小到某个大小，然后通过普通的<span class="math inline">\(3\times3\)</span>卷积核进行卷积，最后再使用一个<span class="math inline">\(1\times1\)</span>卷积核将图像放大到指定的大小，这样看起来就像是一个瓶颈一样，先大后小再大。上述操作可以通过下面的式子进行表示。<span class="math display">\[a(x)=\text{ReLU(BN(}x\text{))}\\c_k(x)=Conv_{k\times k}(a(x))\\\\Basic(x)=c_3(c_3(x))\\Bottleneck(x)=c_1(c_3(c_1(x)))\tag{3}\]</span></p><h3 id="可逆结构">3.可逆结构</h3><p>我们先介绍可逆的残差块。可逆的残差网络是由一系列可逆块组成，可逆块的概念类比ResNets的残差块。可逆块的定义如下：<span class="math display">\[y_1=x_1\\y_2=x_2+\mathcal{F}(x_1)\tag{4}\label{eq4}\]</span> 其中<span class="math inline">\(x_1,x_2\)</span>是每一层输入的拆分，具体怎么拆分需要看使用的是什么方法，是卷积还是普通的全连接网络。</p><p>然而由于上式具有某些性质，不能表达所有的函数，经过改进后的表达式变成了：<span class="math display">\[y_1=x_1\\y_2=x_2\odot exp(\mathcal{F}(x_1)) + \mathcal{G}(x_1)\tag{5}\]</span> 其中，<span class="math inline">\(\odot\)</span>表示的是哈达玛积或者说是点积，也就是每个位置相乘。</p><h2 id="方法">方法</h2><p>下面我们正式介绍可逆残差网络。可逆残差网络就是残差网络的一种变体，能通过后面的层计算当前层的激活单元。我们将要讨论如何在线重构激活单元，以减少存储激活单元需要的内存。</p><h3 id="可逆残差网络">1.可逆残差网络</h3><p>可逆残差网络是由一系列的可逆残差块组成，我们下面给出定义。我们必须将每一层的单元分割成两部分，分别表示为<span class="math inline">\(x_1,x_2\)</span>；在本文的剩余部分，我们假设这是通过分割通道来完成的，也就是说如果有32个通道，那么分一半当作<span class="math inline">\(x_1\)</span>，另一半当作<span class="math inline">\(x_2\)</span>，至于为什么这么做呢？因为作者发现这样做效果非常好...</p><p>每一个可逆块都接受一对输入<span class="math inline">\((x_1,x_2)\)</span>并且产生一对输出<span class="math inline">\((y_1,y_2)\)</span>，根据公式<span class="math inline">\(\eqref{eq4}\)</span>定义的成对加法规则得到的启发，我们定义如下结构：<span class="math display">\[y_1=x_1+\mathcal{F}(x_2)\\y_2=x_2+\mathcal{G}(y_1)\tag{6}\]</span> 其中函数<span class="math inline">\(\mathcal{F,G}\)</span>类似于残差结构中的函数，可以自己定义。</p><p>那么，每一层的激活单元可以通过以下式子进行重构： <span class="math display">\[x_2=y_2-\mathcal{G}(y_1)\\x_1=y_1-\mathcal{F}(x_2)\tag{7}\]</span>需要注意的是，不像残差块，可逆块的卷积步长必须为1，否则会丢失信息，从而导致网络变得不可逆。标准的网络层通常只有少量网络层具有大的步长。如果我们要定义类似于ResNet的结构，那么我们必须显式存储不可逆的网络层。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220103112919345.png" alt="前向传播与方向传播流程"><figcaption aria-hidden="true">前向传播与方向传播流程</figcaption></figure><h3 id="不存储激活单元的反向传播">2.不存储激活单元的反向传播</h3><p>为了深入理解反向传播的程序，我们可以重写一下前向和反向的计算公式，如下：<span class="math display">\[forward:z_1=x_1+\mathcal{F}(x_2)\quad y_2=x_2+\mathcal{G}(z_1)\quady_1=z_1\\\\backward:z_1=y_1\quad x_2=y_2-\mathcal{G}(z_1)\quadx_1=z_1-\mathcal{F}(x_2)\tag{8}\]</span> 尽管<span class="math inline">\(z_1=y_1\)</span>，但两个变量表示计算图中的不同的节点，因此它们两个的总梯度<span class="math inline">\(\overline{z_1},\overline{y_1}\)</span>是不一样的。因为<span class="math inline">\(\overline{z_1}\)</span>还受到了<span class="math inline">\(y_2\)</span>的间接影响，而<span class="math inline">\(\overline{y_1}\)</span>则不然。在反向传播的过程中，我们有的是激活单元<span class="math inline">\((y_1,y_2)\)</span>和它们的总梯度<span class="math inline">\((\overline{y_1},\overline{y_2})\)</span>，我们希望求出来的是该单元的输入<span class="math inline">\((x_1, x_2)\)</span>以及它们的总梯度<span class="math inline">\(\overline{x_1},\overline{x_2}\)</span>，以及函数<span class="math inline">\(\mathcal{F,G}\)</span>的参数的总梯度。再结合公式(8)，我们就能得到反向传播的更新过程：</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20220103112745581.png" alt="可逆残差块反向传播更新步骤"><figcaption aria-hidden="true">可逆残差块反向传播更新步骤</figcaption></figure><p>怎么理解这个步骤呢？下面我画一张图来帮助理解这个更新步骤。公式的2~4步就不用解释了，就是直接反向求<span class="math inline">\(x\)</span>的赋值操作。我们主要解释一下梯度的计算步骤。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/RevNet-(1).1dietdx41x0g.webp" alt="反向传播流程图"><figcaption aria-hidden="true">反向传播流程图</figcaption></figure><p>上图中黑色的箭头表示的前线传播，紫色箭头表示反向传播。可以看到<span class="math inline">\(z_1\)</span>有两个指出的箭头，一个指向<span class="math inline">\(y_1\)</span>，一个指向<span class="math inline">\(\mathcal{G}\)</span>，那么反向传播的时候，这两个箭头将会反着对<span class="math inline">\(z_1\)</span>产生梯度，我们求的是总梯度，因此需要将两部分梯度相加，得到总梯度。由公式的第5行可以看出来就是这两部分的梯度相加，赋值给<span class="math inline">\(\overline{z_1}\)</span>，<span class="math inline">\(\frac{\partial y_2}{\partialz_1}=\overline{y2}\frac{\partial g}{\partialz_1}\)</span>，这个公式就是这样得到的。<span class="math inline">\(x_1\)</span>的总梯度通过上图也能很好的理解，就由读者自己推一下就行了。</p><p>通过重复执行上述的算法，我们就能在只有<span class="math inline">\(y\)</span>和<span class="math inline">\(\overline{y}\)</span>的情况下执行反向传播。但总的来说，在一个残差网络里并不是所有层都可逆的，比如下采样层就不可逆，这时候我们需要显示的将激活单元存储在内存中了。但是残差网络通常都包含大量的残差层和少量的下采样层，如果我们模仿经典的残差神经网络来设计结构的话，那少量的下采样层就可以不用在乎了，因为它与网络的深度是无关的。</p><h3 id="关于计算量的问题">3.关于计算量的问题</h3><p>众所周知，鱼和熊掌不可兼得。本方法在节约了内存的同时，一定是会增加计算量的。一般来说，对于一个具有N层的网络，前向传播和方向传播大约分别会进行N次和2N次加乘操作。对于RevNet而言，在方向传播的过程中，残差层的激活单元每次都需要被重新计算一次，因此，RevNet的方向传播大约会进行4N次操作，或者说比普通的残差曾多33%。然而在实验中发现，前向传播和反向传播的开销基本上是一样的，因此在这种情况下，RevNets的计算量更接近50%。（我也不知道是怎么计算出来的）</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image//image-20220103123836067.png" alt="image-20220103123836067"><figcaption aria-hidden="true">image-20220103123836067</figcaption></figure><h2 id="总结">总结</h2><p>本文主要介绍了RevNets，一种不用存储激活单元的神经网络结构。并且作者发现这种结构在节省内存的同时几乎对网络的性能没有影响。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>Resnet</tag>
      
      <tag>内存优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Longformer：The Long-Document Transformer</title>
    <link href="/2021/12/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Longformer%EF%BC%9AThe-Long-Document-Transformer/"/>
    <url>/2021/12/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Longformer%EF%BC%9AThe-Long-Document-Transformer/</url>
    
    <content type="html"><![CDATA[<p><strong><a href="https://arxiv.org/abs/2004.05150">原文🔗</a></strong></p><h2 id="摘要">摘要</h2><p>基于Transformer的模型不能很好的处理长文本任务，原因是它的时间空间复杂度是文本长度的二次方。为了解决这个限制，作者提出了新的Transformer模型——Longformer，其复杂度是基于文本长度线性的，因此能更容易的去处理上千个Token或更长的文本。</p><p>Longformer的attention机制能完全代替标准attention机制，它结合了局部滑动窗口的attention与任务驱动的全局attention。Longformer的效果在WikiHop数据集和TriviaQA数据集的效果超过了RoBERTa模型，并且达到了新的SOTA。</p><p>作者还提出了基于Longformer的Encoder-Decoder模型（LED），来处理文本生成任务，并且取得了良好的效果。</p><h2 id="longformer实现细节">Longformer实现细节</h2><p>原始的Transformer模型attention部分的的时间与空间复杂度是<span class="math inline">\(O(n^2)\)</span>，其中<span class="math inline">\(n\)</span>是文本的长度。为了解决这个挑战，作者将原始的满的attention矩阵稀疏化，通过一种定义好的“注意力模式（Attentionpattern）”，指定输入中哪些位置的token相互关注（attend）。下面介绍具体的注意力模式有哪些。</p><p><strong>滑动窗口</strong></p><p>由于局部的上下文是非常重要的，因此注意力模式在每个token附近使用了固定大小的attentionwindow，然后使用多层这样的模型，就能获得非常大的感知野。其中最顶层能感受到句子的所有位置，并且有能力输出包含句子所有位置信息的整个句子的表示，就像CNN一样。</p><p>将窗口的大小固定为<span class="math inline">\(w\)</span>，每个token能够attend自己两边<span class="math inline">\(\frac{1}{2}w\)</span>个token，其计算复杂度就是<span class="math inline">\(O(n\times w)\)</span>。由于<span class="math inline">\(w\)</span>远小于<span class="math inline">\(n\)</span>，因此复杂度是与句子长度<span class="math inline">\(n\)</span>呈线性关系的。在一个具有 <span class="math inline">\(l\)</span>层的transformer模型中，最顶层的感受野大小是 <span class="math inline">\(l\times w\)</span>（假设每一层的<span class="math inline">\(w\)</span>是固定的）。根据不同的应用场景，在每一层使用不同大小的<span class="math inline">\(w\)</span>可能有助于平衡模型的效率和表示能力，若<span class="math inline">\(w\)</span>越大，则每个token需要attend的数量越大，表示能力也越强，但计算复杂度也变大，反之亦然。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211221134942417.png" alt="每一层窗口的视野"><figcaption aria-hidden="true">每一层窗口的视野</figcaption></figure><p><strong>膨胀的滑动窗口</strong></p><p>为了进一步扩大感受野但不增加计算量，滑动窗口能被”膨胀“。这与膨胀的CNN非常类似，使窗口有一个大小为<span class="math inline">\(d\)</span>的膨胀间隔，也就是相当于将原本的连续的窗口，中间增加间隔。假设每一层的<span class="math inline">\(w\)</span>和<span class="math inline">\(d\)</span>是固定的，那么感受野的大小就膨胀成了<span class="math inline">\(l \times d \timesw\)</span>，这样就能让视野扩大到上万个token，即使 <span class="math inline">\(d\)</span> 是个很小的值。</p><p><strong>全局Attention</strong></p><p>在本方法中，滑动窗口和膨胀的attention机制对于学习特定任务的表示还不够灵活。因此，作者在输入的某些预先选定的位置添加了全局attention。重要的是，这些全局的attention是对称的，也就是说：全局attention位置的token会attend句子中的所有token，反过来，句子中的所有token都会attend那些具有全局attention特性的token。</p><p>例如，对于分类任务，全局attention用在了[CLS]的位置上，而对于QA任务，全局attention用在了所有的问题token上。</p><p>由于这一类具有全局attention性质的token相对于<span class="math inline">\(n\)</span>来说非常小，而且与<span class="math inline">\(n\)</span>是不相关的，因此结合了局部attention和全局attention的复杂度还是<span class="math inline">\(O(n)\)</span>。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211221140701806.png" alt="各种方法的attention矩阵"><figcaption aria-hidden="true">各种方法的attention矩阵</figcaption></figure><p><strong>全局Attention的线性投影</strong></p><p>给定了线性投影矩阵<span class="math inline">\(Q,K,V\)</span>，原始的Transformer模型计算attention分数公式为：<span class="math display">\[Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span> 在Longformer中，使用了两组投影。第一组<span class="math inline">\(Q_s,K_s,V_s\)</span>用来计算滑动窗口的attention分数，第二组<span class="math inline">\(Q_g,K_g,V_g\)</span>用来计算全局的attention分数。额外的的那个投影矩阵对不同类型的attention的建模提供了灵活性，并且证明了它对下游任务有着好的表现是非常关键的。<span class="math inline">\(Q_g,K_g,V_g\)</span>是用与<span class="math inline">\(Q_s,K_s,V_s\)</span>对应的值初始化的。</p><h2 id="自回归语言模型">自回归语言模型</h2><p>自回归，或者从左到右的的语言模型被宽泛的定义为给定前面的token/characters，预测后续一个token/characters的概率分布。这在自然语言处理中是一个最基本的任务，并且之前很多使用transformer来处理长文本的模型都靠这个任务来评估效果。本文也不例外。</p><p><strong>Attention Pattern</strong></p><p>在自回归语言模型中作者使用了膨胀的滑动窗口矩阵。作者在每一层都使用了不同的窗口大小。具体来说，在底层使用小的窗口大小，并且随着层数上升，增大窗口的大小。这就使得顶层的网络能学到高层的文本表示，因为底层的网络能获取到局部信息。此外，这样做还能平衡模型的效率和表现。</p><p><strong>实验</strong></p><p>作者实验时使用了阶梯式的训练步骤，在训练过程中慢慢增加窗口的大小和输入文本的长度。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211221150404796.png" alt="实验结果"><figcaption aria-hidden="true">实验结果</figcaption></figure><h2 id="longformer-encoder-decoderled">Longformer-Encoder-Decoder(LED)</h2><p>原始的Transformer是Encoder-Decoder结构的模型，目的是为了解决seq2seq的任务，比如摘要和翻译。然而这些模型都不能很好的接收长文本的输入。</p><p>为了解决长文本的seq2seq任务，作者提出了Longformer的变体，包含了与Transformer一样的encoder,decoder结构，唯一不同的在于将原始encoder中的的fullattention改为了Longformer中更高效的local+global的attention模式。decoder对encoder的全部输入和之前的decoder输出使用了fullattention矩阵。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211221151623932.png" alt="LED效果分析"><figcaption aria-hidden="true">LED效果分析</figcaption></figure><h2 id="总结">总结</h2><p>本文提出了Longformer，一种基于transformer的模型，能够处理长文本，这就使得它能更加方便的处理某些任务，不需要像原始方法一样将长文本截断，也不需要复杂的结构来结合这些截断的文本信息。</p><p>Longformer使用了一种attention机制，能结合全局和局部的信息，并且能与输入的长度呈线性复杂度。Longformer在很多数据集上都取得了SOTA的效果，在WiKiHop和TriviaQA上还超过了Roberta，达到了新的SOTA。最后还提出了LED，一种Longformer的变体，能处理seq2seq任务，并且在arXiv长文本摘要任务上取得了好的效果。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文笔记</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Pytorch笔记】Pytorch之scatter函数用法</title>
    <link href="/2021/12/18/%E3%80%90Pytorch%E7%AC%94%E8%AE%B0%E3%80%91Pytorch%E4%B9%8Bscatter%E5%87%BD%E6%95%B0%E7%94%A8%E6%B3%95/"/>
    <url>/2021/12/18/%E3%80%90Pytorch%E7%AC%94%E8%AE%B0%E3%80%91Pytorch%E4%B9%8Bscatter%E5%87%BD%E6%95%B0%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>Pytorch中的函数后加上“_”表示在原始tensor的基础上操作，改变原始tensor，若是torch.的函数，则不会改变原始tensor，而是会生成一个新的tensor，因此<code>torch.scatter()</code>和<code>tensor.scatter_()</code>函数的区别就在于是否改变原tensor。下面我们就通过<code>scatter_()</code>函数来介绍该函数作用。</p><p><code>Tensor.scatter_</code>(<em><code>dim</code></em>,<em><code>index</code></em>, <em><code>src</code></em>,<em><code>reduce=None</code></em>) → <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></p><p>我们首先通过阅读<a href="https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_">官方文档</a>来看看这个函数的作用是什么。翻译过来主要意思就是，将<code>src</code>中的元素，按照index的顺序放入<code>dim</code>维度中。下面还举了一个3-D的例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">self[index[i][j][k]][j][k] = src[i][j][k]  <span class="hljs-comment"># if dim == 0</span><br>self[i][index[i][j][k]][k] = src[i][j][k]  <span class="hljs-comment"># if dim == 1</span><br>self[i][j][index[i][j][k]] = src[i][j][k]  <span class="hljs-comment"># if dim == 2</span><br></code></pre></td></tr></table></figure><p>如果你能一眼看出这个是怎么做的，那就可以退出不用看了。这三行表示的是在三个不同维度上对将src写到self函数中的效果。其中最关键的位置是<code>index[i][j][k]</code>，因为它决定了<code>src[i][j][k]</code>放进self中的位置。因此，<code>src</code>每个维度都必须&gt;=<code>index</code>的每个维度，因为每个<code>index[i][j][k]</code>都对应着一个<code>src[i][j][k]</code>。</p><p>我通过二维的例子来进行解释。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment"># tensor([[0., 0., 0., 0., 0.],</span><br><span class="hljs-comment">#         [0., 0., 0., 0., 0.],</span><br><span class="hljs-comment">#  [0., 0., 0., 0., 0.]])</span><br><br>index = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>]])<br><span class="hljs-comment"># tensor([[1, 0, 2, 1, 1],</span><br><span class="hljs-comment">#         [0, 1, 1, 0, 2]])</span><br><br>src = torch.randn((<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment"># tensor([[-0.4014, -0.7197,  1.1508,  1.1462, -1.0964],</span><br><span class="hljs-comment">#         [ 1.0820, -2.2081,  0.6046,  0.3120, -0.1554]])</span><br><br>x = x.scatter_(dim=<span class="hljs-number">0</span>, index=index, src=src)<br><span class="hljs-comment"># tensor([[ 1.0820, -0.7197,  0.0000,  0.3120,  0.0000],</span><br><span class="hljs-comment">#         [-0.4014, -2.2081,  0.6046,  1.1462, -1.0964],</span><br><span class="hljs-comment">#         [ 0.0000,  0.0000,  1.1508,  0.0000, -0.1554]])</span><br></code></pre></td></tr></table></figure><p>上面怎么得到的呢？你可以按照下面的方式想，就能很容易直观得到结果。</p><p>我们先将<code>index</code>每个位置上的数与<code>src</code>中每个位置上的数对应起来，如下图</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211217163352654.png" alt="index与src的对应关系"><figcaption aria-hidden="true">index与src的对应关系</figcaption></figure><p>这样，每个<code>index</code>的位置，都对应着相应位置一个<code>src</code>的数。我们先在脑子中建立这样一个对应关系的印象，下面会用到这个对应关系。</p><p>通过给的示例<code>self[index[i][j][k]][j][k] = src[i][j][k]</code>可以发现<code>src</code>中的<code>!dim</code>维度的索引（在这个例子中<code>dim=0</code>，<code>!dim</code>列就是第<code>1</code>维度），与<code>x</code>中对应维度的索引一一对应的，<strong>也就是说<code>src</code>第<code>j</code>列的数字，一定是放到<code>x</code>的第<code>j</code>列</strong>，那么你将<code>src</code>想成一列一列的数</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211217164211956.png" alt="按照列划分src"><figcaption aria-hidden="true">按照列划分src</figcaption></figure><p>每一列的数，都要放到<code>x</code>的对应列中去，我们来看结果是不是这样的</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211217164657790.png" alt="scatter之后的x"><figcaption aria-hidden="true">scatter之后的x</figcaption></figure><p>可以看到，经过处理后，<code>x</code>的每一列数字，就是对应到<code>src</code>每一列数字上，只是在这一列上的顺序不同。那么这个顺序怎么确定呢？这就要用到我们上面画的对应关系了，<code>src</code>对应位置的<code>index</code>作为索引，放到<code>x</code>对应列上的位置去，就得到了最终结果。也就是说，<strong><code>index</code>的每一列都是作为<code>src</code>对应列的顺序存在的</strong>。</p><p><strong>最后我们整合一遍，首先看参数<code>dim=0</code>，说明除了第<code>0</code>维度，在其他维度上，<code>src</code>与<code>x</code>的索引是一致的，具体到我们的例子里来说，就是<code>src</code>的每一列与<code>x</code>的每一列位置是对应的，要将<code>src</code>每一列元素，填充到<code>x</code>的每一列中去。但对应的列的填充顺序是什么呢？当然就是看<code>index</code>上，每一列的数字了。</strong></p><p>下面我们再来举一个<code>dim=1</code>的例子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment"># tensor([[0., 0., 0., 0., 0.],</span><br><span class="hljs-comment">#         [0., 0., 0., 0., 0.],</span><br><span class="hljs-comment">#  [0., 0., 0., 0., 0.]])</span><br><br>index = torch.tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>]])<br><span class="hljs-comment"># tensor([[0, 1, 3, 2, 4],</span><br><span class="hljs-comment">#         [1, 3, 4, 0, 2]])</span><br><br>src = torch.randn((<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment"># tensor([[ 0.2267, -1.5383, -1.1069, -1.3450, -0.5601],</span><br><span class="hljs-comment">#         [ 0.5058,  1.3454,  0.1888, -0.0366, -1.2225]])</span><br><br>x = x.scatter_(dim=<span class="hljs-number">1</span>, index=index, src=src)<br></code></pre></td></tr></table></figure><p>大家可以先思考一下这个结果是什么？</p><p>按照刚才的方法，首先由于<code>dim=1</code>，因此对于<code>!dim=1</code>的维度，<code>src</code>与<code>x</code>的索引是一致的，在本例中也就是行，<code>src</code>中每行元素应该填充到<code>x</code>的每一行去，因此，<code>x</code>的第三行肯定是空的，因为<code>src</code>只有两行数。而这两行数应该怎么填充呢？当然就是将<code>index</code>中对应行的数当作索引，把<code>src</code>中的数按照索引放到<code>x</code>中去啦。第一行是<code>[ 0.2267, -1.5383, -1.1069, -1.3450, -0.5601]</code>，索引为<code>[0, 1, 3, 2, 4]</code>，按照索引对第一行排序，<code>0.2267</code>放第<code>0</code>个位置，<code>-1.5383</code>放第<code>1</code>个位置，<code>-1.1069</code>放第<code>3</code>个位置...得到<code>[ 0.2267, -1.5383, -1.3450, -1.1069, -0.5601]</code>，第二行自己算算吧，最后结果就是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[ <span class="hljs-number">0.2267</span>, -<span class="hljs-number">1.5383</span>, -<span class="hljs-number">1.3450</span>, -<span class="hljs-number">1.1069</span>, -<span class="hljs-number">0.5601</span>],<br>        [-<span class="hljs-number">0.0366</span>,  <span class="hljs-number">0.5058</span>, -<span class="hljs-number">1.2225</span>,  <span class="hljs-number">1.3454</span>,  <span class="hljs-number">0.1888</span>],<br>        [ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>]])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>pytorch笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>十一月计划及完成情况</title>
    <link href="/2021/11/30/%E5%8D%81%E4%B8%80%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/"/>
    <url>/2021/11/30/%E5%8D%81%E4%B8%80%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/</url>
    
    <content type="html"><![CDATA[<p>11月1日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>打毛线</p><p>打了四圈</p></li><li><p><input type="checkbox" disabled checked>西瓜书——半监督学习</p><p>计算学习理论没看懂跳过了，半监督学习中的图半监督学习没看懂，其他都大概看懂了</p></li><li><p><input type="checkbox" disabled checked>信号与系统继续学习</p></li></ul><hr><p>11月2日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>GBDT和XGBoost</p><p>GBDT看懂了，XGBoost看懂了一点，还有很多细节没搞懂，明天也可以继续深挖细节</p></li><li><p><input type="checkbox" disabled checked>信号与系统继续学习</p><p>有一点没太学明白，明天要看书复习一遍</p></li><li><p><input type="checkbox" disabled checked>跑步</p><p>一公里5分06。。。好垃圾</p></li><li><p><input type="checkbox" disabled checked>打毛线</p></li></ul><hr><p>11月3日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>XGBoost</p><p>完全疏通，很爽</p></li><li><p><input type="checkbox" disabled checked>体测</p><p>跳远2.24m、引体向上3、一千米4：40</p></li><li><p><input type="checkbox" disabled>信号与系统复习</p><p>下午体测，晚上继续看了会XGBOOST，就没看，明天开始复习</p></li></ul><p>最近还要开始深度学习课程了，先把李宏毅的深度学习看完，代码也要开始练习了，有能力还能看斯坦福的CS224N</p><hr><p>11月4日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>信号与系统复习</p></li><li><p><input type="checkbox" disabled checked>西瓜书——概率图模型</p><p>开了个头，明天继续</p></li><li><p><input type="checkbox" disabled checked>打毛线</p></li></ul><hr><p>11月5日</p><ul class="task-list"><li><input type="checkbox" disabled checked>隐马尔可夫模型吃透</li><li><input type="checkbox" disabled checked>打毛线</li></ul><hr><p>11月6日</p><ul class="task-list"><li><input type="checkbox" disabled checked>条件随机场的定义及表示形式</li></ul><hr><p>11月7日</p><ul class="task-list"><li><input type="checkbox" disabled checked>CRF——最大熵模型</li></ul><p>​ 还是很模糊明天看博客</p><hr><p>11月8日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>最大熵模型与CRF</p><p>最大熵模型基本完成，只是最后的IIS推导还没看明白，CRF最后带入求解也没看懂，下次再看吧</p></li></ul><hr><p>11月9日</p><ul class="task-list"><li><input type="checkbox" disabled checked>信号与系统学习+复习</li></ul><hr><p>11月10日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>深度学习——李宏毅</p><p>把HW1重新做了一遍理解了一遍，课程学了一个章节</p></li></ul><p>明天要开始复习现代企业管理了，有时间还要再继续改进一下HW1，把误差再降低一些</p><hr><p>11月11日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习（0~1章）</li></ul><hr><p>11月12日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习（2章）</li></ul><hr><p>11月13日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>现代企业管理复习（3~4章）</p></li><li><p><input type="checkbox" disabled>信号与系统学习</p><p>学了三节视频，尽早把第四章学完，还有把ML第一个作业继续调一下，不然总感觉心里有块石头吊着，每天都很不舒服</p></li></ul><hr><p>11月14日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>现代企业管理复习（5章）</p></li><li><p><input type="checkbox" disabled checked>信号与系统学习</p></li><li><p><input type="checkbox" disabled checked>HW1调试</p></li></ul><hr><p>11月15日</p><ul class="task-list"><li><input type="checkbox" disabled checked>HW1调试</li><li><input type="checkbox" disabled>现代企业管理复习</li></ul><hr><p>11月16日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习</li><li><input type="checkbox" disabled checked>信号与系统学习</li><li><input type="checkbox" disabled checked>HW2调试</li></ul><hr><p>11月17日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习</li></ul><hr><p>11月18日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习</li><li><input type="checkbox" disabled checked>一拳超人漫画看完</li></ul><hr><p>11月19日</p><ul class="task-list"><li><input type="checkbox" disabled checked>现代企业管理复习</li><li><input type="checkbox" disabled checked>政审表</li><li><input type="checkbox" disabled checked>宝贝作业修改</li><li><input type="checkbox" disabled checked>毕业设计询问</li><li><input type="checkbox" disabled>打围巾结束</li></ul><p>​ 预测失误，1m2根本不够长，还需要继续努力</p><ul class="task-list"><li><p><input type="checkbox" disabled>宝贝小作文</p><p>写了一半</p></li></ul><hr><p>11月20日</p><ul class="task-list"><li><input type="checkbox" disabled checked>形式与政策</li><li><input type="checkbox" disabled checked>小作文写信</li></ul><p>明天开始继续深度学习，还有毕业论文相关的论文开始看</p><hr><p>11月21日</p><ul class="task-list"><li><input type="checkbox" disabled checked>transformer学习</li></ul><hr><p>11月22日</p><ul class="task-list"><li><input type="checkbox" disabled checked>BERT学习</li><li><input type="checkbox" disabled checked>论文阅读</li></ul><hr><p>11月23日</p><ul class="task-list"><li><input type="checkbox" disabled checked>论文阅读</li></ul><hr><p>11月24日</p><ul class="task-list"><li><input type="checkbox" disabled checked>论文阅读</li></ul><hr><p>11月25日</p><ul class="task-list"><li><input type="checkbox" disabled checked>论文阅读</li></ul><hr><p>11月26日</p><ul class="task-list"><li><input type="checkbox" disabled checked>组会</li></ul><hr><p>11月27日</p><p>11月28日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>进击的巨人</p></li><li><p><input type="checkbox" disabled checked>休息</p></li></ul><hr><p>11月29日</p><ul class="task-list"><li><input type="checkbox" disabled checked>HW4，attention看完</li></ul><p>看了一天的这个作业代码，训练一次要两个小时，根本没办法写。一晚上看pad_sequences没看明白，到宿舍看明白了一些，明天要写一篇博客记录一下，确实有点难理解。还有collate_fn没理解，明天再看几篇博客理解理解。下一步还要看attention源码，pytorch也要多熟悉了。</p><hr><p>11月30日</p><p>问题：现在基本上都是在看别人的项目代码，自己还没有试着写过代码，看着别人的代码就觉得很有逻辑，但是如果自己写起来估计就不太写得好，怎么办？</p><ul class="task-list"><li><input type="checkbox" disabled checked>attention is all you need论文阅读</li><li><input type="checkbox" disabled checked>collate_fn作用</li><li><input type="checkbox" disabled checked>pytorch的attention源码阅读</li></ul><p>​ 看了但没完全看懂，明天再试着继续看一下，还有论文conformer也看看</p><hr><div class="note note-info">            <p>这个月计划完成的还行，中间有几天看动漫看的着迷了，从早看到玩，需要改进。还有要去锻炼了，体检都说我超重了/(ㄒoㄒ)/~~。</p><p>下个月要继续pytorch的学习使用，还有李宏毅深度学习看完来。待学习的任务还有CS224N、线性代数基础书、西瓜书很多公式的推导、统计学习方法学习、深度学习代码编写。</p>          </div>]]></content>
    
    
    <categories>
      
      <category>计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>十月计划及完成情况</title>
    <link href="/2021/11/01/%E5%8D%81%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/"/>
    <url>/2021/11/01/%E5%8D%81%E6%9C%88%E8%AE%A1%E5%88%92%E5%8F%8A%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5/</url>
    
    <content type="html"><![CDATA[<p>10月12日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——决策树</p><div><font color="red">多变量决策树还未理解</font></div></li><li><p><input type="checkbox" disabled checked>信号与系统学习</p></li><li><p><input type="checkbox" disabled checked>跑步三公里</p></li></ul><hr><p>10月13日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——神经网络</p><p>还剩最后的神经网络分类没看完</p></li><li><p><input type="checkbox" disabled checked>西瓜书——LDA</p><div><font color="red">拉格朗日乘子法还没掌握</font></div></li><li><p><input type="checkbox" disabled>信号与系统学习与复习</p><div><font color="red">LDA看的久了一些，就没时间来看了</font></div></li><li><p><input type="checkbox" disabled checked>宝贝的信写完</p></li></ul><hr><p>10月14日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——神经网络</p><p>神经网络结束，朴素贝叶斯看完</p></li><li><p><input type="checkbox" disabled checked>信号与系统学复习与学习</p><p>第一章复习完成，第二章学习遇到问题，明天继续啃</p></li></ul><hr><p>10月15日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——SVM</p><p>SMO算法还没理解透，下次继续理解</p></li><li><p><input type="checkbox" disabled checked>拉格朗日乘子法</p></li><li><p><input type="checkbox" disabled>信号与系统学习</p></li></ul><hr><p>10月16日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——贝叶斯分类器</p><p>朴素贝叶斯看完了</p></li><li><p><input type="checkbox" disabled checked>信号与系统学习</p></li></ul><hr><p>10月17日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——贝叶斯分类器</p><p>贝叶斯分类器结束，EM算法学习也结束</p></li><li><p><input type="checkbox" disabled>跑步三公里</p></li></ul><hr><p>10月18日：</p><ul class="task-list"><li><input type="checkbox" disabled checked>西瓜书——集成学习开头</li><li><input type="checkbox" disabled checked>EM算法复习理解一下</li><li><input type="checkbox" disabled checked>信号与系统学习</li></ul><hr><p>10月19日：</p><ul class="task-list"><li><input type="checkbox" disabled checked>西瓜书——集成学习</li><li><input type="checkbox" disabled checked>信号与系统复习</li></ul><hr><p>10月20日：</p><ul class="task-list"><li><input type="checkbox" disabled>西瓜书——聚类</li><li><input type="checkbox" disabled checked>信号与系统学习</li><li><input type="checkbox" disabled checked>机器人汇报PPT</li></ul><hr><p>10月21日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>机器人改进</p><p>机器人优化结束，还剩实验报告没写</p></li><li><p><input type="checkbox" disabled checked>信号与系统第二章学习结束</p><p>学习与复习结束，明天开始第三章</p></li><li><p><input type="checkbox" disabled checked>西瓜书——聚类</p><p>看了一部分，明天结束</p></li></ul><hr><p>10月22日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书聚类结束</p><p>高斯混合模型和EM算法结束，花了很多时间，导致没时间看信号与系统</p></li><li><p><input type="checkbox" disabled>信号与系统第三章开始学习</p></li><li><p><input type="checkbox" disabled checked>跑步四公里</p></li></ul><hr><p>10月23日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>机器人博客撰写</p><p>花了半个上午+一个下午+半个晚上，超出预期</p></li><li><p><input type="checkbox" disabled checked>信号与系统第三章开始学习</p><p>刚开了个头，明天继续</p></li><li><p><input type="checkbox" disabled>西瓜书——降维</p><p>没空看啦，明天再看吧</p></li></ul><hr><p>10月24日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>信号与系统继续学习</p><p>学了一点</p></li><li><p><input type="checkbox" disabled>西瓜书——降维</p><p>心血来潮更新了我和宝贝的博客，还搭了一个私有云盘花了一天时间，就没搞其他的</p></li></ul><hr><p>10月25日：</p><ul class="task-list"><li><p><input type="checkbox" disabled>搭邮件服务器</p><p>一上午没成功。。。</p></li></ul><p>其他啥都没干，就当放假</p><hr><p>10月26日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>信号与系统第三章学习结束</p></li><li><p><input type="checkbox" disabled>西瓜书——降维</p><p>又没完成。。一晚上又去弄WSL去了，明天不能这么下去了，该学什么就学什么，打毛线都还没学，时间要利用起来，不能这么浪费了</p></li></ul><hr><p>10月27日：</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——降维，一定要开始了</p><p>KPCA还没看明白，其他的其他的看了一下午，感觉最近的效率有点低了，得调整啊</p></li><li><p><input type="checkbox" disabled checked>机器人课设报告要完成了</p><p>一上午写报告</p></li><li><p><input type="checkbox" disabled>复习信号与系统第三章</p></li><li><p><input type="checkbox" disabled>学打毛线</p></li></ul><hr><p>10月28日：</p><p>​ 7点33下床</p><p>​ 8点23打开电脑学习</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——降维</p></li><li><p><input type="checkbox" disabled checked>机器人汇报PPT</p></li><li><p><input type="checkbox" disabled checked>宝贝的报告写完</p></li><li><p><input type="checkbox" disabled checked>复习信号与系统第三章</p></li><li><p><input type="checkbox" disabled checked>跑步</p><p>一公里五分零四。。。好拉跨</p></li><li><p><input type="checkbox" disabled>学打毛线</p></li></ul><hr><p>10月29日：</p><p>​ 8点09下床</p><p>​ 十点半开始看机器学习（之前机器人汇报）</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>西瓜书——特征选择与<del>数据压缩</del></p><p>特征选择看完了，最后的LASSO回归求解没看懂，数据压缩也基本没看懂</p></li><li><p><input type="checkbox" disabled>学打毛线</p></li><li><p><input type="checkbox" disabled>信号与系统继续</p></li><li><p><input type="checkbox" disabled checked>机器人课设汇报</p></li><li><p><input type="checkbox" disabled checked>线性代数视频学习</p></li></ul><hr><p>10月30日</p><p>​ 7点44下床</p><p>​ 8点40开始学习</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>线性代数视频学习完成</p></li><li><p><input type="checkbox" disabled checked>信号与系统第四章开始学习</p></li><li><p><input type="checkbox" disabled checked>打毛线</p><p>打到凌晨两点半，什么都没打出来，打错了</p></li></ul><hr><p>10月31日</p><ul class="task-list"><li><p><input type="checkbox" disabled checked>打毛线</p><p>十一点起床打毛线，打到晚上八点半，打错两次什么都没打出来</p></li><li><p><input type="checkbox" disabled>西瓜书——计算学习理论</p></li></ul><hr><div class="note note-info">            <p>这个月每天的计划完成情况不是很理想，很多时间都被浪费了，下个月要努力了。</p>          </div>]]></content>
    
    
    <categories>
      
      <category>计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PX4无人机+Gazebo仿真实现移动物体的跟踪</title>
    <link href="/2021/10/23/PX4%E6%97%A0%E4%BA%BA%E6%9C%BA-Gazebo%E4%BB%BF%E7%9C%9F%E5%AE%9E%E7%8E%B0%E7%A7%BB%E5%8A%A8%E7%89%A9%E4%BD%93%E7%9A%84%E8%B7%9F%E8%B8%AA/"/>
    <url>/2021/10/23/PX4%E6%97%A0%E4%BA%BA%E6%9C%BA-Gazebo%E4%BB%BF%E7%9C%9F%E5%AE%9E%E7%8E%B0%E7%A7%BB%E5%8A%A8%E7%89%A9%E4%BD%93%E7%9A%84%E8%B7%9F%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>这个学期我们有一个智能机器人系统的课设，我们组分配到的题目是《仿真环境下使用无人机及相机跟踪移动物体》，本文主要记录完成该课设的步骤以及内容。我们采用的最终方案是PX4飞控+gazebo仿真+mavros通讯控制，实现了在gazebo环境下无人机跟踪一个移动的小车。本文所使用的是Ubuntu18.04+ melodic。</p>          </div><span id="more"></span><h1 id="试验环境介绍">试验环境介绍</h1><div class="note note-primary">            <p>首先要搞懂各个部分的关系<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/fcts1230/article/details/107915898">APM,PX4,GAZEBO,MAVLINK,MAVROS,ROS之间的关系以及科研设备选型"&gt;[7]</a></a></sup>，以及各自的作用，才能对控制无人机有个完整的认识，我在一开始做的时候就花了很多时间都没搞懂PX4到底是个无人机还是个什么东西，mavros又是干什么的。下面我简要介绍一下各个部分的关系，让大家有个大致的了解。</p>          </div><h2 id="px4飞控">PX4飞控</h2><p>PX4是一个飞控固件，所谓的飞控固件，就是能够向无人机发出控制命令，控制无人机的位姿、飞行速度以及螺旋桨的转速等等。无人机的运动就需要通过飞控固件发出命令来控制。官网的用户手册<a href="https://docs.px4.io/master/en/">在这</a>，推荐看英文版本，中文版本有的地方翻译的实在是太烂了，我看的时候感觉像是机翻的，而且与原文的位置都不太一样。</p><h2 id="gazebo仿真">Gazebo仿真</h2><p>gazebo仿真就不用多说了吧，在学ros基本的操作的时候就应该接触过gazebo。这就是一个能够模拟现实世界的仿真软件，PX4的源代码里就提供了PX4无人机的gazebo模型，通过launch文件直接运行就能得到一个gazebo下的无人机。</p><h2 id="mavros通讯">MAVROS通讯</h2><p>mavros里面有个ros，一看就是和ros相关的。我们看官网的介绍<em>“MAVROS-- MAVLink extendable communication node for ROS with proxy for GroundControlStation.”</em>，这句话的意思是，<strong>MAVROS是MAVLink为了让ROS代理控制站的扩展交流节点</strong>。首先MAVLink是一个无人机通讯协议，也就是说与无人机交流所发出的信号或数据格式都要符合该协议，与HTTP等协议是一个道理。然后控制站其实是PX4为了控制无人机所开发的一个图形化控制站，可以通过GUI的形式来操作无人机，给一般用户很好的体验。而这里是用来代理控制站，也就是说充当控制站来控制无人机。到这里就很明显了，MAVROS就相当于代码版的控制站，若想要通过ros节点开控制无人机的飞行，那就必须通过mavros这个包，在这个包内包含了控制无人机的消息格式等。</p><div class="note note-info">            <p>综上所述，整个无人机的控制逻辑就是，通过mavros向PX4飞控发送控制命令，PX4再将命令发送到无人机的各个组件，以控制无人机按照用户的逻辑进行运动。而该无人机就在gazebo中，在gazebo中可以看到无人机的运动情况。</p>          </div><h1 id="实验过程">实验过程</h1><h2 id="px4无人机的安装">PX4无人机的安装</h2><h3 id="安装环境依赖">1、安装环境依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install -y ninja-build exiftool python-argparse python-empy python-toml python-numpy python-yaml python-dev python-pip ninja-build protobuf-compiler libeigen3-dev genromfs xmlstarlet libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev<br></code></pre></td></tr></table></figure><h3 id="安装python依赖melodic默认的是python2">2、安装python依赖（melodic默认的是python2）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install pandas jinja2 pyserial cerberus pyulog numpy toml pyquaternion  -i https://pypi.tuna.tsinghua.edu.cn/simple<br></code></pre></td></tr></table></figure><p>我安装的时候pyulog没装上，其他的都装上了，如果你们也有这个问题，就把其他的装上，pyulog后面还有个步骤会自动安装</p><h3 id="安装ros与gazebo">3、安装ros与gazebo</h3><p>这两个的安装就不多说了，如果没安装的话可以在网上先安装好这两个再继续操作。</p><h3 id="安装mavros">4、安装mavros</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install ros-melodic-mavros ros-melodic-mavros-extras<br>wget https://gitee.com/robin_shaun/XTDrone/raw/master/sitl_config/mavros/install_geographiclib_datasets.sh<br>sudo chmod a+x ./install_geographiclib_datasets.sh<br>sudo ./install_geographiclib_datasets.sh <span class="hljs-comment">#这步需要装一段时间,请耐心等待PX4配置</span><br></code></pre></td></tr></table></figure><div class="note note-warning">            <p>我在安装的时候出现两个问题。</p><p>第一个问题是sudo aptinstall包的时候一直出现404，未找到这个包，解决方案时sudo aptupdate，将软件源更新一下，很可能是原始的位置已经过期了，需要更新才能找到最新的位置。</p><p>第二个问题是最后一步的.sh文件执行太慢了，我挂那两三个小时都没结束，大概是因为被墙了吧。解决办法如下<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/weixin_41865104/article/details/119418901">执行install_geographiclib_datasets.sh 错误！ "&gt;[8]</a></a></sup>：</p><ul><li><p>在 <strong>/usr/share 下目录新建 GeographicLib目录。</strong></p></li><li><p>将 <strong>geoids</strong> <strong>gravity</strong><strong>magnetic</strong> 三个文件夹拷贝到<strong>/usr/share/GeographicLib</strong> 文件夹下面。</p></li></ul><p>上述三个文件夹的链接<a href="https://pan.baidu.com/s/1Mn_L5xls1AH8fx6127YpSg"><strong>在这</strong></a>，提取码：dje9</p>          </div><h3 id="px4安装">5、PX4安装</h3><p>这里推荐使用gitee安装，非常感谢<a href="https://www.yuque.com/xtdrone/">XTDrone团队</a><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://www.yuque.com/xtdrone/manual_cn/basic_config">XTDrone仿真平台基础配置"&gt;[2]</a></a></sup>将代码放在了gitee上，我也使用过github安装，但总是断开连接，无数次重试才完整安装完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~<br>git <span class="hljs-built_in">clone</span> https://gitee.com/robin_shaun/PX4_Firmware<br><span class="hljs-built_in">cd</span> PX4_Firmware<br>git checkout -b xtdrone/dev v1.11.0-beta1<br>bash ./Tools/setup/ubuntu.sh --no-nuttx --no-sim-tools<br></code></pre></td></tr></table></figure><p>将.gitmodules替换为如下内容（在PX4_Firmware文件夹中ctrl+h查看隐藏文件）<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/qq_45067735/article/details/107303796">Ubuntu18.04下基于ROS和PX4的无人机仿真平台的基础配置搭建"&gt;[1]</a></a></sup></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs bash">[submodule <span class="hljs-string">&quot;mavlink/include/mavlink/v2.0&quot;</span>]<br>path = mavlink/include/mavlink/v2.0<br>url = https://gitee.com/robin_shaun/c_library_v2.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;src/drivers/uavcan/libuavcan&quot;</span>]<br>path = src/drivers/uavcan/libuavcan<br>url = https://gitee.com/robin_shaun/uavcan.git<br>branch = px4<br>[submodule <span class="hljs-string">&quot;Tools/jMAVSim&quot;</span>]<br>path = Tools/jMAVSim<br>url = https://gitee.com/robin_shaun/jMAVSim.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;Tools/sitl_gazebo&quot;</span>]<br>path = Tools/sitl_gazebo<br>url = https://gitee.com/robin_shaun/sitl_gazebo.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;src/lib/matrix&quot;</span>]<br>path = src/lib/matrix<br>url = https://gitee.com/robin_shaun/Matrix.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;src/lib/ecl&quot;</span>]<br>path = src/lib/ecl<br>url = https://gitee.com/robin_shaun/ecl.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;boards/atlflight/cmake_hexagon&quot;</span>]<br>path = boards/atlflight/cmake_hexagon<br>url = https://gitee.com/robin_shaun/cmake_hexagon.git<br>branch = px4<br>[submodule <span class="hljs-string">&quot;src/drivers/gps/devices&quot;</span>]<br>path = src/drivers/gps/devices<br>url = https://gitee.com/robin_shaun/GpsDrivers.git<br>branch = master<br>[submodule <span class="hljs-string">&quot;src/modules/micrortps_bridge/micro-CDR&quot;</span>]<br>path = src/modules/micrortps_bridge/micro-CDR<br>url = https://gitee.com/robin_shaun/micro-CDR.git<br>branch = px4<br>[submodule <span class="hljs-string">&quot;platforms/nuttx/NuttX/nuttx&quot;</span>]<br>path = platforms/nuttx/NuttX/nuttx<br>url = https://gitee.com/robin_shaun/NuttX.git<br>branch = px4_firmware_nuttx-9.1.0+<br>[submodule <span class="hljs-string">&quot;platforms/nuttx/NuttX/apps&quot;</span>]<br>path = platforms/nuttx/NuttX/apps<br>url = https://gitee.com/robin_shaun/NuttX-apps.git<br>branch = px4_firmware_nuttx-9.1.0+<br>[submodule <span class="hljs-string">&quot;platforms/qurt/dspal&quot;</span>]<br>path = platforms/qurt/dspal<br>url = https://gitee.com/robin_shaun/dspal.git<br>[submodule <span class="hljs-string">&quot;Tools/flightgear_bridge&quot;</span>]<br>path = Tools/flightgear_bridge<br>url = https://gitee.com/robin_shaun/PX4-FlightGear-Bridge.git<br>branch = master <br>[submodule <span class="hljs-string">&quot;Tools/jsbsim_bridge&quot;</span>]<br>path = Tools/jsbsim_bridge<br>url = https://gitee.com/robin_shaun/px4-jsbsim-bridge.git<br>[submodule <span class="hljs-string">&quot;src/examples/gyro_fft/CMSIS_5&quot;</span>]<br>path = src/examples/gyro_fft/CMSIS_5<br>url = https://gitee.com/mirrors/CMSIS_5<br></code></pre></td></tr></table></figure><p>再次执行子模块更新指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git submodule update --init --recursive<br></code></pre></td></tr></table></figure><p>编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">make px4_sitl_default gazebo<br></code></pre></td></tr></table></figure><p><strong>配置环境变量，注意路径的匹配，你若修改了文件夹名要进行对应的修改</strong>，第一个catkin_ws是自己的工作目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/catkin_ws/devel/setup.bash<br><span class="hljs-built_in">source</span> ~/PX4_Firmware/Tools/setup_gazebo.bash ~/PX4_Firmware/ ~/PX4_Firmware/build/px4_sitl_default<br><span class="hljs-built_in">export</span> ROS_PACKAGE_PATH=<span class="hljs-variable">$ROS_PACKAGE_PATH</span>:~/PX4_Firmware<br><span class="hljs-built_in">export</span> ROS_PACKAGE_PATH=<span class="hljs-variable">$ROS_PACKAGE_PATH</span>:~/PX4_Firmware/Tools/sitl_gazebo<br></code></pre></td></tr></table></figure><p>下面我们就可以测试PX4无人机了，执行下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware<br>roslaunch px4 mavros_posix_sitl.launch<br></code></pre></td></tr></table></figure><p>此时会打开gazebo环境，里面地面上有一个无人机。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023150619296.png" alt="gazebo无人机仿真"><figcaption aria-hidden="true">gazebo无人机仿真</figcaption></figure><p>最后一步，测试无人机通讯</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rostopic <span class="hljs-built_in">echo</span> /mavros/state<br></code></pre></td></tr></table></figure><p>若显示的消息中出现<code>connected: True</code>,则说明MAVROS与SITL通信成功。到此，无人机的配置就结束了。</p><h2 id="移动小车的安装">移动小车的安装</h2><div class="note note-primary">            <p>由于实验要求的是实现移动物体的跟踪，因此我使用了一个可控制的小车来代替移动物体<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://jishuin.proginn.com/p/763bfbd27b74">在gazebo中导入移动小车+二维码"&gt;[10]</a></a></sup>，通过键盘控制节点可以控制小车在gazebo环境中移动。</p>          </div><p>本试验使用的是TurtleBot3小车，安装和控制移动都非常方便。</p><p>安装小车命令<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/ldw_wdl/article/details/108255645">ROS-melodic学习turtlebot3笔记＜一功能包导入与测试＞"&gt;[5]</a></a></sup></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install ros-melodic-turtlebot3-*<br></code></pre></td></tr></table></figure><p>通过上述命令就安装好了TurtleBot小车，是不是很方便。</p><p>由于该小车有三种形态，所以还需要通过环境变量指定一种形态，否则无法运行，我实验中使用的是<code>burger</code>形态，其他两种形态你们可以自己去修改，我下面都以burger形态小车来讲解。通过环境变量指定小车有一下两种方式，推荐第二种一劳永逸，但若要修改就需要进入<code>.bashrc</code>文件中修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> TURTLEBOT3_MODEL=burger<span class="hljs-comment"># 每次打开新的终端都要执行</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export TURTLEBOT3_MODEL=burger&quot;</span> &gt;&gt; ~/.bashrc<span class="hljs-comment">#直接写入环境变量，打开终端每次都会自动执行</span><br></code></pre></td></tr></table></figure><p>下面我们运行小车，测试一下小车控制</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">roslaunch turtlebot3_gazebo turtlebot3_world.launch<br></code></pre></td></tr></table></figure><p>然后运行键盘控制节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rosrun teleop_twist_keyboard teleop_twist_keyboard.py<br></code></pre></td></tr></table></figure><p>若没安装该节点需要先安装，执行下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install ros-melodic-teleop-twist-keyboard<br></code></pre></td></tr></table></figure><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023152313324.png" alt="键盘控制节点控制小车"><figcaption aria-hidden="true">键盘控制节点控制小车</figcaption></figure><p>通过<code>I L J K ,</code>四个键可以控制小车的运动，详细的运动控制自己看控制台的输出。到此，移动小车的安装就已经完成。</p><h2 id="px4无人机添加摄像头以及配置的修改">PX4无人机添加摄像头以及配置的修改</h2><div class="note note-primary">            <p>通过上面的工作，我们完成了无人机和移动物体的配置，若要完成无人机通过相机追踪小车，那相机怎么能少得了呢？默认的PX4无人机是不带摄像头的，我们需要修改配置文件使其带上一个摄像头。</p>          </div><p>给PX4添加一个深度摄像机<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/u013083665/article/details/104840286">PX4+gazebo仿真给无人机添加摄像头"&gt;[3]</a></a></sup></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware/launch<br>cp mavros_posix_sitl.launch mavros_posix_sitl_cp.launch<span class="hljs-comment"># 不修改原始无人机文件，复制一个副本进行修改</span><br>gedit mavros_posix_sitl_cp.launch<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>我后面的修改操作都是基于副本，先复制一份然后操作副本，以保持源代码的结构</p>          </div><p>做如下改动</p><p>添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;arg name=<span class="hljs-string">&quot;my_model&quot;</span> default=<span class="hljs-string">&quot;iris_downward_depth_camera&quot;</span>/&gt;<br></code></pre></td></tr></table></figure><p>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;arg name=<span class="hljs-string">&quot;sdf&quot;</span> default=<span class="hljs-string">&quot;<span class="hljs-subst">$(find mavlink_sitl_gazebo)</span>/models/<span class="hljs-subst">$(arg vehicle)</span>/<span class="hljs-subst">$(arg vehicle)</span>.sdf&quot;</span>/&gt; <br></code></pre></td></tr></table></figure><p>为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;arg name=<span class="hljs-string">&quot;sdf&quot;</span> default=<span class="hljs-string">&quot;<span class="hljs-subst">$(find mavlink_sitl_gazebo)</span>/models/<span class="hljs-subst">$(arg vehicle)</span>/<span class="hljs-subst">$(arg my_model)</span>.sdf&quot;</span>/&gt; <br></code></pre></td></tr></table></figure><div class="note note-warning">            <p>注意添加的代码需要在修改的上方</p>          </div><p>添加摄像头就完成了，但是该摄像头默认的分辨率是<strong>48 *64</strong>，非常低，飞高一些就看不清地面的小车了，我们还需要修改一下摄像头的分辨率。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware/Tools/sitl_gazebo/models/depth_camera<br>gedit depth_camera.sdf<br></code></pre></td></tr></table></figure><p>将对应部分修改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;update_rate&gt;10&lt;/update_rate&gt;<br>...<br>&lt;image&gt;<br>&lt;format&gt;R8G8B8&lt;/format&gt;<br>&lt;width&gt;400&lt;/width&gt;<br>&lt;height&gt;400&lt;/height&gt;<br>&lt;/image&gt;<br></code></pre></td></tr></table></figure><p>width与height对应的就是摄像头的分辨率，update_rate是图像的发布频率，由于把像素改高了，怕系统处理速度慢，因此把频率降低一倍。</p><p>下面我们来测试一下摄像头是否配置成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware<br>roslaunch px4 mavros_posix_sitl_cp.launch<span class="hljs-comment"># 注意我修改的都是副本，不要运行错了</span><br></code></pre></td></tr></table></figure><p>放大无人机可以看见前面装上了一个长条形摄像机，这就是一个向下的深度相机。<img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023160952159.png" alt="无人机上的深度相机"></p><p>然后打开rviz，新开一个终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rviz<br></code></pre></td></tr></table></figure><p>先添加一个接收图像的窗口</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023160140889.png" alt="添加一个图像窗口"><figcaption aria-hidden="true">添加一个图像窗口</figcaption></figure><p>将图像的话题选择为<code>/camera/rgb/image_raw</code>，另一个对应的是深度图像，可以自己切换看看效果。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023161101435.png" alt="选择对应的话题"><figcaption aria-hidden="true">选择对应的话题</figcaption></figure><p>这个时候image窗口就会显示无人机摄像机拍摄下来的图像，然后在运行无人机的那个终端输入命令<code>commander takeoff</code>，观察该图像窗口，会随着无人机起飞变化。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023161208267.png" alt="无人机起飞测试"><figcaption aria-hidden="true">无人机起飞测试</figcaption></figure><p>由于这个地面平坦，将小车放到这个环境中的话，小车会动不了，所以要将仿真环境改一下，改成原始的空仿真环境。</p><p>PX4仿真环境的配置文件是<code>/home/ljw/PX4_Firmware/launch/posix_sitl.launch</code>，与之前一样，我们不对原始文件进行修改，我们修改副本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware/launch<br>cp posix_sitl.launch posix_sitl_cp.launch<br>gedit posix_sitl_cp.launch<br></code></pre></td></tr></table></figure><p>将</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;!-- Gazebo sim --&gt;<br>&lt;include file=<span class="hljs-string">&quot;<span class="hljs-subst">$(find gazebo_ros)</span>/launch/empty_world.launch&quot;</span>&gt;<br>&lt;arg name=<span class="hljs-string">&quot;gui&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg gui)</span>&quot;</span>/&gt;<br>&lt;arg name=<span class="hljs-string">&quot;world_name&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg world)</span>&quot;</span>/&gt;<br>&lt;arg name=<span class="hljs-string">&quot;debug&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg debug)</span>&quot;</span>/&gt;<br>&lt;arg name=<span class="hljs-string">&quot;verbose&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg verbose)</span>&quot;</span>/&gt;<br>&lt;arg name=<span class="hljs-string">&quot;paused&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg paused)</span>&quot;</span>/&gt;<br>&lt;arg name=<span class="hljs-string">&quot;respawn_gazebo&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg respawn_gazebo)</span>&quot;</span>/&gt;<br>&lt;/include&gt;<br></code></pre></td></tr></table></figure><p>修改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;!-- Gazebo sim --&gt;<br>&lt;include file=<span class="hljs-string">&quot;<span class="hljs-subst">$(find gazebo_ros)</span>/launch/empty_world.launch&quot;</span>&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;gui&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg gui)</span>&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;world_name&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(find turtlebot3_gazebo)</span>/worlds/empty.world&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;debug&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg debug)</span>&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;verbose&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg verbose)</span>&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;paused&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg paused)</span>&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;respawn_gazebo&quot;</span> value=<span class="hljs-string">&quot;<span class="hljs-subst">$(arg respawn_gazebo)</span>&quot;</span>/&gt;<br>&lt;/include&gt;<br></code></pre></td></tr></table></figure><p>也就是将原本的gazebo的.world文件换成turtlebot3小车的empty.world文件，这个world里什么都没有。光这样修改还没有生效，因为我们修改的是副本，原始调用这个文件的文件也需要修改，调用这个文件的文件就是之前的<code>mavros_posix_sitl_cp.launch</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">gedit mavros_posix_sitl_cp.launch<br></code></pre></td></tr></table></figure><p>将</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;include file=<span class="hljs-string">&quot;<span class="hljs-subst">$(find px4)</span>/launch/posix_sitl.launch&quot;</span>&gt;<br></code></pre></td></tr></table></figure><p>修改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;include file=<span class="hljs-string">&quot;<span class="hljs-subst">$(find px4)</span>/launch/posix_sitl_cp.launch&quot;</span>&gt;<br></code></pre></td></tr></table></figure><p>到此，无人机的配置就已经完成，可以再次运行一次无人机，看看环境是否发生变化。</p><h2 id="合并无人机和移动小车">合并无人机和移动小车</h2><div class="note note-primary">            <p>在前面的步骤中，我们将无人机和移动小车都准备好了，下面我们就只要将无人机和小车放在同一环境中，就能开始我们的跟踪实验了。</p>          </div><p>通过阅读turtlebot3的启动文件<code>/opt/ros/melodic/share/turtlebot3_gazebo/turtlebot3_empty_world.launch</code>，可以看到启动小车的代码，我们将该代码添加到启动无人机的文件中，就能同时启动小车和无人机。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware/launch<br>gedit posix_sitl_cp.launch<br></code></pre></td></tr></table></figure><p>添加如下代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;!-- car model and parameter --&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;model&quot;</span> default=<span class="hljs-string">&quot;<span class="hljs-subst">$(env TURTLEBOT3_MODEL)</span>&quot;</span> doc=<span class="hljs-string">&quot;model type [burger, waffle, waffle_pi]&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;x_pos&quot;</span> default=<span class="hljs-string">&quot;1.0&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;y_pos&quot;</span> default=<span class="hljs-string">&quot;1.0&quot;</span>/&gt;<br>    &lt;arg name=<span class="hljs-string">&quot;z_pos&quot;</span> default=<span class="hljs-string">&quot;0.0&quot;</span>/&gt;<br>    &lt;param name=<span class="hljs-string">&quot;robot_description&quot;</span> <span class="hljs-built_in">command</span>=<span class="hljs-string">&quot;<span class="hljs-subst">$(find xacro)</span>/xacro --inorder <span class="hljs-subst">$(find turtlebot3_description)</span>/urdf/turtlebot3_burger.urdf.xacro&quot;</span> /&gt;<br><br>&lt;!-- gazebo car model --&gt;<br>&lt;node pkg=<span class="hljs-string">&quot;gazebo_ros&quot;</span> <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;spawn_model&quot;</span> name=<span class="hljs-string">&quot;spawn_urdf&quot;</span> args=<span class="hljs-string">&quot;-urdf -model turtlebot3_<span class="hljs-subst">$(arg model)</span> -x <span class="hljs-subst">$(arg x_pos)</span> -y <span class="hljs-subst">$(arg y_pos)</span> -z <span class="hljs-subst">$(arg z_pos)</span> -param robot_description&quot;</span> /&gt;<br></code></pre></td></tr></table></figure><p>我们让小车出生在<code>1 1</code>位置，无人机默认出生在<code>0 0</code>位置。为了让小车更容易被无人机识别，我们将小车全身改成黑色。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">roscd turtlebot3_description<br><span class="hljs-built_in">cd</span> urdf<br>sudo gedit turtlebot3_burger.gazebo.xacro<br></code></pre></td></tr></table></figure><div class="note note-success">            <p>注意选择自己的小车文件进行修改，我这里修改的是burger小车的。</p>          </div><p>将文件中所有<code>&lt;material&gt;Gazebo/xxx&lt;/material&gt;</code>中的xxx全部改成Black。</p><p>到此，无人机与移动小车全部配置完毕执行，我们测试一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/PX4_Firmware<br>roslaunch px4 mavros_posix_sitl_cp.launch<br></code></pre></td></tr></table></figure><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20211023165246791.png" alt="无人机与小车"><figcaption aria-hidden="true">无人机与小车</figcaption></figure><p>我们可以看到中间一个无人机和一个黑乎乎的小车，周围的环境已经变成了空的了。然后启动键盘控制节点可以控制小车的运动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rosrun teleop_twist_keyboard teleop_twist_keyboard.py<br></code></pre></td></tr></table></figure><h2 id="控制无人机运动">控制无人机运动</h2><p>通过阅读PX4官网的一个<a href="https://docs.px4.io/master/en/ros/mavros_offboard.html">控制实例</a><sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://docs.px4.io/master/en/ros/mavros_offboard.html">MAVROSOffboard control example"&gt;[9]</a></a></sup>，我们可以大致了解无人机运动的控制流程。我将实例代码复制过来并且添加注释，让大家对无人机控制代码有个理解。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">头文件，包括常见的geometry_msgs和mavros通信需要的mavros_msgs，添加上就行</span><br><span class="hljs-comment">*/</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;ros/ros.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;geometry_msgs/PoseStamped.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/CommandBool.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/SetMode.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/State.h&gt;</span></span><br><br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">current_state表示的是无人机的状态，在主函数中订阅了对应的话题，这个状态就会不断更新，表示无人机当前的状态。state_cb就是对应的回调函数，会不断的执行，更新状态。现在先不用管为什么需要这个状态，后面的代码会解释。</span><br><span class="hljs-comment">*/</span><br>mavros_msgs::State current_state;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">state_cb</span><span class="hljs-params">(<span class="hljs-keyword">const</span> mavros_msgs::State::ConstPtr&amp; msg)</span></span>&#123;<br>    current_state = *msg;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span></span><br><span class="hljs-function"></span>&#123;<br>    ros::<span class="hljs-built_in">init</span>(argc, argv, <span class="hljs-string">&quot;offb_node&quot;</span>);<br>    ros::NodeHandle nh;<br>    <br><span class="hljs-comment">// 订阅无人机的状态</span><br>    ros::Subscriber state_sub = nh.subscribe&lt;mavros_msgs::State&gt;<br>            (<span class="hljs-string">&quot;mavros/state&quot;</span>, <span class="hljs-number">10</span>, state_cb);<br>    <br>    <span class="hljs-comment">/* </span><br><span class="hljs-comment">    发布一个geometry_msgs::PoseStamped的消息，需要知道的是，这个消息是控制无人机的一种方式，将指定坐标包裹进这个消息，然后发布出去，无人机就能自动飞行到指定的坐标地点</span><br><span class="hljs-comment">    */</span> <br>    ros::Publisher local_pos_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;<br>            (<span class="hljs-string">&quot;mavros/setpoint_position/local&quot;</span>, <span class="hljs-number">10</span>);<br>    <br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    无人机有一个锁，如果不解锁，无人机虽然接受了命令但是不会动被锁住了，只有解锁了才能对无人机进行控制，下面这个服务调用就是用来请求解锁无人机。上面的current_state就包含了无人机是否解锁的信息，若没解锁就需要解锁，否则就不用，其用途在这就体现出来</span><br><span class="hljs-comment">    */</span><br>    ros::ServiceClient arming_client = nh.serviceClient&lt;mavros_msgs::CommandBool&gt;<br>            (<span class="hljs-string">&quot;mavros/cmd/arming&quot;</span>);<br>    <br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    无人机飞行有很多种模式，如果需要用代码操控无人机，我们就需要切换到OFFBOARD模式。上面的current_state也包含了无人机当前的飞行模式，若不是OFFBOARD就需要切换到该模式。下面的这个服务调用就是用来请求切换无人机飞行模式。</span><br><span class="hljs-comment">    */</span><br>    ros::ServiceClient set_mode_client = nh.serviceClient&lt;mavros_msgs::SetMode&gt;<br>            (<span class="hljs-string">&quot;mavros/set_mode&quot;</span>);<br><br>    <span class="hljs-comment">//the setpoint publishing rate MUST be faster than 2Hz</span><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    在OFFBOARD模式下，需要以&gt;=2HZ的频率向无人机发送消息，否则无人机会回退到OFFBOARD模式之前所在的模式，因此这里的rate需要设置的比2大就行</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-function">ros::Rate <span class="hljs-title">rate</span><span class="hljs-params">(<span class="hljs-number">20.0</span>)</span></span>;<br><br>    <span class="hljs-comment">// wait for FCU connection</span><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    等待无人机与控制站连接（代码的方式就是代理），只有连接了才能发送消息</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-keyword">while</span>(ros::<span class="hljs-built_in">ok</span>() &amp;&amp; !current_state.connected)&#123;<br>        ros::<span class="hljs-built_in">spinOnce</span>();<br>        rate.<span class="hljs-built_in">sleep</span>();<br>    &#125;<br><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    pose就是坐标，本实例是让无人机在2m处悬空，因此z设置为2，z表示的就是高度</span><br><span class="hljs-comment">    */</span><br>    geometry_msgs::PoseStamped pose;<br>    pose.pose.position.x = <span class="hljs-number">0</span>;<br>    pose.pose.position.y = <span class="hljs-number">0</span>;<br>    pose.pose.position.z = <span class="hljs-number">2</span>;<br><br>    <span class="hljs-comment">// 下面这个感觉有没有都无所谓</span><br>    <span class="hljs-comment">//send a few setpoints before starting</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">100</span>; ros::<span class="hljs-built_in">ok</span>() &amp;&amp; i &gt; <span class="hljs-number">0</span>; --i)&#123;<br>        local_pos_pub.<span class="hljs-built_in">publish</span>(pose);<br>        ros::<span class="hljs-built_in">spinOnce</span>();<br>        rate.<span class="hljs-built_in">sleep</span>();<br>    &#125;<br><br>    <span class="hljs-comment">// 请求的切换模式的消息，设置为OFFBOARD</span><br>    mavros_msgs::SetMode offb_set_mode;<br>    offb_set_mode.request.custom_mode = <span class="hljs-string">&quot;OFFBOARD&quot;</span>;<br><br>    <span class="hljs-comment">// 请求解锁的消息，arm表示解锁，设置为true，disarm是上锁</span><br>    mavros_msgs::CommandBool arm_cmd;<br>    arm_cmd.request.value = <span class="hljs-literal">true</span>;<br><br>    <span class="hljs-comment">// 记录上次请求的时间</span><br>    ros::Time last_request = ros::Time::<span class="hljs-built_in">now</span>();<br><br>    <span class="hljs-keyword">while</span>(ros::<span class="hljs-built_in">ok</span>())&#123;<br>        <span class="hljs-comment">// 如果无人机模式不是OFFBOARD并且离上次操作时间大于5秒就发送请求切换，这里的5s是为了演示清楚设置的延时</span><br>        <span class="hljs-keyword">if</span>( current_state.mode != <span class="hljs-string">&quot;OFFBOARD&quot;</span> &amp;&amp;<br>            (ros::Time::<span class="hljs-built_in">now</span>() - last_request &gt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">5.0</span>)))&#123;<br>            <span class="hljs-keyword">if</span>( set_mode_client.<span class="hljs-built_in">call</span>(offb_set_mode) &amp;&amp;<br>                offb_set_mode.response.mode_sent)&#123;<br>                <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;Offboard enabled&quot;</span>);<br>            &#125;<br>            <span class="hljs-comment">// 更新本次请求的时间</span><br>            last_request = ros::Time::<span class="hljs-built_in">now</span>();<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 如果当前未解锁且与请求时间大于5s，就发送请求解锁</span><br>            <span class="hljs-keyword">if</span>( !current_state.armed &amp;&amp;<br>                (ros::Time::<span class="hljs-built_in">now</span>() - last_request &gt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">5.0</span>)))&#123;<br>                <span class="hljs-keyword">if</span>( arming_client.<span class="hljs-built_in">call</span>(arm_cmd) &amp;&amp;<br>                    arm_cmd.response.success)&#123;<br>                    <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;Vehicle armed&quot;</span>);<br>                &#125;<br>                last_request = ros::Time::<span class="hljs-built_in">now</span>();<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 不断发送位置消息，但是只有解锁后才能真正开始运动，如果不发送就会退出OFFBOARD模式，因为请求发送速度要&gt;=2HZ</span><br>        local_pos_pub.<span class="hljs-built_in">publish</span>(pose);<br><br>        ros::<span class="hljs-built_in">spinOnce</span>();<br>        rate.<span class="hljs-built_in">sleep</span>();<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>通过官网的代码就能知道控制无人机飞行的一般流程，只要将核心代码逻辑修改一下，就能实现无人机对小车的跟踪了。可以先将上面的代码运行一次，观察一下无人机的运动。</p><div class="note note-success">            <p>总体流程为：</p><p>1、通过launch文件启动无人机的gazebo环境</p><p>2、新建一个工作空间，包含的依赖有<code>roscpp、std_msgs、geometry_msgs、mavros、cv_bridge、image_transport、sensor_msgs</code></p><p>其中后面几个是为了后续图像处理用的，这里一并导入</p><p>3、创建一个cpp文件，将上述代码复制进去</p><p>4、修改CMakeLists</p><p>5、rosrun该节点</p><p>在无人机解锁后就能看到无人机飞到了空中2m处</p>          </div><h2 id="控制无人机跟踪运动小车">控制无人机跟踪运动小车</h2><div class="note note-primary">            <p>通过上述无人机悬空的代码我们已经了解了控制无人机飞行的代码流程：首先定义好需要发送与接收的话题消息，并且定义好各个请求，然后将无人机切换到OFFBOARD模式，接着解锁无人机，同时需要一直给无人机发送运动控制的消息，包括位置控制或速度控制，并且频率要大于2HZ。通过以上流程框架，我们就能设计一个自动跟踪移动小车的代码。</p>          </div><p>通过网上查阅资料看到，控制无人机运动不仅可以通过发送位置消息<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/qq_31736703/article/details/79924224">使用ROS节点控制PX4——位置控制"&gt;[4]</a></a></sup>，还可以像控制小乌龟一样，发送速度消息<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<a href="https://blog.csdn.net/wbzhang233/article/details/106727276">PX4学习笔记3:速度控制"&gt;[6]</a></a></sup>，这就为跟踪小车的提供了方案。我设计的跟踪思路：</p><p>之前案例订阅和发布的话题就不用多说了，全部都要订阅，然后需要额外订阅的是无人机发送的图像，之前设置了10HZ，也就是一秒钟无人机会发送十帧图像过来，在该订阅的回调函数内，对图像进行处理，检查图像内是否有小车，如果有的话，就通过比较小车像素点的位置和图像中心像素点的位置，来判断方位，并相应的设置速度。图像处理回调函数如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;ros/ros.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;geometry_msgs/PoseStamped.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;geometry_msgs/Twist.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/CommandBool.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/SetMode.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/State.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;mavros_msgs/Altitude.h&gt;</span></span><br><br><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;sensor_msgs/Image.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;cv_bridge/cv_bridge.h&quot;</span></span><br><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;opencv2/core/core.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span><br><span class="hljs-comment">// 一些全局变量</span><br><br><span class="hljs-comment">// 悬空高度（追踪小车的高度）</span><br><span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span> h = <span class="hljs-number">4</span>;<br><span class="hljs-comment">// 调整高度的速度（上升或下降）</span><br><span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span> hv = <span class="hljs-number">0.1</span>;<br><br><span class="hljs-comment">// 控制无人机的速度</span><br>geometry_msgs::Twist velocity;<br><br><span class="hljs-comment">// 无人机当前的高度</span><br><span class="hljs-keyword">double</span> curH;<br><br><span class="hljs-comment">// 无人机是否已经稳定在空中的标志</span><br><span class="hljs-keyword">bool</span> start = <span class="hljs-literal">false</span>;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">doImg</span><span class="hljs-params">(<span class="hljs-keyword">const</span> sensor_msgs::Image::ConstPtr &amp;msg)</span> </span>&#123;<br>    <br>    <span class="hljs-keyword">if</span>(!start) <span class="hljs-keyword">return</span>;<br>    <br>    <span class="hljs-comment">// 将无人机发布的图像先转化为灰度图，再进行二值化，就能得到黑白图像，若小车出现，那么在图像内有黑色的像素，否则图像全是白色像素，这也是我将小车改成黑色的原因，若改成其它颜色就不好进行分离</span><br>    cv_bridge::CvImagePtr cv_ptr = cv_bridge::<span class="hljs-built_in">toCvCopy</span>(msg, sensor_msgs::image_encodings::BGR8);<br>cv::Mat img = cv_ptr -&gt; image;<br>    cv::Mat gray, bin;<br>    cv::<span class="hljs-built_in">cvtColor</span>(img, gray, cv::COLOR_BGR2GRAY);<br>    cv::<span class="hljs-built_in">threshold</span>(gray, bin, <span class="hljs-number">127</span>, <span class="hljs-number">255</span>, cv::THRESH_BINARY);<br>    <br>    <span class="hljs-comment">// 获得图像的宽和高</span><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> row = bin.rows, col = bin.cols;<br>    <span class="hljs-comment">// 图像中心点的位置，我们假设图像中心点的位置就是无人机的位置，这样就能很方便的发布速度来控制无人机</span><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">double</span> centX = row / <span class="hljs-number">2</span>, centY = col / <span class="hljs-number">2</span>;<br>    <br>    <span class="hljs-comment">// x y用来记录小车在该帧图像出现的位置</span><br>    <span class="hljs-keyword">int</span> x, y;<br>    <span class="hljs-comment">// 是否找到小车的标记</span><br>    <span class="hljs-keyword">bool</span> findCar = <span class="hljs-literal">false</span>;<br>    <br>    <span class="hljs-comment">// 遍历图像，若图像内有黑色像素则代表发现了小车，记录下此时的x y位置</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++) &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; col; j++) &#123;<br>            uchar point = bin.at&lt;uchar&gt;(i, j);<br>            <span class="hljs-keyword">if</span>(point == <span class="hljs-number">0</span>) &#123;<br>                findCar = <span class="hljs-literal">true</span>;<br>                x = i, y = j;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(findCar) <span class="hljs-keyword">break</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 记录最后一次找到小车的时间</span><br>    <span class="hljs-keyword">static</span> ros::Time last_find_time = ros::Time::<span class="hljs-built_in">now</span>();<br>    <span class="hljs-keyword">if</span>(findCar) &#123;<br>        <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;找到目标位置, x = %d, y = %d&quot;</span>, x, y);<br>        <span class="hljs-comment">// 将小车（所在像素点）相对无人机（图像中心像素点）的位置归一化到0 ~ 1之间，并以此作为控制无人机的速度，小车离无人机越远，则无人机的速度越大，否则无人机的速度越小</span><br>        <span class="hljs-keyword">double</span> vx = <span class="hljs-built_in">abs</span>(centX - x) / centX;<br>        <span class="hljs-keyword">double</span> vy = <span class="hljs-built_in">abs</span>(centY - y) / centY;<br>        <br>        <span class="hljs-comment">// 经测试，无人机发送的图像的垂直方向是无人机的x方向，图像的水平方向是无人机的y方向</span><br>        <span class="hljs-comment">// 因此，若小车（像素位置）在无人机（像素位置）上方，需要发送一个正的x方向速度，否则要发送一个负方向的速度</span><br>        <span class="hljs-keyword">if</span>(x &lt; centX) velocity.linear.x = vx;<br>        <span class="hljs-keyword">else</span> velocity.linear.x = -vx;<br>        <br><span class="hljs-comment">// y方向同理</span><br>        <span class="hljs-keyword">if</span>(y &lt; centY) velocity.linear.y = vy;<br>        <span class="hljs-keyword">else</span> velocity.linear.y = -vy;<br><br>        <span class="hljs-comment">// 若不给无人机发送z方向的速度，无人机会时上时下，因此通过下面这个代码控制无人机高度，若低于一定高度，就发布z方向的速度，若高于某个高度，就发送一个-z方向的速度，让无人机下降</span><br>        <span class="hljs-keyword">if</span>(curH &lt; h - <span class="hljs-number">0.5</span>) velocity.linear.z = hv;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(curH &lt; h + <span class="hljs-number">0.5</span>) velocity.linear.z = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">else</span> velocity.linear.z = (curH - h) * -hv;<br>        <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;发布速度 x : %f, y : %f, z : %f&quot;</span>, velocity.linear.x, velocity.linear.y, velocity.linear.z);<br>        <span class="hljs-comment">// 记录无人机最后一次发现小车的时间，后面有用</span><br>        last_find_time = ros::Time::<span class="hljs-built_in">now</span>();<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        ros::Time now = ros::Time::<span class="hljs-built_in">now</span>();<br>        velocity.linear.x = <span class="hljs-number">0</span>;<br>        velocity.linear.y = <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">// 无人机丢失目标五秒内，什么都不操作</span><br>        <span class="hljs-keyword">if</span>(now - last_find_time &lt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">5</span>)) &#123;<br>            <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;没有找到目标...&quot;</span>);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 无人机丢失目标五秒后，开始向上飞行（扩大视野）来搜寻小车，搜寻的最高高度是无人机跟踪小车高度的两倍，这也是前面代码中控制无人机下降的原因，若无人机在升空过程中发现目标小车，会立刻下降跟踪小车</span><br>            <span class="hljs-keyword">if</span>(curH &lt; <span class="hljs-number">2</span> * h - <span class="hljs-number">1</span>) &#123;<br>                <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;上升高度寻找，当前高度为：%.2f&quot;</span>, curH);<br>                velocity.linear.z = hv;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">if</span>(curH &gt; <span class="hljs-number">2</span> * h + <span class="hljs-number">1</span>) velocity.linear.z = -hv;<br>                <span class="hljs-keyword">else</span> velocity.linear.z = <span class="hljs-number">0</span>;<br>                <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;目标丢失。。。&quot;</span>);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的回调函数完成了对无人机追踪小车速度的控制，其运行逻辑是：若无人机发现了小车，就通过小车相对无人机的方位，发送<code>x y</code>方向的速度，否则如果丢失的话，在五秒内不进行任何操作，超过五秒后，开始提升无人机的高度扩大视野来寻找小车，最大高度是跟踪小车高度的两倍，一旦发现小车立刻下降并跟踪小车。</p><p>上面只是一个回调函数，还要主函数来控制无人机。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">do_H</span><span class="hljs-params">(<span class="hljs-keyword">const</span> mavros_msgs::Altitude::ConstPtr&amp; msg)</span> </span>&#123;<br>    curH = msg-&gt;local;<br>&#125;<br><br>mavros_msgs::State current_state;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">state_cb</span><span class="hljs-params">(<span class="hljs-keyword">const</span> mavros_msgs::State::ConstPtr&amp; msg)</span></span>&#123;<br>    current_state = *msg;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span></span><br><span class="hljs-function"></span>&#123;<br>    ros::<span class="hljs-built_in">init</span>(argc, argv, <span class="hljs-string">&quot;offb_node&quot;</span>);<br>    ros::NodeHandle nh;<br>    <span class="hljs-built_in">setlocale</span>(LC_ALL, <span class="hljs-string">&quot;&quot;</span>);<br><br>    ros::Subscriber state_sub = nh.subscribe&lt;mavros_msgs::State&gt;<br>            (<span class="hljs-string">&quot;mavros/state&quot;</span>, <span class="hljs-number">10</span>, state_cb);<br>    ros::Publisher local_pos_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;<br>            (<span class="hljs-string">&quot;mavros/setpoint_position/local&quot;</span>, <span class="hljs-number">10</span>);<br>    ros::Publisher local_vec_pub = nh.advertise&lt;geometry_msgs::Twist&gt;<br>            (<span class="hljs-string">&quot;/mavros/setpoint_velocity/cmd_vel_unstamped&quot;</span>, <span class="hljs-number">10</span>);<br>    ros::ServiceClient arming_client = nh.serviceClient&lt;mavros_msgs::CommandBool&gt;<br>            (<span class="hljs-string">&quot;mavros/cmd/arming&quot;</span>);<br>    ros::ServiceClient set_mode_client = nh.serviceClient&lt;mavros_msgs::SetMode&gt;<br>            (<span class="hljs-string">&quot;mavros/set_mode&quot;</span>);<br>    ros::Subscriber img_sub = nh.subscribe&lt;sensor_msgs::Image&gt;(<span class="hljs-string">&quot;/camera/rgb/image_raw&quot;</span>, <span class="hljs-number">10</span>, doImg);<br><br>    ros::Subscriber height_sub = nh.subscribe&lt;mavros_msgs::Altitude&gt;<br>            (<span class="hljs-string">&quot;/mavros/altitude&quot;</span>, <span class="hljs-number">10</span>, do_H);<br><br>    <span class="hljs-comment">//the setpoint publishing rate MUST be faster than 2Hz</span><br>    <span class="hljs-function">ros::Rate <span class="hljs-title">rate</span><span class="hljs-params">(<span class="hljs-number">20.0</span>)</span></span>;<br><br>    <span class="hljs-comment">// wait for FCU connection</span><br>    <span class="hljs-keyword">while</span>(ros::<span class="hljs-built_in">ok</span>() &amp;&amp; !current_state.connected)&#123;<br>        ros::<span class="hljs-built_in">spinOnce</span>();<br>        rate.<span class="hljs-built_in">sleep</span>();<br>    &#125;<br><br>    geometry_msgs::PoseStamped pose;<br>    pose.pose.position.x = <span class="hljs-number">0</span>;<br>    pose.pose.position.y = <span class="hljs-number">0</span>;<br>    pose.pose.position.z = h;<br><br>    velocity.linear.x = <span class="hljs-number">0</span>;<br>    velocity.linear.y = <span class="hljs-number">0</span>;<br>    velocity.linear.z = <span class="hljs-number">0</span>;<br><br>    mavros_msgs::SetMode offb_set_mode;<br>    offb_set_mode.request.custom_mode = <span class="hljs-string">&quot;OFFBOARD&quot;</span>;<br><br>    mavros_msgs::CommandBool arm_cmd;<br>    arm_cmd.request.value = <span class="hljs-literal">true</span>;<br><br>    ros::Time last_request = ros::Time::<span class="hljs-built_in">now</span>();<br><br>    <span class="hljs-keyword">bool</span> takeoff = <span class="hljs-literal">false</span>;<br><br>    <span class="hljs-keyword">while</span>(ros::<span class="hljs-built_in">ok</span>())&#123;<br>        <span class="hljs-keyword">if</span>(!takeoff) &#123;<br>            <span class="hljs-keyword">if</span>( current_state.mode != <span class="hljs-string">&quot;OFFBOARD&quot;</span> &amp;&amp;<br>                (ros::Time::<span class="hljs-built_in">now</span>() - last_request &gt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">2.0</span>)))&#123;<br>                <span class="hljs-keyword">if</span>( set_mode_client.<span class="hljs-built_in">call</span>(offb_set_mode) &amp;&amp;<br>                    offb_set_mode.response.mode_sent)&#123;<br>                    <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;Offboard enabled&quot;</span>);<br>                &#125;<br>                last_request = ros::Time::<span class="hljs-built_in">now</span>();<br>            &#125;<br><br>            <span class="hljs-keyword">if</span>( !current_state.armed &amp;&amp;<br>                (ros::Time::<span class="hljs-built_in">now</span>() - last_request &gt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">2.0</span>)))&#123;<br>                <span class="hljs-keyword">if</span>( arming_client.<span class="hljs-built_in">call</span>(arm_cmd) &amp;&amp;<br>                    arm_cmd.response.success)&#123;<br>                    <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;Vehicle armed&quot;</span>);<br>                &#125;<br>                last_request = ros::Time::<span class="hljs-built_in">now</span>();<br>            &#125;<br><br>            <span class="hljs-keyword">if</span>( current_state.armed &amp;&amp; <br>                (ros::Time::<span class="hljs-built_in">now</span>() - last_request &gt; ros::<span class="hljs-built_in">Duration</span>(<span class="hljs-number">5.0</span>))) &#123;<br>                    takeoff = <span class="hljs-literal">true</span>;<br>                    <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;Vehicle stabled&quot;</span>);<br>                    start = <span class="hljs-literal">true</span>;<br>                    <span class="hljs-built_in">ROS_INFO</span>(<span class="hljs-string">&quot;开始追踪...&quot;</span>);<br>                    last_request = ros::Time::<span class="hljs-built_in">now</span>();<br>                &#125;<br><br>            local_pos_pub.<span class="hljs-built_in">publish</span>(pose);<br><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            local_vec_pub.<span class="hljs-built_in">publish</span>(velocity);<br>        &#125;<br><br>        ros::<span class="hljs-built_in">spinOnce</span>();<br>        rate.<span class="hljs-built_in">sleep</span>();<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>上述代码的逻辑比较好理解，我就不加注释，流程是：先通过位置控制无人机，让无人机在高度h处稳定悬空，当无人机稳定悬停在空中时，将控制无人机的方式改为速度控制，也就是通过发送速度来控制无人机。</p><div class="note note-info">            <p>为了方便讲解，将代码分成了两部分贴，将两部分合起来放在一个cpp里，就能正常执行。代码中无人机是否稳定悬空是通过一个时间延迟实现的，假定无人机能在五秒内悬停在指定点，五秒前都是通过位置控制无人机，五秒后就一直通过速度控制无人机。</p>          </div><p>到此，无人机跟踪运动小车的整个实验就完成了。</p><h1 id="演示视频">演示视频</h1><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;"><iframe src="//player.bilibili.com/player.html?aid=848629352&amp;bvid=BV1nL4y1B7Zt&amp;cid=429718339&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h1 id="参考">参考</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://blog.csdn.net/qq_45067735/article/details/107303796">Ubuntu18.04下基于ROS和PX4的无人机仿真平台的基础配置搭建</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://www.yuque.com/xtdrone/manual_cn/basic_config">XTDrone仿真平台基础配置</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://blog.csdn.net/u013083665/article/details/104840286">PX4+gazebo仿真给无人机添加摄像头</a><a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://blog.csdn.net/qq_31736703/article/details/79924224">使用ROS节点控制PX4——位置控制</a><a href="#fnref:4" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://blog.csdn.net/ldw_wdl/article/details/108255645">ROS-melodic学习turtlebot3笔记＜一功能包导入与测试＞</a><a href="#fnref:5" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a href="https://blog.csdn.net/wbzhang233/article/details/106727276">PX4学习笔记3:速度控制</a> <a href="#fnref:6" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a href="https://blog.csdn.net/fcts1230/article/details/107915898">APM,PX4,GAZEBO,MAVLINK,MAVROS,ROS之间的关系以及科研设备选型</a><a href="#fnref:7" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:8" class="footnote-text"><span><a href="https://blog.csdn.net/weixin_41865104/article/details/119418901">执行install_geographiclib_datasets.sh 错误！</a><a href="#fnref:8" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:9" class="footnote-text"><span><a href="https://docs.px4.io/master/en/ros/mavros_offboard.html">MAVROS<em>Offboard</em> control example</a><a href="#fnref:9" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:10" class="footnote-text"><span><a href="https://jishuin.proginn.com/p/763bfbd27b74">在gazebo中导入移动小车+二维码</a><a href="#fnref:10" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:11" class="footnote-text"><span><a href="http://www.autolabor.com.cn/book/ROSTutorials/">autolaborROSTutorials</a><a href="#fnref:11" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>ROS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ROS</tag>
      
      <tag>PX4</tag>
      
      <tag>目标跟踪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021年保研经验贴</title>
    <link href="/2021/09/21/2021%E5%B9%B4%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E8%B4%B4/"/>
    <url>/2021/09/21/2021%E5%B9%B4%E4%BF%9D%E7%A0%94%E7%BB%8F%E9%AA%8C%E8%B4%B4/</url>
    
    <content type="html"><![CDATA[<blockquote><p>2021年保研大战就快要结束了，感觉形势还是一如既往的严峻，大佬们是一如既往的海。每次面试前，感觉自己复习的挺好，应该没什么问题，可每次面试出来之后，就感觉我怎么什么都不会。在此记录一下我的保研经历，不算非常累，运气起了很大的作用，希望对以后保研的学弟学妹或九推的同学能起到帮助，也欢迎大家在评论区交流！</p></blockquote><span id="more"></span><h1 id="基本情况">基本情况</h1><p>本科就读于合肥工业大学（不出名的211），所在班级是人数非常少的创新班，夏令营排名为5/ 28，后期综合排名为2 / 28。</p><p>四级：579，六级：596</p><p>论文：无</p><p>竞赛：比较多，但是都挺水的</p><p>项目：一个大创项目，一个实验室项目</p><p><strong>夏令营入营：北京邮电大学计算机学院，华东师范大学计算机学院，山东大学软件学院</strong></p><p><strong>夏令营offer：华师计算机、山大软院（全员优营😅）</strong></p><p><strong>预推免：东南大学计算机、国科大人工智能学院</strong></p><p><strong>最终去向：国科大人工智能学院</strong></p><h1 id="夏令营">夏令营</h1><h2 id="北京邮电大学计算机7.9">北京邮电大学计算机（7.9）</h2><h3 id="概况介绍">概况介绍</h3><p>北邮好像是第一次开夏令营，填报的时候系统可以填三个志愿，最后能进一个学院。我至今都没搞清楚是什么情况，系统上显示我是第一个志愿被录取了，但是后来给我面试的好像是第二个志愿，2组软工的，一共入了二十个，好像只要5，6个。刚好那几天没有课，我就去请了一星期的假到外面开宾馆去面试。北邮面试挺简单的，老师们感觉也都很温柔。</p><h3 id="学院面试">学院面试</h3><p>一上来老师就说面试分为三个部分。</p><p>第一个部分是政治问题，如何看待校园贷、学术不端、当代大学生如何为国家做贡献。说完之后一个老师问我那你说说你如何为国家做贡献，我说我不犯法就是为国家做贡献哈哈哈，然后说了什么可能承担国家的课题之类的，攻克一些技术方面的话。</p><p>第二部分是英语回答问题，那老师中文问问题，要我用英文回答。问了我们学校智能科学与技术专业（我所在的创新班）和计算机科学与技术专业的区别，还有为什么我选择他们的计算机学院不选择人工智能学院。我用的我的中式英语给他们回答了一遍，说我们智科都注重于软件，他们计算机软硬兼顾，我们学了机器学习，计算机视觉还有自然语言处理等，他们注重数据库、操作系统等。然后回答后面一个问题的时候，我最后一句说的是yourinstitute is more ... more fit me. 回答完之后我自己都笑了哈哈哈哈。</p><p>第三部分就正式中文面试了。首先中文自我介绍一下，但由于我之前都只背了英文自我介绍，背了好几个晚上的英文版本，背的贼溜，上来居然要我中文自我介绍。我就当场把英文的转成中文的，顺口介绍了一下大创项目。讲完之后发现很多地方没讲到，竞赛还有成绩都没讲到┭┮﹏┭┮然后开始问我的项目，项目的数据是哪来的，项目推荐系统的准确性是如何衡量的（我项目中有个推荐系统），我大创项目的具体流程，然后问我有没有考虑过用步态识别来完成这个项目（前一天听老师的研究生汇报课题，好像他们就研究的步态识别）。然后把我专利问了问，还问了我的比赛情况，我的在比赛中的职责之类的。然后一个老师插了一句，你是智能科学与技术的是吧，那我问你随机森林算法原理是什么。幸好前几天复习机器学习把随机森林给看了一遍，感觉回答的挺好的。最后问我如何看待实习、读研计划、如果研究生遇到困难怎么办。</p><h3 id="总结">总结</h3><p>北邮面试的总体感觉还是不错的，除了英文自我介绍，其他问题回答的都挺好。过了一个星期北邮老师打电话来问我的意向，问我有没有其他的offer，最后去不去北邮。然后我当时非常纠结学硕专硕的区别，我就跟他说如果学硕我就去，专硕不一定。电话打完之后我就后悔了，因为当时回家了一趟还刚进高铁站回校，下午就给老师发了封邮件说：专硕我也愿意！，那老师说：好的！之后就没有消息了。在那个夏令营的群里问出没出结果，大家也都不理我。那个时候拿到华师的offer了，过了几天一气之下就把群给退了🤣</p><h2 id="山东大学软件学院7.10-7.11">山东大学软件学院（7.10 ~ 7.11）</h2><h3 id="概况介绍-1">概况介绍</h3><p>山大软件感觉实力也不错，总共128人面试，好像有些人没参加，最后优营好像96个，几乎全员优营，而且优营之后还没说是否能直接录取，说的是当前保研名额还没确定，等九月份才能确定是否录取。然后九月份的时候居然还开了预推免，真不知道山大要搞什么。</p><h3 id="号宣讲会">10号宣讲会</h3><p>宣讲会就是各个实验室老师汇报他们做的东西，做的情况，非常无聊，而且还会记录时长，不能退出，进去和结束都要签到，好烦人。我就把腾讯会议在那挂着，一下都没听，去车站接女朋友去了。从上午讲到下午，上午八点半开始，下午六点多结束，中间一小时休息，其他时间一直在讲。。</p><h3 id="号面试">11号面试</h3><p>感觉山大面试面不出个什么东西来，又不要我英文自我介绍，让我中文自我介绍。然后英文问了我项目几个问题，我都回答上了。然后那些老师就一直问我项目，这个怎么做的，有没有考虑什么什么什么。我就说没考虑，没时间做那么多。然后就结束了。</p><h3 id="总结-1">总结</h3><p>山大夏令营之后要联系导师，不联系导师不给优营，而且还发了个问卷挺唬人，有一项就是拿到优营之后去不去山大，填不去那肯定不要你，填去，那心里又不舒服，最后还是填了去哈哈哈哈。九月份的时候又收集了一个问卷，我就直接填了不去。感觉山大面试问不出什么水平来，完全就问项目，专业课专业知识什么的一下都没问。</p><h2 id="华东师范大学计算机7.13-7.15">华东师范大学计算机（7.13 ~7.15）</h2><h3 id="概况介绍-2">概况介绍</h3><p>入了华师计算机是我意想不到的，里面也有很多运气成分。华师夏令营的系统可以填2个志愿，我五月份在华师夏令营网站看到计算机学院要求专业排名前15%，而我是17%，所以我当时就没去报计算机夏令营。因为软件工程要求前20%就行，所以我第一志愿就填了软件工程，推荐信用的是我大创指导老师的推荐信。然后到了六月多，系统快关了，我再去官网看了看，发现计算机的排名要求也变成了20%，我就又赶紧报了个计算机学院，然后我想两个推荐信用同一个老师不太好，我就换了个之前我大数据比赛的指导老师的推荐信。最后没想到第一志愿没入，第二志愿给入了。计算机夏令营总共入了114人，实际进群100个左右，后来有的人又退群，说不去了，还剩九十多个人在群里。到机试的时候看到只有83个人提交过，最后优营了60个，比例还是非常高的，入了营基本上就稳了。</p><h3 id="号宣讲会-1">12号宣讲会</h3><p>第一天就是一大堆的宣讲，各个团队的情况介绍啦，还有各个老师的课题汇报之类的。我基本没怎么听，在吃东西跟女朋友一起看觉醒年代哈哈哈。就听了两个比较感兴趣的团队，一个机器学习团队，一个语言认知与知识计算团队。</p><h3 id="号上午机考-下午交流">13号上午机考 + 下午交流</h3><p>第二天就是机考以及与各个团队的交流。之前就听说华师夏令营的机考是他们学校的ACM出题，所以非常慌，一直也在练算法。用的当然就是华师自己的OJ，感兴趣的可以注册一个去看看，刷刷题<a href="https://acm.ecnu.edu.cn/">ECNU OnlineJudge</a>。账号是当天早上考前发的，中途不能掉线，因为账号绑定IP地址，如果掉线IP变了这个号就登不上了。一共四题，每题100分，感觉挺难的，没有人AC但有人拿了360，真的是太牛了。我最后拿了230分，感觉有个十几二十名吧。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921104210722.png" alt="华师机考结果"><figcaption aria-hidden="true">华师机考结果</figcaption></figure><h4 id="a.-索引查询">A. 索引查询</h4><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921103755949.png" alt="A.索引查询"><figcaption aria-hidden="true">A.索引查询</figcaption></figure><h4 id="b.-框体排序">B. 框体排序</h4><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921104358796.png" alt="B. 框体排序"><figcaption aria-hidden="true">B. 框体排序</figcaption></figure><h4 id="c.-放水">C. 放水</h4><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921104509779.png" alt="C. 放水-1"><figcaption aria-hidden="true">C. 放水-1</figcaption></figure><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921104601946.png" alt="C. 放水-2"><figcaption aria-hidden="true">C. 放水-2</figcaption></figure><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921104629359.png" alt="C. 放水-3"><figcaption aria-hidden="true">C. 放水-3</figcaption></figure><h4 id="d.-正则表达式匹配">D. 正则表达式匹配</h4><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921105119416.png" alt="D. 正则表达式匹配"><figcaption aria-hidden="true">D. 正则表达式匹配</figcaption></figure><h3 id="号团队面试">14号团队面试</h3><p>14号下午需要提交一个志愿表，要填写打算去的团队，以及一二三志愿导师，学院会尽量根据志愿情况，让志愿上的团队来面试你。我当时提交的团队是机器学习团队，因此第二天面试我的就是机器学习团队的老师。</p><p>首先英文自我介绍（终于能用到自我介绍了），我就把背了无数遍的自我介绍又熟练的背了一遍。然后是给了一段英文文章，让我读一遍，然后翻译出来。我感觉我读的还行，翻译的时候就有点磕磕绊绊，自己知道是什么意思，估计面试的老师没听明白我在说什么。翻译完之后还有一个老师问我六级过了没(─.─|||</p><p>自我介绍之后给了一张图片，让我回答图片上的问题，第一个问题是容器和虚拟机的概念，当时一下没反应过来容器是什么，就说我没听说过容器。面试结束后想了想，容器不就是docker嘛，之前学Java的时候我还用过，居然没回答上。第二个问题是SVM是什么，让我讲讲SVM的原理之类的。由于我当时就不是很了解SVM，只知道这个SVM是最大分类间隔分类器，前几天又正好看了李宏毅老师的SVM讲解，就说了一大堆没说到重点，把那个老师都说懵了。我说了什么就是最大分类间隔，然后用的损失函数是hinge-loss之类的，那老师说不是问你损失函数，问你原理。我又说了一大堆屁话哈哈哈，然后这个问题就结束了。</p><p>之后就是各个老师问问题，一个老师问看你做这个项目，对于训练模型方面你有什么经验可以给我们分享吗，有没有遇到什么坑。由于我的项目都是随便做了做，根本没去训练，当时想要老师给台服务器训练模型，老师都不给我，直接让学长给了我一个训练好的模型，然后我就在那胡乱跟老师扯哈哈哈，说到什么学习率方面。然后他又问那学习率方面你怎么做的，我说我用的学习率衰减。他继续问学习率衰减还有什么其他方法吗，我回答说按照当前损失函数梯度设置学习率，梯度越小学习率设置越小，需要计算当前梯度之类的。然后那老师说叫我去看看Pytorch的学习率衰减方法，里面有很多，我这时候才反应过来他问的是Pytorch里的学习率衰减策略，我之前也是有看过的啊喂，只是不知道他问的是这个。</p><p>总的来说，面试感觉很凉，很凉很凉，面完之后就一直躺床上，一直在想该怎么回答。</p><h3 id="总结-2">总结</h3><p>面试完第二天，那个填了志愿的老师就打电话给我了，问了问我的情况，说我面试的分数怎么这么低，问了我什么问题，我说问了我SVM，然后他说，哦，我记得你。当时刚好就是这个老师一直在问我SVM，把他给说蒙了。。。然后他说他打电话问了我老师（给我写推荐信的）我的情况，由于我比赛给我们学校那个老师挂了好几个名，然后都拿到了奖，所以这个老师给我说了一通好话，把我推荐给这老师了，而且好巧不巧，这个老师跟华师我填志愿的老师之前就有合作，很早就认识了，他才有机会跟我说好话。然后华师的老师最后说可以要我，把我简历发他一份。刚跟那老师打完电话，我们学校的老师就给我打电话了，说华师老师打电话问他我的情况，说我面试成绩不好，然后他帮我解释说我不太会面试，但是实践能力很强，比赛拿了很多奖，对我印象很深刻之类的话。我当时真是太感谢他了！这老师真的太好了呜呜呜。</p><p>过了两个星期出结果，我也顺利的拿到了优营。在这还是要感谢一下我的老师呜呜呜。</p><h1 id="预推免">预推免</h1><h2 id="东南大学计算机学院">东南大学计算机学院</h2><h3 id="概况介绍-3">概况介绍</h3><p>东南计算机总共入营了四五百人，计算机学院和软件学院好像是一起面试的，分了好多组并行面试。东南是夏令营和预推免一起开的，所以入了很多人，而且东南入营了没有任何短信或邮件通知，只有加了群或者经常关注官网或系统才能知道自己入营了，感觉很多同学就因为这个错过了入营的机会，没去系统里点确认参加。由于当时已经拿到华师offer了，也不想去东南，就没复习天天在家玩了。所以最后面试情况也不好，没拿到优营。</p><h3 id="分组面试8.7">分组面试（8.7）</h3><p>我面试是第40号，总共46人，到下午才轮到我。首先是讲PPT，学院发了个PPT模版，要自己做个PPT然后屏幕共享讲解。讲完之后英文问我项目，我做了那些工作，以及这个项目怎么做的之类的。很久没有面试，没有练口语了，所以回答的超级烂，磕磕绊绊，没有一句话完整说完。英文问完之后老师开始问问题，第一个老师说我项目太简单了。第二个老师看我PPT最后一页写了大数据之类的什么什么，就问我大数据方面的问题：1、如果数据量太大，比方1T或更大，单机无法全部加载，你怎么训练模型，2、数据量如果太少，你有什么办法解决。我当时一个都没答好，第一个问题我就没回答，老师说不用都会打，我就回答了第二个，我说数据加强，自己手动做数据什么的。然后那个老师说这类方法的名字叫什么你知不知道，我又说不知道。然后就结束了。</p><h3 id="总结-3">总结</h3><p>面试完之后我就好迷茫，怎么问我一个都不会，心里有点难受呜呜呜。然后去网上查了一下，看到感觉那些方法都不是老师想要问的方法。总的来说自己还是非常菜，还是要继续提升自己，多看看书。</p><h2 id="国科大人工智能学院">国科大人工智能学院</h2><h3 id="概况介绍-4">概况介绍</h3><p>我在七月份还是八月份的时候就在国科大系统上报名了预推免，然后一直没有消息，我还以为我早就凉了，前两个星期晚上跑步的时候，北京来了一个电话，我一看北京，我还以为北邮被鸽穿了来找我了哈哈哈哈，没想到是国科大的老师来问我情况，问我有没有别的offer，我说有个上海的offer，但如果国科大能要我我还是想冲一下，去面试。了解了一下我的情况后就说过几天面试，等消息。过了两天官网就发通知了，总共19人入了，加群的有16人，最终就16个人面试，不知道招多少人，按往年情况来看，估计招十个左右。进群看到一个清华，一个上交，压力就大起来了。</p><h3 id="学院面试-1">学院面试</h3><p>国科大学院面试感觉也很舒服，老师看起来也都很友好，首先是英文自我介绍，我还是用的之前背的模版，但这次综合排名出来之后，我又多加了两句话说我已经取得了保研资格，并且综合排名是第二名。之后老师问我创新班是什么情况，让我介绍一下。又问了一下我项目的情况，以及一些课程情况。因为我简历上写能熟练运用C++，Python，Java进行编程，老师就问有多熟练，到哪种程度。最后问我如何在不知道python列表情况下获得最后一个元素。。。总的来说非常简单，就跟聊天一样。</p><h3 id="导师面试">导师面试</h3><p>第二天上午我就打电话给填了志愿的老师问我能不能去，她说她在开会，下午再联系我。下午她就发封邮件给我，让我看一篇论文，第二天一起讨论讨论。那篇论文是关于transformer变形的论文，我就先把transformer看了一遍，然后去看这篇论文，当天晚上就看的差不多了。第二天起来又看了一会。下午五点的时候来给我面试，一共三个人，两个老师，还有一个人应该是她的研一学生。讲完之后她说我讲的不错，一天时间能理解到这个程度很不错。第二天早上我刚醒没一会，她就打电话来说要我了，把我报到学院去了。然后我的面试就这么结束了。</p><h3 id="总结-4">总结</h3><p>国科大从通知我面试到最后拟录取我，正好一个星期，12号老师打电话了解情况，19号就给我发了拟录取通知，都没太反应过来。去网上搜了一下国科大人工智能学院的信息，都不太多，因为是2017年才新成立的学院。然后经过多方打听，并在拟录取我的那个中午，我也跟导师聊了三四十分钟，把我想知道的信息都问清楚了，感觉这个学院还是不错的，而且导师感觉也很不错<del>，比华师找的那个好多了</del>至少不会很差吧，而且听我在北京读书的朋友说国科大在北京名气挺大的，刚好我女朋友毕业以后也去北京，我就选择了国科大人工智能学院，把华师给拒了。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/Inkedimage-20210921135534831.jpg" alt="国科大预录取"><figcaption aria-hidden="true">国科大预录取</figcaption></figure><h1 id="写在最后">写在最后</h1><p>2021年保研就快要结束了，我的去向也基本上定了下来，虽然还不知道国科大究竟怎么样，但终究只是走的路不一样，关键还是要看研究生阶段自己的造化了。去哪里其实都一样，但求个<strong>无悔</strong>二字，只要自己满意就行。等我去那边读书了再来更新那边的情况吧。</p><p>保研大战刚开始的时候，我去博客上看了很多经验贴，南大，中科大厦大之类的，我就感觉如果我去我也行，可实际上到自己报名的时候，连入营的机会都没有。连续被拒十多次，心态都要爆炸了。后来心态慢慢也放平了，看到保研群里的大佬那么多，要不就是都有论文，要不就是排名特别高，我这种没论文没排名的人，那些学校确实看不上我，我也不做那种春秋大梦了。</p><figure><img src="https://cdn.jsdelivr.net/gh/WEI-1228/image/blog-image/image-20210921141046347.png" alt="未入营"><figcaption aria-hidden="true">未入营</figcaption></figure><p>今年保研的情况不会比上一届严峻，海王依旧很多，往往十个人就能占了一百个夏令营名额，所以按道理来说预推免会有很多的机会。但实际上今年很多学校都特别海，候补的人特别多，基本上入营后，除了优营的选手就是候补。这也就导致我后来的第二名的排名没什么用了，想去投，但学校不多了。本来非常想去中科大，但中科大今年收我们学校的人不多，往年入营的人都有很多，今年却卡了rank，只收了我们班前两名，和计算机的前三名，后面的人压根就没机会，而且由于WL很长，我现在有rank了但没机会给我投了。</p><p>最后也希望没有offer的同学在九推中拿到满意的offer，学弟学妹保研的时候也能拿到心仪的offer！</p><hr><p>11月15日补充</p><p>在开系统最后的那几天，我身边有很多同学给中科大的老师发邮件，中科大很多老师都没招满，都需要自己去联系，很多同学就通过自己联系去了中科大，联系其他学校的也有，所以到最后快开系统的几天机会还是有很多的，海王放了offer就有机会了。所以不要轻易放弃，不要因为夏令营失利就否定自己！</p>]]></content>
    
    
    <categories>
      
      <category>保研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>保研</tag>
      
      <tag>计算机</tag>
      
      <tag>夏令营</tag>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
